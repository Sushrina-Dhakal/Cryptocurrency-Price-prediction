{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b34e0cd-42f7-45c2-a6bb-a24607351b07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ba432b-c2ad-44d0-9d99-3d0d57ee6b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993b1413-ec52-4e52-8146-25314a80ad0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df=yf.download(\"BTC-USD\",\"2020-01-01\",\"2024-01-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b60049-47f5-465e-9a73-998584d81a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ad1fa8-da0c-4c54-9ffe-4ec1b2d3c13f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>7194.892090</td>\n",
       "      <td>7254.330566</td>\n",
       "      <td>7174.944336</td>\n",
       "      <td>7200.174316</td>\n",
       "      <td>7200.174316</td>\n",
       "      <td>18565664997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>7202.551270</td>\n",
       "      <td>7212.155273</td>\n",
       "      <td>6935.270020</td>\n",
       "      <td>6985.470215</td>\n",
       "      <td>6985.470215</td>\n",
       "      <td>20802083465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>6984.428711</td>\n",
       "      <td>7413.715332</td>\n",
       "      <td>6914.996094</td>\n",
       "      <td>7344.884277</td>\n",
       "      <td>7344.884277</td>\n",
       "      <td>28111481032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>7345.375488</td>\n",
       "      <td>7427.385742</td>\n",
       "      <td>7309.514160</td>\n",
       "      <td>7410.656738</td>\n",
       "      <td>7410.656738</td>\n",
       "      <td>18444271275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>7410.451660</td>\n",
       "      <td>7544.497070</td>\n",
       "      <td>7400.535645</td>\n",
       "      <td>7411.317383</td>\n",
       "      <td>7411.317383</td>\n",
       "      <td>19725074095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>39936.816406</td>\n",
       "      <td>42209.386719</td>\n",
       "      <td>39825.691406</td>\n",
       "      <td>41816.871094</td>\n",
       "      <td>41816.871094</td>\n",
       "      <td>25598119893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>41815.625000</td>\n",
       "      <td>42195.632812</td>\n",
       "      <td>41431.281250</td>\n",
       "      <td>42120.054688</td>\n",
       "      <td>42120.054688</td>\n",
       "      <td>11422941934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>42126.125000</td>\n",
       "      <td>42797.175781</td>\n",
       "      <td>41696.910156</td>\n",
       "      <td>42035.593750</td>\n",
       "      <td>42035.593750</td>\n",
       "      <td>16858971687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>42030.914062</td>\n",
       "      <td>43305.867188</td>\n",
       "      <td>41818.332031</td>\n",
       "      <td>43288.246094</td>\n",
       "      <td>43288.246094</td>\n",
       "      <td>20668476578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>43300.226562</td>\n",
       "      <td>43838.945312</td>\n",
       "      <td>42711.371094</td>\n",
       "      <td>42952.609375</td>\n",
       "      <td>42952.609375</td>\n",
       "      <td>23842814518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "2020-01-01   7194.892090   7254.330566   7174.944336   7200.174316   \n",
       "2020-01-02   7202.551270   7212.155273   6935.270020   6985.470215   \n",
       "2020-01-03   6984.428711   7413.715332   6914.996094   7344.884277   \n",
       "2020-01-04   7345.375488   7427.385742   7309.514160   7410.656738   \n",
       "2020-01-05   7410.451660   7544.497070   7400.535645   7411.317383   \n",
       "...                  ...           ...           ...           ...   \n",
       "2024-01-26  39936.816406  42209.386719  39825.691406  41816.871094   \n",
       "2024-01-27  41815.625000  42195.632812  41431.281250  42120.054688   \n",
       "2024-01-28  42126.125000  42797.175781  41696.910156  42035.593750   \n",
       "2024-01-29  42030.914062  43305.867188  41818.332031  43288.246094   \n",
       "2024-01-30  43300.226562  43838.945312  42711.371094  42952.609375   \n",
       "\n",
       "               Adj Close       Volume  \n",
       "Date                                   \n",
       "2020-01-01   7200.174316  18565664997  \n",
       "2020-01-02   6985.470215  20802083465  \n",
       "2020-01-03   7344.884277  28111481032  \n",
       "2020-01-04   7410.656738  18444271275  \n",
       "2020-01-05   7411.317383  19725074095  \n",
       "...                  ...          ...  \n",
       "2024-01-26  41816.871094  25598119893  \n",
       "2024-01-27  42120.054688  11422941934  \n",
       "2024-01-28  42035.593750  16858971687  \n",
       "2024-01-29  43288.246094  20668476578  \n",
       "2024-01-30  42952.609375  23842814518  \n",
       "\n",
       "[1491 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea955ee-1928-4890-b6e3-f225b9a6d4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f1ca91-604d-4338-95d7-aab2da37bf91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f335b592-8b6c-43f6-862b-faaa1e015376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61c27df-c8ac-45ef-9c6c-e1362c9097d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    lstm_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"BCH_model_lstm.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(lstm_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'Plot_actualvspredicted/BCH_actual_vs_predicted.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'loss_curve/BCH_loss_curve.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e9d63b-6822-4d9c-9580-c5745df54963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'BCH-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa8eddc-14b3-4296-937b-9cc4ae27b2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd173f1d-d366-4b40-b593-57770862e30a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e3ac05-137e-42b8-9ad4-8d87634032d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6391c0dd-dadb-4046-b768-aa5c281fa934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 41s 65ms/step - loss: 0.0053 - val_loss: 2.9632e-05\n",
      "Epoch 2/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0021 - val_loss: 1.2149e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0015 - val_loss: 1.6894e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0011 - val_loss: 4.3675e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.1091e-04 - val_loss: 5.0934e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0010 - val_loss: 5.2088e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.3127e-04 - val_loss: 3.2863e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 9.4349e-04 - val_loss: 2.6084e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 0.0011 - val_loss: 1.8511e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.0477e-04 - val_loss: 5.9986e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.0950e-04 - val_loss: 1.1490e-05\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.4161e-04 - val_loss: 1.9272e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 8.1547e-04 - val_loss: 8.6089e-06\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.1133e-04 - val_loss: 1.4937e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.1085e-04 - val_loss: 1.6246e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 9.2741e-04 - val_loss: 4.0291e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.4141e-04 - val_loss: 3.9266e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 8.9235e-04 - val_loss: 2.5630e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 9.3755e-04 - val_loss: 6.3759e-06\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.6175e-04 - val_loss: 4.7458e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.5166e-04 - val_loss: 6.0230e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.8609e-04 - val_loss: 2.1330e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.2878e-04 - val_loss: 0.0018\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.4039e-04 - val_loss: 1.4979e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.5281e-04 - val_loss: 1.2920e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.9688e-04 - val_loss: 4.9274e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7174e-04 - val_loss: 1.1214e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.0480e-04 - val_loss: 7.6023e-06\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.3691e-04 - val_loss: 4.3178e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 7.3992e-04 - val_loss: 4.0263e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 7.1449e-04 - val_loss: 8.2597e-06\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 7.2079e-04 - val_loss: 1.0927e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 8.2306e-04 - val_loss: 1.3065e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.7861e-04 - val_loss: 1.2882e-04\n",
      "9/9 [==============================] - 6s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 11.574812775965095\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 35s 58ms/step - loss: 0.0055 - val_loss: 1.2956e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 49ms/step - loss: 0.0032 - val_loss: 5.2879e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0021 - val_loss: 1.7757e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 0.0017 - val_loss: 1.7810e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 0.0016 - val_loss: 3.4391e-05\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 0.0013 - val_loss: 7.6222e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0011 - val_loss: 4.5910e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 0.0014 - val_loss: 2.8852e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 9.6644e-04 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0013 - val_loss: 1.8541e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0010 - val_loss: 2.9681e-05\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 8.3335e-04 - val_loss: 1.2711e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0013 - val_loss: 3.1118e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.9853e-04 - val_loss: 2.6922e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 8.3132e-04 - val_loss: 7.0391e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.1494e-04 - val_loss: 9.1323e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.7765e-04 - val_loss: 1.4775e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.8604e-04 - val_loss: 0.0015\n",
      "9/9 [==============================] - 5s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 31.053576212427743\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 34s 69ms/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 16s - loss: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0020 - val_loss: 1.4082e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0025 - val_loss: 5.0990e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0011 - val_loss: 3.6135e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 9.4852e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 9.0460e-04 - val_loss: 1.6408e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.4209e-04 - val_loss: 9.1155e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0010 - val_loss: 2.5085e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.5003e-04 - val_loss: 1.8375e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 9.2244e-04 - val_loss: 3.5050e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 9.5090e-04 - val_loss: 7.9931e-06\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 0.0014 - val_loss: 3.0333e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 7.6519e-04 - val_loss: 7.1686e-06\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 8.8667e-04 - val_loss: 4.9274e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 15s 54ms/step - loss: 7.5597e-04 - val_loss: 3.9060e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 6.8826e-04 - val_loss: 2.7187e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 8.3483e-04 - val_loss: 8.8215e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.4797e-04 - val_loss: 1.2237e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0010 - val_loss: 1.4611e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.4469e-04 - val_loss: 8.6881e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.7969e-04 - val_loss: 1.6491e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.6692e-04 - val_loss: 1.3597e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 6.5512e-04 - val_loss: 7.0443e-06\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.1151e-04 - val_loss: 1.0837e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 7.1675e-04 - val_loss: 8.7149e-06\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 6.8506e-04 - val_loss: 1.8144e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 7.4448e-04 - val_loss: 2.9620e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 5.8274e-04 - val_loss: 3.8757e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 7.5761e-04 - val_loss: 2.3812e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 9.0951e-04 - val_loss: 5.5606e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 7.6147e-04 - val_loss: 3.9718e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 7.4022e-04 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 6.9489e-04 - val_loss: 9.3287e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 7.2885e-04 - val_loss: 4.9473e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 7.6041e-04 - val_loss: 5.6081e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 7.1336e-04 - val_loss: 9.8155e-06\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 7.4212e-04 - val_loss: 2.0933e-05\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 6.6348e-04 - val_loss: 5.2011e-05\n",
      "9/9 [==============================] - 5s 38ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.883977529684667\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 36s 64ms/step - loss: 0.0065 - val_loss: 1.0759e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 13s - loss: 0.0271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 16s 59ms/step - loss: 0.0027 - val_loss: 4.9063e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 0.0015 - val_loss: 6.6707e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.0011 - val_loss: 1.7724e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.0016 - val_loss: 1.5517e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 9.4179e-04 - val_loss: 2.0848e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 8.7126e-04 - val_loss: 2.5212e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 9.1650e-04 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 9.0811e-04 - val_loss: 7.2565e-06\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.4327e-04 - val_loss: 7.0794e-06\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 8.0564e-04 - val_loss: 3.4553e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.0012 - val_loss: 5.0310e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.0011 - val_loss: 6.8271e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0010 - val_loss: 4.5379e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.0011 - val_loss: 7.5801e-06\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 7.5766e-04 - val_loss: 7.1898e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.7100e-04 - val_loss: 4.1060e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 7.4443e-04 - val_loss: 1.5640e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 7.8052e-04 - val_loss: 2.2886e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.4493e-04 - val_loss: 3.6534e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 6.4489e-04 - val_loss: 7.2023e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.2524e-04 - val_loss: 2.1658e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 9.3577e-04 - val_loss: 3.3422e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 19s 69ms/step - loss: 7.3974e-04 - val_loss: 3.4063e-04\n",
      "9/9 [==============================] - 6s 44ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.690908391640852\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 39s 92ms/step - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 18s - loss: 1.8654e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 20s 74ms/step - loss: 0.0022 - val_loss: 1.6671e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 0.0017 - val_loss: 1.6708e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 0.0014 - val_loss: 2.9510e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 0.0013 - val_loss: 6.1698e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.0011 - val_loss: 4.7376e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.0010 - val_loss: 8.4030e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 0.0010 - val_loss: 3.1322e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 0.0011 - val_loss: 9.9880e-06\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 9.5264e-04 - val_loss: 5.3524e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 7.8966e-04 - val_loss: 3.5074e-05\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 8.2686e-04 - val_loss: 2.1997e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 8.9997e-04 - val_loss: 1.6658e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 9.8291e-04 - val_loss: 1.3306e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 9.7250e-04 - val_loss: 7.8860e-06\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 9.3002e-04 - val_loss: 1.3974e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 8.3006e-04 - val_loss: 6.6124e-06\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 8.3620e-04 - val_loss: 1.4743e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 8.2479e-04 - val_loss: 7.8160e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 8.2500e-04 - val_loss: 7.1235e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 6.3599e-04 - val_loss: 5.7801e-06\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 6.6844e-04 - val_loss: 1.0455e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 7.0301e-04 - val_loss: 1.9005e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 23s 88ms/step - loss: 7.4323e-04 - val_loss: 5.7886e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 7.3275e-04 - val_loss: 7.5395e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.9883e-04 - val_loss: 3.3690e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.6086e-04 - val_loss: 1.0491e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.5203e-04 - val_loss: 6.0464e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 6.7376e-04 - val_loss: 6.8935e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 6.9409e-04 - val_loss: 7.7524e-06\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.4237e-04 - val_loss: 6.0451e-06\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 6.7525e-04 - val_loss: 6.8673e-06\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 7.2599e-04 - val_loss: 2.0115e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 6.8388e-04 - val_loss: 2.5033e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 7.4049e-04 - val_loss: 6.6348e-06\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 6.5810e-04 - val_loss: 1.5056e-04\n",
      "8/8 [==============================] - 7s 46ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.94968246688757\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 77s 152ms/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 2/100\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 0.0019 - val_loss: 2.0295e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 0.0015 - val_loss: 2.9815e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 0.0012 - val_loss: 5.6057e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0012 - val_loss: 3.0782e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 0.0010 - val_loss: 1.1856e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 30s 110ms/step - loss: 0.0012 - val_loss: 3.2153e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0017 - val_loss: 2.2714e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.0010 - val_loss: 8.0338e-06\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 9.5581e-04 - val_loss: 4.9850e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 8.1067e-04 - val_loss: 2.1088e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 8.5800e-04 - val_loss: 1.6122e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 7.0090e-04 - val_loss: 8.2649e-06\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 28s 104ms/step - loss: 9.0798e-04 - val_loss: 2.7681e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 7.7656e-04 - val_loss: 1.1481e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 8.0290e-04 - val_loss: 1.7538e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0012 - val_loss: 2.4329e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 7.1237e-04 - val_loss: 3.2987e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 7.3636e-04 - val_loss: 2.6052e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 8.2047e-04 - val_loss: 0.0014\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 30s 110ms/step - loss: 7.3301e-04 - val_loss: 7.2973e-06\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 8.3791e-04 - val_loss: 2.0238e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 6.5263e-04 - val_loss: 1.1981e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 7.3844e-04 - val_loss: 2.6609e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 6.5678e-04 - val_loss: 3.3607e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 6.8376e-04 - val_loss: 7.0287e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 6.3692e-04 - val_loss: 2.6571e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 30s 110ms/step - loss: 7.4030e-04 - val_loss: 2.0106e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 6.3016e-04 - val_loss: 3.8234e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 6.0208e-04 - val_loss: 1.7337e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 6.5616e-04 - val_loss: 7.4149e-05\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 6.4240e-04 - val_loss: 4.9191e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 8.9129e-04 - val_loss: 1.4791e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 6.1518e-04 - val_loss: 3.8849e-05\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 28s 103ms/step - loss: 6.5563e-04 - val_loss: 1.3605e-05\n",
      "8/8 [==============================] - 7s 64ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 12.436209035187217\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 55s 138ms/step - loss: 0.0053 - val_loss: 6.8374e-05\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 31s 115ms/step - loss: 0.0027 - val_loss: 9.7231e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 0.0013 - val_loss: 6.0955e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 33s 122ms/step - loss: 0.0012 - val_loss: 9.1382e-06\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 0.0010 - val_loss: 1.1171e-05\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 0.0011 - val_loss: 8.7228e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 0.0014 - val_loss: 9.0515e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 8.9224e-04 - val_loss: 9.9839e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 7.3960e-04 - val_loss: 1.5766e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 9.3203e-04 - val_loss: 3.4777e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 28s 104ms/step - loss: 8.0660e-04 - val_loss: 5.6929e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 9.5929e-04 - val_loss: 7.5792e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 28s 104ms/step - loss: 6.4872e-04 - val_loss: 2.0490e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 28s 106ms/step - loss: 8.2923e-04 - val_loss: 9.9158e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 33s 124ms/step - loss: 9.9030e-04 - val_loss: 1.5426e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 33s 122ms/step - loss: 8.8854e-04 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 8.8686e-04 - val_loss: 6.6421e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 7.1029e-04 - val_loss: 6.4076e-06\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.5431e-04 - val_loss: 9.7457e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 27s 101ms/step - loss: 7.1585e-04 - val_loss: 3.2650e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 33s 124ms/step - loss: 7.9898e-04 - val_loss: 2.7877e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 7.3592e-04 - val_loss: 1.2924e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 9.2093e-04 - val_loss: 4.8979e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 9.6333e-04 - val_loss: 8.6898e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 6.5224e-04 - val_loss: 1.6994e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 6.5244e-04 - val_loss: 1.6059e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 7.4752e-04 - val_loss: 0.0033\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 8.9736e-04 - val_loss: 7.8846e-06\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 7.8205e-04 - val_loss: 2.5133e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 7.4295e-04 - val_loss: 3.6409e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 6.8418e-04 - val_loss: 2.3701e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 7.4092e-04 - val_loss: 8.7480e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 6.6136e-04 - val_loss: 3.5690e-04\n",
      "8/8 [==============================] - 7s 95ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.80414416080001\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.0065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 86s 195ms/step - loss: 0.0065 - val_loss: 1.6820e-04\n",
      "Epoch 2/100\n",
      "268/268 [==============================] - 45s 168ms/step - loss: 0.0027 - val_loss: 1.6725e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.0014 - val_loss: 9.1978e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 0.0015 - val_loss: 3.2206e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 44s 163ms/step - loss: 0.0012 - val_loss: 1.6738e-05\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 43s 162ms/step - loss: 9.5789e-04 - val_loss: 9.0645e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 40s 150ms/step - loss: 0.0010 - val_loss: 9.0983e-06\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 39s 144ms/step - loss: 8.4982e-04 - val_loss: 2.7356e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.0011 - val_loss: 1.5853e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 8.5209e-04 - val_loss: 6.6035e-06\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 9.9204e-04 - val_loss: 2.3761e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 0.0011 - val_loss: 8.0040e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 36s 134ms/step - loss: 0.0010 - val_loss: 5.7242e-06\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 38s 143ms/step - loss: 8.7579e-04 - val_loss: 0.0029\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.0011 - val_loss: 5.7092e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 27s 101ms/step - loss: 7.8291e-04 - val_loss: 1.2948e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 7.7607e-04 - val_loss: 2.7759e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 8.2673e-04 - val_loss: 2.2782e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 6.9622e-04 - val_loss: 1.0251e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 6.8434e-04 - val_loss: 1.0726e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 8.2667e-04 - val_loss: 9.2053e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 33s 121ms/step - loss: 9.4717e-04 - val_loss: 6.2540e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 7.6019e-04 - val_loss: 1.0787e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 8.9088e-04 - val_loss: 6.0094e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 8.3092e-04 - val_loss: 1.0913e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 6.7814e-04 - val_loss: 9.0910e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 8.8263e-04 - val_loss: 2.8370e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 7.2521e-04 - val_loss: 7.5152e-06\n",
      "8/8 [==============================] - 5s 91ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.944102715682918\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 23s 62ms/step - loss: 0.0049 - val_loss: 5.1584e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 4s - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0028 - val_loss: 5.5792e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0015 - val_loss: 1.5667e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0012 - val_loss: 7.6438e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 3.5132e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 2.7986e-05\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0012 - val_loss: 4.9431e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 9.8891e-04 - val_loss: 2.4100e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.0570e-04 - val_loss: 1.2814e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0010 - val_loss: 8.5888e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.6147e-04 - val_loss: 3.7912e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.6535e-04 - val_loss: 2.0831e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 9.6179e-04 - val_loss: 8.5004e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.5421e-04 - val_loss: 1.5445e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.9834e-04 - val_loss: 2.4954e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.9943e-04 - val_loss: 1.9335e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.2539e-04 - val_loss: 1.1172e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.4542e-04 - val_loss: 2.8507e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.9443e-04 - val_loss: 1.0149e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.7619e-04 - val_loss: 4.6421e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.3020e-04 - val_loss: 5.7257e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.7226e-04 - val_loss: 6.3987e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.0294e-04 - val_loss: 4.9965e-05\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.8865e-04 - val_loss: 1.1700e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.7806e-04 - val_loss: 2.2018e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.5884e-04 - val_loss: 0.0013\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.5039e-04 - val_loss: 1.0916e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8426e-04 - val_loss: 3.4924e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6463e-04 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8660e-04 - val_loss: 2.5903e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.0142e-04 - val_loss: 4.1085e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.4062e-04 - val_loss: 7.5656e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.3982e-04 - val_loss: 2.2906e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.0031e-04 - val_loss: 6.2612e-06\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.7241e-04 - val_loss: 4.0579e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.4051e-04 - val_loss: 4.0990e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.8982e-04 - val_loss: 2.2114e-05\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.5492e-04 - val_loss: 3.1590e-05\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.1532e-04 - val_loss: 3.0111e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.6281e-04 - val_loss: 2.1725e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0280e-04 - val_loss: 2.2423e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.7958e-04 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.9999e-04 - val_loss: 7.2924e-05\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.1640e-04 - val_loss: 5.4591e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.7168e-04 - val_loss: 1.8260e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.2836e-04 - val_loss: 1.5003e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.8004e-04 - val_loss: 6.1012e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.2000e-04 - val_loss: 6.9795e-05\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.1251e-04 - val_loss: 4.9880e-05\n",
      "9/9 [==============================] - 3s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.577124515604899\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 28s 77ms/step - loss: 0.0064 - val_loss: 4.8120e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 8.4999e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0036 - val_loss: 4.7800e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0029 - val_loss: 3.6680e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0018 - val_loss: 3.0069e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0021 - val_loss: 5.5806e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0013 - val_loss: 2.4382e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0013 - val_loss: 7.7449e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0011 - val_loss: 2.5073e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0011 - val_loss: 2.6132e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0011 - val_loss: 4.6240e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.6307e-04 - val_loss: 2.3028e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0012 - val_loss: 7.8517e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.2203e-04 - val_loss: 5.4577e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.5268e-04 - val_loss: 1.1737e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0011 - val_loss: 1.9671e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.7466e-04 - val_loss: 2.5066e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.0204e-04 - val_loss: 1.4180e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.5742e-04 - val_loss: 3.5538e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.1178e-04 - val_loss: 6.9146e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.2448e-04 - val_loss: 4.3271e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.1096e-04 - val_loss: 4.1061e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.2975e-04 - val_loss: 1.3368e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.1576e-04 - val_loss: 9.6484e-06\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.2849e-04 - val_loss: 8.6258e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.2686e-04 - val_loss: 4.2367e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.7048e-04 - val_loss: 1.1353e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.6379e-04 - val_loss: 2.8723e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0695e-04 - val_loss: 2.6830e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.1877e-04 - val_loss: 1.9729e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.3525e-04 - val_loss: 1.8890e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.1464e-04 - val_loss: 9.0540e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.5490e-04 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0126e-04 - val_loss: 4.0138e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.0582e-04 - val_loss: 4.1508e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0729e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.9046e-04 - val_loss: 5.6684e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.8242e-04 - val_loss: 3.9325e-05\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.1325e-04 - val_loss: 3.3071e-05\n",
      "9/9 [==============================] - 4s 25ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.753525124658438\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 23s 76ms/step - loss: 0.0050 - val_loss: 3.3186e-05\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 7s - loss: 7.4298e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0025 - val_loss: 2.0768e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0013 - val_loss: 2.0898e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0013 - val_loss: 1.5175e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0011 - val_loss: 8.9243e-05\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 9.4314e-04 - val_loss: 1.0972e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 9.7205e-04 - val_loss: 4.7507e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.1021e-04 - val_loss: 1.0298e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 49ms/step - loss: 9.8860e-04 - val_loss: 2.7299e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 9.1131e-04 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.8999e-04 - val_loss: 4.9929e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.8422e-04 - val_loss: 4.6730e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.8555e-04 - val_loss: 4.3699e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.0714e-04 - val_loss: 1.5178e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3012e-04 - val_loss: 2.7624e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.1713e-04 - val_loss: 8.4956e-06\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0070e-04 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 9.1370e-04 - val_loss: 2.1536e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 8.2917e-04 - val_loss: 9.8814e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.8340e-04 - val_loss: 4.7925e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 7.5718e-04 - val_loss: 7.3203e-06\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 7.0348e-04 - val_loss: 3.1949e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.5342e-04 - val_loss: 1.7271e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 8.4100e-04 - val_loss: 1.1749e-05\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.7222e-04 - val_loss: 3.1228e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.9686e-04 - val_loss: 4.8577e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 7.3020e-04 - val_loss: 6.7355e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 6.8734e-04 - val_loss: 1.4594e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.8560e-04 - val_loss: 5.7709e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 9.0238e-04 - val_loss: 5.3500e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0012 - val_loss: 1.0856e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.9912e-04 - val_loss: 1.2852e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.4557e-04 - val_loss: 1.5541e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.1374e-04 - val_loss: 1.4461e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 6.2978e-04 - val_loss: 0.0016\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 7.4442e-04 - val_loss: 1.5801e-04\n",
      "9/9 [==============================] - 4s 34ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.383760352908787\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 41s 121ms/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0034 - val_loss: 1.0659e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0018 - val_loss: 1.7433e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 0.0015 - val_loss: 3.0467e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0014 - val_loss: 1.9850e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 0.0012 - val_loss: 5.5139e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 0.0011 - val_loss: 1.2142e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 9.4499e-04 - val_loss: 1.4484e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 8.4509e-04 - val_loss: 4.3257e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.8609e-04 - val_loss: 9.8629e-06\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.1869e-04 - val_loss: 3.9267e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.5106e-04 - val_loss: 3.3668e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.9919e-04 - val_loss: 2.4061e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.7345e-04 - val_loss: 9.6171e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 9.5097e-04 - val_loss: 4.7831e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 8.5420e-04 - val_loss: 1.1421e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 9.3455e-04 - val_loss: 2.1713e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.9287e-04 - val_loss: 2.8669e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.3354e-04 - val_loss: 4.2909e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 8.2561e-04 - val_loss: 7.4794e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.9897e-04 - val_loss: 6.7724e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 8.2196e-04 - val_loss: 7.2857e-06\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 8.1210e-04 - val_loss: 8.6244e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 7.6575e-04 - val_loss: 1.6834e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 0.0010 - val_loss: 1.8797e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.8857e-04 - val_loss: 7.2770e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 6.3500e-04 - val_loss: 1.8722e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.7342e-04 - val_loss: 2.2388e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.4721e-04 - val_loss: 7.9116e-06\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 7.6881e-04 - val_loss: 2.9321e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 6.2715e-04 - val_loss: 6.7426e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 7.1744e-04 - val_loss: 9.0430e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.4718e-04 - val_loss: 3.8574e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 6.6064e-04 - val_loss: 3.2210e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 6.6017e-04 - val_loss: 3.9416e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 8.2628e-04 - val_loss: 2.8608e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.3522e-04 - val_loss: 2.1136e-04\n",
      "9/9 [==============================] - 4s 37ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.15982072098446\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 27s 100ms/step - loss: 0.0038 - val_loss: 6.4225e-05\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 9s - loss: 5.1844e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0020 - val_loss: 8.4038e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 0.0015 - val_loss: 2.7154e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 0.0014 - val_loss: 4.6131e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 0.0011 - val_loss: 1.2598e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0012 - val_loss: 2.2767e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 0.0012 - val_loss: 8.8638e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0011 - val_loss: 4.1196e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 9.6928e-04 - val_loss: 2.1806e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 8.5824e-04 - val_loss: 5.2244e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 8.5082e-04 - val_loss: 3.6167e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.9568e-04 - val_loss: 7.1218e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 8.3848e-04 - val_loss: 2.3583e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 7.4178e-04 - val_loss: 7.8510e-06\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.4350e-04 - val_loss: 8.0629e-06\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.2776e-04 - val_loss: 9.5914e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 8.6066e-04 - val_loss: 1.0727e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 6.5750e-04 - val_loss: 7.6076e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.7403e-04 - val_loss: 2.5630e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.6256e-04 - val_loss: 2.2834e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 7.3341e-04 - val_loss: 8.2328e-06\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.6774e-04 - val_loss: 1.5988e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 8.5902e-04 - val_loss: 5.4651e-05\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.1062e-04 - val_loss: 8.5511e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 5.9501e-04 - val_loss: 5.9705e-06\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 6.5336e-04 - val_loss: 6.3630e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.7842e-04 - val_loss: 0.0016\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.1819e-04 - val_loss: 1.6536e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.6343e-04 - val_loss: 8.8167e-06\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.3627e-04 - val_loss: 8.9856e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.1620e-04 - val_loss: 4.3903e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.3738e-04 - val_loss: 2.2630e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 6.4027e-04 - val_loss: 4.2114e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.2414e-04 - val_loss: 2.1472e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.4568e-04 - val_loss: 2.8029e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 5.7616e-04 - val_loss: 6.0851e-06\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.0557e-04 - val_loss: 5.7022e-06\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 6.2322e-04 - val_loss: 3.1333e-05\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.4691e-04 - val_loss: 6.3546e-06\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.6229e-04 - val_loss: 1.5626e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 5.5904e-04 - val_loss: 3.8978e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 5.4995e-04 - val_loss: 8.9748e-06\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 9.1021e-04 - val_loss: 4.2845e-05\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 5.8479e-04 - val_loss: 6.4135e-06\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 6.9068e-04 - val_loss: 5.6330e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 6.9574e-04 - val_loss: 1.0990e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.0329e-04 - val_loss: 1.6085e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 7.0291e-04 - val_loss: 1.1796e-05\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 5.6830e-04 - val_loss: 1.1144e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 5.9396e-04 - val_loss: 2.9418e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 5.8194e-04 - val_loss: 6.3305e-06\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 5.9846e-04 - val_loss: 1.2471e-04\n",
      "8/8 [==============================] - 7s 60ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.816004149098124\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 49s 157ms/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 14s 108ms/step - loss: 0.0030 - val_loss: 5.9471e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 0.0019 - val_loss: 1.8544e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 14s 104ms/step - loss: 0.0015 - val_loss: 3.7342e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 0.0014 - val_loss: 6.9640e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0013 - val_loss: 3.1949e-05\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 0.0013 - val_loss: 5.3681e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 13s 95ms/step - loss: 0.0012 - val_loss: 2.7652e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 0.0012 - val_loss: 1.1720e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 0.0012 - val_loss: 3.9023e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 0.0012 - val_loss: 1.8930e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 9.3293e-04 - val_loss: 5.4018e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 8.5357e-04 - val_loss: 1.5586e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 9.0327e-04 - val_loss: 3.2215e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.1472e-04 - val_loss: 2.3643e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 8.7919e-04 - val_loss: 2.3046e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 8.2506e-04 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.8486e-04 - val_loss: 1.8657e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 9.1012e-04 - val_loss: 2.0940e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 8.4397e-04 - val_loss: 2.0237e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 8.3341e-04 - val_loss: 8.7008e-06\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 9.5182e-04 - val_loss: 6.7916e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 7.4188e-04 - val_loss: 6.3797e-06\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.2355e-04 - val_loss: 1.5867e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.5586e-04 - val_loss: 8.5946e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.1777e-04 - val_loss: 6.9333e-05\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.3183e-04 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 7.6831e-04 - val_loss: 3.8523e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.9419e-04 - val_loss: 1.0104e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.9363e-04 - val_loss: 1.9699e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.5055e-04 - val_loss: 2.3316e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 9.3142e-04 - val_loss: 4.4388e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 7.0493e-04 - val_loss: 4.7258e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 5.8409e-04 - val_loss: 1.5363e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 6.6648e-04 - val_loss: 1.1269e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 6.1517e-04 - val_loss: 6.2570e-06\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 7.1279e-04 - val_loss: 1.5749e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 6.9168e-04 - val_loss: 5.5198e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.7058e-04 - val_loss: 2.2182e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.2588e-04 - val_loss: 3.8213e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.2808e-04 - val_loss: 9.5880e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.7325e-04 - val_loss: 1.1409e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 5.9540e-04 - val_loss: 1.0935e-05\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 8.0107e-04 - val_loss: 7.8545e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.7151e-04 - val_loss: 7.1549e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 7.0013e-04 - val_loss: 1.2837e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.8080e-04 - val_loss: 7.0831e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.2588e-04 - val_loss: 2.0603e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 5.9685e-04 - val_loss: 1.2296e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.7942e-04 - val_loss: 2.4935e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.0470e-04 - val_loss: 4.0234e-05\n",
      "8/8 [==============================] - 3s 49ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 12.431941662977493\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 22s 98ms/step - loss: 0.0066 - val_loss: 4.2484e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 10s - loss: 0.0221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 11s 82ms/step - loss: 0.0024 - val_loss: 6.8530e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 0.0019 - val_loss: 2.8188e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 0.0015 - val_loss: 4.1366e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.0013 - val_loss: 4.0376e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.0013 - val_loss: 6.0294e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.0012 - val_loss: 1.3296e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 9.9688e-04 - val_loss: 2.7509e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 9.3946e-04 - val_loss: 0.0013\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 0.0012 - val_loss: 3.9396e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 8.7177e-04 - val_loss: 5.3780e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 9.2087e-04 - val_loss: 5.5829e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 9.3268e-04 - val_loss: 7.3759e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 7.3818e-04 - val_loss: 8.3022e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 7.6332e-04 - val_loss: 3.2089e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 9.5803e-04 - val_loss: 2.4287e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 8.0745e-04 - val_loss: 6.2486e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 9.8056e-04 - val_loss: 2.8174e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.6545e-04 - val_loss: 8.9918e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 7.3272e-04 - val_loss: 5.8641e-06\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 7.5239e-04 - val_loss: 1.7854e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 7.0098e-04 - val_loss: 6.0090e-06\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 6.8530e-04 - val_loss: 1.9073e-05\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 7.1259e-04 - val_loss: 1.7405e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 7.1983e-04 - val_loss: 6.7045e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.6618e-04 - val_loss: 1.4591e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 7.1189e-04 - val_loss: 9.1763e-06\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.8954e-04 - val_loss: 8.1794e-06\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 7.6691e-04 - val_loss: 7.7355e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 6.8033e-04 - val_loss: 1.5071e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 6.8224e-04 - val_loss: 5.5020e-06\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 6.4855e-04 - val_loss: 1.5201e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.1436e-04 - val_loss: 3.8713e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 11s 86ms/step - loss: 9.7545e-04 - val_loss: 1.0778e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 6.5397e-04 - val_loss: 1.5825e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 7.0813e-04 - val_loss: 7.1867e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 9.3625e-04 - val_loss: 1.1612e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 7.0413e-04 - val_loss: 1.7565e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 7.1109e-04 - val_loss: 9.2321e-06\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 6.4585e-04 - val_loss: 8.1904e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 7.5114e-04 - val_loss: 1.7897e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 6.8286e-04 - val_loss: 3.3952e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.8854e-04 - val_loss: 8.3561e-06\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 11s 86ms/step - loss: 6.1920e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 7.3490e-04 - val_loss: 1.1348e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 5.7988e-04 - val_loss: 3.3257e-04\n",
      "8/8 [==============================] - 2s 57ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.86525139928024\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 27s 128ms/step - loss: 0.0060 - val_loss: 6.3111e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0039 - val_loss: 2.1690e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 0.0026 - val_loss: 2.0781e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0021 - val_loss: 3.9397e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 0.0014 - val_loss: 6.4957e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 0.0014 - val_loss: 1.3962e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0011 - val_loss: 7.1083e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 14s 108ms/step - loss: 0.0014 - val_loss: 5.6904e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 14s 106ms/step - loss: 9.5039e-04 - val_loss: 3.1700e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 14s 107ms/step - loss: 0.0011 - val_loss: 8.1829e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 7.7962e-04 - val_loss: 2.6901e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 8.4890e-04 - val_loss: 4.4265e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 14s 108ms/step - loss: 9.4353e-04 - val_loss: 7.7131e-06\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 9.2111e-04 - val_loss: 1.5432e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0013 - val_loss: 2.1220e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 8.6107e-04 - val_loss: 1.3173e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 6.9147e-04 - val_loss: 2.2415e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 7.6169e-04 - val_loss: 2.8966e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 14s 107ms/step - loss: 7.4522e-04 - val_loss: 4.4971e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 9.0896e-04 - val_loss: 1.3260e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 7.5870e-04 - val_loss: 5.8672e-06\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 7.3885e-04 - val_loss: 1.0039e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 14s 104ms/step - loss: 6.7403e-04 - val_loss: 6.6214e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 7.2022e-04 - val_loss: 6.4083e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 8.1909e-04 - val_loss: 2.7808e-05\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 8.8383e-04 - val_loss: 1.8772e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 9.6036e-04 - val_loss: 7.9766e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 6.6750e-04 - val_loss: 2.2944e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 7.1021e-04 - val_loss: 4.5676e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.4454e-04 - val_loss: 6.6298e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 9.7210e-04 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 14s 108ms/step - loss: 7.3714e-04 - val_loss: 7.7653e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 7.1709e-04 - val_loss: 2.9069e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.6001e-04 - val_loss: 6.2505e-06\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 8.3355e-04 - val_loss: 2.9137e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 7.1434e-04 - val_loss: 1.4205e-04\n",
      "8/8 [==============================] - 3s 66ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.195092693637921\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d54fc3e-ad35-4e61-a742-9e47a21d6989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 11.574812775965095}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 31.053576212427743}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 9.883977529684667}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 10.690908391640852}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 10.94968246688757}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 12.436209035187217}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 10.80414416080001}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 10.944102715682918}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 9.577124515604899}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 10.753525124658438}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 9.383760352908787}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 10.15982072098446}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 9.816004149098124}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 12.431941662977493}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 10.86525139928024}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 10.195092693637921}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd52963-c06e-45da-b86c-77b5b6289eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = joblib.load(\"BCH_model_lstm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b3dd620-4d75-4547-8958-f9e3c82a05a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler = prepare_data(df, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d869c9c-ab6f-4ba0-a7ee-57ee35b5886c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f01cb67-4f8e-45b0-92bf-b2c303e211e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(1,-1)\n",
    "y_test = y_test.reshape(1,-1)\n",
    "y_pred_scaled = scaler.inverse_transform(y_pred)\n",
    "y_test_scaled = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a52809b3-5f68-423d-874e-62f1227e0f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.383760352908787"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_pred_scaled, y_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fc8fd8e-7d39-4fbc-beea-27da565e9d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a0eeac5-8349-4db9-a81d-78872db2033a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8139902757183313"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mape(y_test_scaled, y_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067756f3-907c-458a-9a34-746b8722bf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
