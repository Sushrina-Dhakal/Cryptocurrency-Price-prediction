{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d4a9d8-1e4b-48fa-a45d-25ccbe43a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3c0021-3d99-449e-83c9-90455f986e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7759d9f6-5ac4-4487-9bb3-8bb6c652a0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440c9132-be76-4db3-9b35-10ff87d9568e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86670bf-bbbc-494d-b871-0fea7b378433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    lstm_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    plt.plot(y_test, label='Actual')\n",
    "    plt.plot(lstm_predictions, label='Predicted')\n",
    "    plt.title('Actual vs Predicted Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Bitcoin_Models/actual_vs_predicted_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "    plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Epoch Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Bitcoin_Models/loss_curve_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a7b73f-49ac-4046-a99e-0d15cc99fdba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'BTC-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50858e37-8d49-4e10-8390-2794114d4bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_range = [50, 100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60,80]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4389e42-9484-40b5-b685-985be1fd8d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4f0dbb-b756-469a-b7af-e56599fbe28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab621df5-16c6-4566-a798-e96ea368cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "263/263 [==============================] - 25s 49ms/step - loss: 0.0084 - val_loss: 7.2595e-04\n",
      "Epoch 2/50\n",
      "  3/263 [..............................] - ETA: 10s - loss: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 9s 34ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0027 - val_loss: 7.3448e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0018 - val_loss: 3.7599e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 0.0015 - val_loss: 7.8180e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 0.0015 - val_loss: 2.8015e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 8.7624e-04 - val_loss: 2.0500e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 9.0328e-04 - val_loss: 3.9897e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 7.4628e-04 - val_loss: 3.9562e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 7.7703e-04 - val_loss: 2.7338e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.6907e-04 - val_loss: 1.7210e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.1736e-04 - val_loss: 1.8666e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.3489e-04 - val_loss: 2.4135e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 7.0871e-04 - val_loss: 3.4526e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.2851e-04 - val_loss: 1.4380e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 6.1323e-04 - val_loss: 1.3214e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.9144e-04 - val_loss: 1.2220e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 6.4450e-04 - val_loss: 1.1846e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 6.3842e-04 - val_loss: 1.4348e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 7.2160e-04 - val_loss: 1.2294e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 9.5920e-04 - val_loss: 1.4155e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 6.0058e-04 - val_loss: 1.6113e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.8000e-04 - val_loss: 1.3033e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.4130e-04 - val_loss: 1.3013e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 6.3855e-04 - val_loss: 2.0173e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 6.4536e-04 - val_loss: 1.2167e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.4965e-04 - val_loss: 1.5279e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 5.8312e-04 - val_loss: 3.7138e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.0510e-04 - val_loss: 2.2986e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 6.3753e-04 - val_loss: 1.3846e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 6.0039e-04 - val_loss: 1.0389e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.5216e-04 - val_loss: 2.0431e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 6.6999e-04 - val_loss: 1.5106e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 6.4715e-04 - val_loss: 1.6196e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.7908e-04 - val_loss: 1.0323e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.3571e-04 - val_loss: 1.0276e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.0003e-04 - val_loss: 1.8281e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.5666e-04 - val_loss: 1.0234e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 5.7069e-04 - val_loss: 1.0877e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 9s 35ms/step - loss: 5.8529e-04 - val_loss: 1.6976e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 9s 36ms/step - loss: 5.7102e-04 - val_loss: 1.5314e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 6.0728e-04 - val_loss: 3.5482e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 5.9452e-04 - val_loss: 1.1774e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.9277e-04 - val_loss: 1.5253e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 5.2604e-04 - val_loss: 1.2393e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 5.8618e-04 - val_loss: 1.4010e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 17s 63ms/step - loss: 6.0649e-04 - val_loss: 1.4459e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 5.3308e-04 - val_loss: 4.0254e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 5.5270e-04 - val_loss: 9.8998e-05\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 5.6780e-04 - val_loss: 1.3198e-04\n",
      "9/9 [==============================] - 3s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 947.3022114119542\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 31s 60ms/step - loss: 0.0093 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "  1/263 [..............................] - ETA: 18s - loss: 5.3516e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0051 - val_loss: 7.9264e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.0031 - val_loss: 5.6476e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 0.0020 - val_loss: 8.6673e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0016 - val_loss: 3.4255e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.0015 - val_loss: 3.7046e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 15s 55ms/step - loss: 0.0014 - val_loss: 2.4282e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0010 - val_loss: 3.4569e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 9.1475e-04 - val_loss: 4.6918e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 9.0382e-04 - val_loss: 6.6192e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 9.6949e-04 - val_loss: 1.6800e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.6073e-04 - val_loss: 2.8335e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.7166e-04 - val_loss: 2.0303e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 7.4313e-04 - val_loss: 5.0861e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.9297e-04 - val_loss: 1.4965e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 7.4674e-04 - val_loss: 4.7953e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.6444e-04 - val_loss: 3.2635e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.4984e-04 - val_loss: 1.1887e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 7.4050e-04 - val_loss: 1.1817e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 8.1452e-04 - val_loss: 2.0164e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 8.0085e-04 - val_loss: 1.0903e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 7.4472e-04 - val_loss: 1.8585e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 6.8751e-04 - val_loss: 1.0845e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 6.8836e-04 - val_loss: 1.0734e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.1251e-04 - val_loss: 1.9931e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.7400e-04 - val_loss: 1.6629e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.2644e-04 - val_loss: 1.3325e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.6041e-04 - val_loss: 1.1498e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.3113e-04 - val_loss: 1.0440e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.2149e-04 - val_loss: 1.3423e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.2203e-04 - val_loss: 1.6722e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.3611e-04 - val_loss: 1.7918e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.3208e-04 - val_loss: 2.7922e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 6.4677e-04 - val_loss: 2.7645e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.2584e-04 - val_loss: 9.4867e-05\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.9639e-04 - val_loss: 1.8380e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.5089e-04 - val_loss: 1.2448e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 5.6135e-04 - val_loss: 1.3260e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 5.9356e-04 - val_loss: 1.9566e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.5933e-04 - val_loss: 9.7996e-05\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.1703e-04 - val_loss: 1.1815e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 6.2954e-04 - val_loss: 2.4639e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.2374e-04 - val_loss: 2.4271e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 6.8356e-04 - val_loss: 1.4476e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 5.8521e-04 - val_loss: 2.2030e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 6.1379e-04 - val_loss: 3.3673e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 16s 63ms/step - loss: 6.4117e-04 - val_loss: 1.1044e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 7.0329e-04 - val_loss: 4.5104e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.4019e-04 - val_loss: 1.3931e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 7.1259e-04 - val_loss: 9.6914e-05\n",
      "9/9 [==============================] - 3s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 674.5037989615822\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 27s 64ms/step - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "  2/263 [..............................] - ETA: 13s - loss: 0.0055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0029 - val_loss: 8.0349e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0017 - val_loss: 4.1056e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.0017 - val_loss: 7.1329e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 9.7832e-04 - val_loss: 5.8604e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 8.7383e-04 - val_loss: 2.2980e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.8561e-04 - val_loss: 2.5725e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 8.5005e-04 - val_loss: 4.0933e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 7.7015e-04 - val_loss: 1.5457e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 5.9758e-04 - val_loss: 1.7690e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 7.6964e-04 - val_loss: 5.0421e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 8.6884e-04 - val_loss: 1.2800e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.5165e-04 - val_loss: 1.1794e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 5.7967e-04 - val_loss: 2.5191e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.0212e-04 - val_loss: 2.6051e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.4010e-04 - val_loss: 1.8885e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.6298e-04 - val_loss: 1.3992e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.1435e-04 - val_loss: 7.3976e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.7368e-04 - val_loss: 3.2041e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.0730e-04 - val_loss: 1.3013e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.9855e-04 - val_loss: 3.0807e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.4760e-04 - val_loss: 1.0876e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.3903e-04 - val_loss: 4.8473e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.5264e-04 - val_loss: 1.8638e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 15s 55ms/step - loss: 7.5440e-04 - val_loss: 1.0990e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 8.6852e-04 - val_loss: 5.9231e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.4981e-04 - val_loss: 1.3580e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 7.3858e-04 - val_loss: 1.0723e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.0280e-04 - val_loss: 6.0038e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 12s 48ms/step - loss: 6.1243e-04 - val_loss: 1.0056e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 15s 55ms/step - loss: 6.5014e-04 - val_loss: 1.1212e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 5.6470e-04 - val_loss: 9.3976e-05\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 6.0642e-04 - val_loss: 9.8123e-05\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 5.5801e-04 - val_loss: 1.2082e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 6.5613e-04 - val_loss: 9.8639e-05\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 5.8515e-04 - val_loss: 1.0690e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 15s 55ms/step - loss: 5.8018e-04 - val_loss: 1.8176e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0816e-04 - val_loss: 2.5645e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 6.2313e-04 - val_loss: 2.2944e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.9332e-04 - val_loss: 9.7719e-05\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 5.7270e-04 - val_loss: 1.8514e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 6.1092e-04 - val_loss: 1.0080e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 5.4915e-04 - val_loss: 1.5967e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.1541e-04 - val_loss: 1.1775e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.4366e-04 - val_loss: 1.0513e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 5.6847e-04 - val_loss: 1.3195e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.4549e-04 - val_loss: 1.5721e-04\n",
      "9/9 [==============================] - 3s 84ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 655.7679438763513\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 35s 78ms/step - loss: 0.0102 - val_loss: 0.0011\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 20s 74ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 19s 70ms/step - loss: 0.0029 - val_loss: 3.6507e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 0.0017 - val_loss: 3.4139e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.0014 - val_loss: 2.7789e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 0.0013 - val_loss: 1.9426e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 9.0878e-04 - val_loss: 4.4730e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 9.5063e-04 - val_loss: 2.0273e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.4889e-04 - val_loss: 1.4278e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 8.4864e-04 - val_loss: 2.4033e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 8.5193e-04 - val_loss: 1.6747e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 8.7691e-04 - val_loss: 1.1385e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 9.0785e-04 - val_loss: 2.2953e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 8.2041e-04 - val_loss: 1.1637e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.0011 - val_loss: 3.3797e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 19s 73ms/step - loss: 7.2748e-04 - val_loss: 2.5800e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 9.4653e-04 - val_loss: 1.4027e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 8.8827e-04 - val_loss: 1.3831e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 6.7582e-04 - val_loss: 9.8604e-05\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 5.9256e-04 - val_loss: 1.2649e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 5.7939e-04 - val_loss: 1.5658e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 7.0529e-04 - val_loss: 1.6435e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 16s 59ms/step - loss: 7.0023e-04 - val_loss: 3.2780e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 6.7971e-04 - val_loss: 1.6061e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.6329e-04 - val_loss: 1.1310e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 6.7381e-04 - val_loss: 4.0106e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 7.3828e-04 - val_loss: 1.5336e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 8.5206e-04 - val_loss: 3.3855e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 6.1045e-04 - val_loss: 1.3957e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 7.2833e-04 - val_loss: 1.0013e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.9620e-04 - val_loss: 1.0674e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 6.7051e-04 - val_loss: 2.2597e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.7972e-04 - val_loss: 1.2731e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 6.0387e-04 - val_loss: 6.3842e-04\n",
      "9/9 [==============================] - 4s 47ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 658.2745992730383\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 37s 90ms/step - loss: 0.0089 - val_loss: 7.7716e-04\n",
      "Epoch 2/50\n",
      "  1/263 [..............................] - ETA: 18s - loss: 0.0093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 23s 88ms/step - loss: 0.0028 - val_loss: 6.2494e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 0.0021 - val_loss: 6.0063e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.0019 - val_loss: 4.2360e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.0015 - val_loss: 9.3516e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 0.0013 - val_loss: 2.5630e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 26s 99ms/step - loss: 0.0010 - val_loss: 2.3260e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.0011 - val_loss: 2.4031e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 8.5586e-04 - val_loss: 1.7306e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 7.7905e-04 - val_loss: 5.9191e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.7984e-04 - val_loss: 4.3445e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 9.6118e-04 - val_loss: 3.5166e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 5.9948e-04 - val_loss: 1.5611e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 7.0572e-04 - val_loss: 1.3463e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 7.0751e-04 - val_loss: 4.1261e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 24s 90ms/step - loss: 7.1727e-04 - val_loss: 1.9512e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 7.5528e-04 - val_loss: 1.3571e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.4335e-04 - val_loss: 2.8065e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 7.2460e-04 - val_loss: 1.7485e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 19s 73ms/step - loss: 6.6996e-04 - val_loss: 1.2827e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.9582e-04 - val_loss: 1.7701e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 6.6967e-04 - val_loss: 1.3566e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 6.9175e-04 - val_loss: 4.7955e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 6.3034e-04 - val_loss: 1.3023e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 5.7845e-04 - val_loss: 1.4601e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 6.6182e-04 - val_loss: 1.2243e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.7311e-04 - val_loss: 1.2509e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 5.7919e-04 - val_loss: 1.9181e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 19s 73ms/step - loss: 6.9496e-04 - val_loss: 1.2437e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 6.2886e-04 - val_loss: 1.3929e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 6.4197e-04 - val_loss: 3.0536e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 5.7608e-04 - val_loss: 1.3099e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 6.1475e-04 - val_loss: 1.2088e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 5.8770e-04 - val_loss: 2.4339e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 6.4803e-04 - val_loss: 1.5173e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 6.0281e-04 - val_loss: 1.6333e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 5.5265e-04 - val_loss: 3.1426e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 5.6112e-04 - val_loss: 2.8682e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.5911e-04 - val_loss: 2.2274e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 5.8817e-04 - val_loss: 1.7357e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 6.1723e-04 - val_loss: 1.3799e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 5.4498e-04 - val_loss: 1.7047e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 5.6779e-04 - val_loss: 1.6961e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.0167e-04 - val_loss: 1.3306e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 5.2976e-04 - val_loss: 1.1629e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.0120e-04 - val_loss: 1.4418e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 19s 73ms/step - loss: 5.1826e-04 - val_loss: 1.1785e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.3955e-04 - val_loss: 1.7214e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 5.6333e-04 - val_loss: 1.1831e-04\n",
      "8/8 [==============================] - 3s 42ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 676.491914964014\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 47s 115ms/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 25s 96ms/step - loss: 0.0035 - val_loss: 9.9403e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 0.0027 - val_loss: 5.7307e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 0.0017 - val_loss: 8.8705e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 0.0018 - val_loss: 3.8188e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 0.0012 - val_loss: 3.6036e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 28s 106ms/step - loss: 9.9347e-04 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0012 - val_loss: 2.1117e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 8.6472e-04 - val_loss: 2.1670e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 7.8381e-04 - val_loss: 1.9580e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.8325e-04 - val_loss: 6.9002e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 9.4734e-04 - val_loss: 4.2195e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 6.9352e-04 - val_loss: 3.0369e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 7.4212e-04 - val_loss: 9.2997e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 8.6174e-04 - val_loss: 1.6575e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.8495e-04 - val_loss: 1.8143e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.1430e-04 - val_loss: 1.9013e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.9122e-04 - val_loss: 1.5812e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.6851e-04 - val_loss: 1.3864e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.1207e-04 - val_loss: 1.4601e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 40s 154ms/step - loss: 7.0787e-04 - val_loss: 1.3185e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 53s 200ms/step - loss: 6.8613e-04 - val_loss: 1.7863e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 81s 308ms/step - loss: 7.3514e-04 - val_loss: 1.2970e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 71s 271ms/step - loss: 6.2601e-04 - val_loss: 1.5513e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 6.9236e-04 - val_loss: 6.9883e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 6.6211e-04 - val_loss: 1.2181e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.2493e-04 - val_loss: 2.2184e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 6.0021e-04 - val_loss: 1.2415e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 6.0406e-04 - val_loss: 4.6353e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.1225e-04 - val_loss: 3.3197e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 6.2881e-04 - val_loss: 2.0906e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 6.1619e-04 - val_loss: 3.1613e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 6.8518e-04 - val_loss: 1.2655e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 35s 135ms/step - loss: 6.1162e-04 - val_loss: 1.6440e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 34s 127ms/step - loss: 6.2239e-04 - val_loss: 1.4239e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 5.9528e-04 - val_loss: 1.2818e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.1189e-04 - val_loss: 3.7767e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 32s 124ms/step - loss: 6.0364e-04 - val_loss: 1.1152e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 5.9220e-04 - val_loss: 1.9718e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 6.8475e-04 - val_loss: 2.8237e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.0104e-04 - val_loss: 2.4376e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 5.2883e-04 - val_loss: 1.6083e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 5.6561e-04 - val_loss: 1.7974e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 5.7872e-04 - val_loss: 1.4728e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 5.8434e-04 - val_loss: 1.3108e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 6.1552e-04 - val_loss: 1.4148e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 5.8730e-04 - val_loss: 1.8978e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 5.7210e-04 - val_loss: 1.5019e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 6.2181e-04 - val_loss: 1.2487e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.1534e-04 - val_loss: 1.3026e-04\n",
      "8/8 [==============================] - 5s 59ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 805.7078025252819\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 59s 149ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 42s 158ms/step - loss: 0.0028 - val_loss: 5.6219e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 71s 269ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 66s 252ms/step - loss: 0.0019 - val_loss: 4.8973e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0011 - val_loss: 2.2398e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 41s 156ms/step - loss: 9.1776e-04 - val_loss: 2.1611e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 0.0012 - val_loss: 1.7918e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 7.7017e-04 - val_loss: 4.1083e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 7.9367e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 9.3933e-04 - val_loss: 6.9401e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 7.5922e-04 - val_loss: 2.1440e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 37s 143ms/step - loss: 7.2583e-04 - val_loss: 9.8346e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 8.5914e-04 - val_loss: 3.9339e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 9.0468e-04 - val_loss: 9.4739e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 6.4979e-04 - val_loss: 1.2920e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 5.9166e-04 - val_loss: 1.8897e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 6.5439e-04 - val_loss: 1.4067e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 6.4690e-04 - val_loss: 2.1329e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 6.3359e-04 - val_loss: 1.9655e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 8.6635e-04 - val_loss: 2.3133e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 7.9540e-04 - val_loss: 1.3416e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 6.6769e-04 - val_loss: 1.2990e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 51s 193ms/step - loss: 6.1559e-04 - val_loss: 1.2475e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 41s 158ms/step - loss: 6.2948e-04 - val_loss: 1.4336e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 6.9594e-04 - val_loss: 1.2057e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 42s 162ms/step - loss: 6.8337e-04 - val_loss: 1.4292e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 6.5967e-04 - val_loss: 1.2370e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 6.7157e-04 - val_loss: 1.5578e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 7.5139e-04 - val_loss: 2.7709e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 5.9050e-04 - val_loss: 1.4280e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.1265e-04 - val_loss: 2.2601e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 41s 156ms/step - loss: 6.1329e-04 - val_loss: 4.4416e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 6.3616e-04 - val_loss: 1.4560e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 6.7588e-04 - val_loss: 1.8459e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 5.9148e-04 - val_loss: 4.4919e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 6.8656e-04 - val_loss: 1.1963e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 5.5687e-04 - val_loss: 1.5246e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 42s 158ms/step - loss: 6.5368e-04 - val_loss: 1.1388e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 41s 156ms/step - loss: 5.7850e-04 - val_loss: 1.8226e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 6.4771e-04 - val_loss: 3.0410e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 6.4765e-04 - val_loss: 3.8330e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 5.5783e-04 - val_loss: 1.1135e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 6.0242e-04 - val_loss: 1.3049e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 6.2135e-04 - val_loss: 2.4964e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 5.7851e-04 - val_loss: 1.6776e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 5.9827e-04 - val_loss: 4.8553e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 5.5629e-04 - val_loss: 1.1752e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 40s 150ms/step - loss: 6.3267e-04 - val_loss: 1.1567e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 5.5296e-04 - val_loss: 1.2175e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 5.5145e-04 - val_loss: 1.3935e-04\n",
      "8/8 [==============================] - 8s 100ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 741.108645534591\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 80s 181ms/step - loss: 0.0119 - val_loss: 0.0027\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 0.0032 - val_loss: 5.4232e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 0.0021 - val_loss: 5.8449e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 41s 156ms/step - loss: 0.0013 - val_loss: 3.3557e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0015 - val_loss: 9.8187e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0011 - val_loss: 2.5538e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 8.6150e-04 - val_loss: 4.7431e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 8.8129e-04 - val_loss: 1.8903e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 8.6646e-04 - val_loss: 1.9386e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.6572e-04 - val_loss: 1.5016e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 9.1332e-04 - val_loss: 2.4104e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 7.9375e-04 - val_loss: 2.3134e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 6.9883e-04 - val_loss: 1.4515e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 9.2542e-04 - val_loss: 1.4352e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 43s 165ms/step - loss: 7.5666e-04 - val_loss: 1.3694e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 6.6796e-04 - val_loss: 1.5019e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 6.0247e-04 - val_loss: 2.8211e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 6.4616e-04 - val_loss: 1.3111e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 8.2296e-04 - val_loss: 1.6294e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 6.9182e-04 - val_loss: 1.2535e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 7.7815e-04 - val_loss: 2.3746e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 7.7343e-04 - val_loss: 1.1481e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 7.4796e-04 - val_loss: 1.6856e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 7.3998e-04 - val_loss: 2.1212e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 6.6706e-04 - val_loss: 2.8336e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 6.6536e-04 - val_loss: 1.1118e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 5.3768e-04 - val_loss: 1.1969e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 7.0923e-04 - val_loss: 1.3364e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 6.6952e-04 - val_loss: 1.1978e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 6.1268e-04 - val_loss: 1.4436e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 6.0478e-04 - val_loss: 1.5679e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 47s 178ms/step - loss: 6.9667e-04 - val_loss: 6.5914e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 6.7242e-04 - val_loss: 3.3734e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.5695e-04 - val_loss: 1.1467e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 6.2317e-04 - val_loss: 1.2221e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 7.2240e-04 - val_loss: 2.5128e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 6.8792e-04 - val_loss: 1.9941e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 7.2297e-04 - val_loss: 1.4178e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 6.9775e-04 - val_loss: 1.3674e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 5.6626e-04 - val_loss: 1.4390e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 57s 216ms/step - loss: 5.7708e-04 - val_loss: 1.2970e-04\n",
      "8/8 [==============================] - 8s 95ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 719.6021348839267\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 64s 160ms/step - loss: 0.0067 - val_loss: 7.1842e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 34s 130ms/step - loss: 0.0025 - val_loss: 5.0856e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 0.0018 - val_loss: 9.2995e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 0.0014 - val_loss: 7.7729e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0012 - val_loss: 7.8332e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 0.0012 - val_loss: 2.8681e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 0.0010 - val_loss: 2.2527e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 36s 135ms/step - loss: 0.0012 - val_loss: 5.9284e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 8.4518e-04 - val_loss: 4.6073e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 8.2745e-04 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 7.4924e-04 - val_loss: 7.9198e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 6.9249e-04 - val_loss: 1.7390e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 6.5269e-04 - val_loss: 1.5459e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 6.9193e-04 - val_loss: 1.6715e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 5.5102e-04 - val_loss: 6.3040e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 7.0358e-04 - val_loss: 1.5535e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 35s 135ms/step - loss: 7.1443e-04 - val_loss: 4.2356e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 7.8563e-04 - val_loss: 2.1983e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 8.0320e-04 - val_loss: 1.4278e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 6.4807e-04 - val_loss: 1.3789e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 6.2934e-04 - val_loss: 2.2566e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.3892e-04 - val_loss: 1.2617e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 5.9226e-04 - val_loss: 1.3812e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.7685e-04 - val_loss: 2.0529e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.4026e-04 - val_loss: 2.3536e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.8486e-04 - val_loss: 2.9040e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 5.9416e-04 - val_loss: 1.3367e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 5.6988e-04 - val_loss: 2.8731e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 6.4852e-04 - val_loss: 1.5738e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.8158e-04 - val_loss: 2.1098e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 6.4910e-04 - val_loss: 1.5859e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 5.8903e-04 - val_loss: 2.5096e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 5.6252e-04 - val_loss: 1.6740e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 6.0078e-04 - val_loss: 2.8780e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.4134e-04 - val_loss: 2.2914e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 5.8277e-04 - val_loss: 3.8780e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 5.5435e-04 - val_loss: 1.7461e-04\n",
      "7/7 [==============================] - 6s 76ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 701.3365197432306\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 96s 228ms/step - loss: 0.0082 - val_loss: 0.0011\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 54s 205ms/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 59s 223ms/step - loss: 0.0016 - val_loss: 5.6080e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 56s 213ms/step - loss: 0.0015 - val_loss: 3.2470e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0014 - val_loss: 3.1228e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 45s 169ms/step - loss: 0.0012 - val_loss: 5.1201e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0012 - val_loss: 2.2919e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 8.4558e-04 - val_loss: 4.7149e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 44s 165ms/step - loss: 9.6983e-04 - val_loss: 3.7834e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 9.5738e-04 - val_loss: 7.0073e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 42s 158ms/step - loss: 8.4428e-04 - val_loss: 3.5121e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 9.6324e-04 - val_loss: 1.7142e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 7.6022e-04 - val_loss: 1.7864e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 7.4697e-04 - val_loss: 3.4213e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.1855e-04 - val_loss: 4.0467e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 47s 177ms/step - loss: 6.9541e-04 - val_loss: 1.9379e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 47s 178ms/step - loss: 7.7207e-04 - val_loss: 3.8197e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 41s 156ms/step - loss: 7.3762e-04 - val_loss: 1.5245e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 6.4416e-04 - val_loss: 1.7584e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 43s 165ms/step - loss: 7.3116e-04 - val_loss: 3.0158e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 7.1810e-04 - val_loss: 2.6205e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 8.5601e-04 - val_loss: 1.3148e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 54s 206ms/step - loss: 6.4297e-04 - val_loss: 1.4247e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 7.1403e-04 - val_loss: 1.4670e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 6.6328e-04 - val_loss: 1.6032e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 52s 197ms/step - loss: 6.0591e-04 - val_loss: 1.1941e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 8.0616e-04 - val_loss: 1.1029e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 6.8676e-04 - val_loss: 1.2092e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.4643e-04 - val_loss: 1.2358e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 6.3137e-04 - val_loss: 2.7320e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.3207e-04 - val_loss: 1.3217e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.3220e-04 - val_loss: 1.1786e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 5.5774e-04 - val_loss: 3.1207e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 6.9811e-04 - val_loss: 1.4376e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 5.8528e-04 - val_loss: 1.1489e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 5.4901e-04 - val_loss: 2.0138e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 6.1665e-04 - val_loss: 4.2665e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 5.7150e-04 - val_loss: 2.0892e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 6.6134e-04 - val_loss: 1.2233e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 5.9549e-04 - val_loss: 6.5967e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 5.7050e-04 - val_loss: 1.3426e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 5.6844e-04 - val_loss: 1.1919e-04\n",
      "7/7 [==============================] - 6s 73ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 715.692186694386\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 76s 213ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 0.0028 - val_loss: 3.6622e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 0.0014 - val_loss: 3.1015e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 0.0010 - val_loss: 2.0596e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 0.0010 - val_loss: 2.4582e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 8.1984e-04 - val_loss: 1.8173e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 0.0010 - val_loss: 5.3022e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 6.9153e-04 - val_loss: 1.4853e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 8.6974e-04 - val_loss: 7.9174e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.6500e-04 - val_loss: 1.5956e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.2537e-04 - val_loss: 4.3096e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 8.5565e-04 - val_loss: 2.6786e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.6998e-04 - val_loss: 2.8013e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 6.8368e-04 - val_loss: 1.3221e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.2748e-04 - val_loss: 1.4182e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.9940e-04 - val_loss: 2.8527e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.2855e-04 - val_loss: 1.3477e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.2097e-04 - val_loss: 1.5913e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 6.9319e-04 - val_loss: 1.3654e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 40s 151ms/step - loss: 7.3447e-04 - val_loss: 2.8372e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.1337e-04 - val_loss: 2.0565e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.4623e-04 - val_loss: 2.2277e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 6.6659e-04 - val_loss: 1.2571e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 39s 146ms/step - loss: 8.9204e-04 - val_loss: 1.1105e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 5.9549e-04 - val_loss: 1.6586e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.2878e-04 - val_loss: 3.3875e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 6.8703e-04 - val_loss: 2.9051e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.1045e-04 - val_loss: 1.3067e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 6.6950e-04 - val_loss: 4.4411e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 6.4727e-04 - val_loss: 2.2097e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 7.2118e-04 - val_loss: 2.3302e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.4747e-04 - val_loss: 1.1730e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 5.6564e-04 - val_loss: 1.1415e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.2402e-04 - val_loss: 1.4449e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 5.9992e-04 - val_loss: 4.3880e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 5.6989e-04 - val_loss: 1.4656e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 7.3078e-04 - val_loss: 3.9888e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.2276e-04 - val_loss: 1.4120e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 5.4330e-04 - val_loss: 1.3558e-04\n",
      "7/7 [==============================] - 4s 89ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 700.1169735624156\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 69s 194ms/step - loss: 0.0088 - val_loss: 9.5984e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0039 - val_loss: 5.7008e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 0.0016 - val_loss: 3.3554e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 9.5257e-04 - val_loss: 2.5623e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 50s 189ms/step - loss: 0.0011 - val_loss: 2.3264e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 51s 193ms/step - loss: 7.7668e-04 - val_loss: 3.6120e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 0.0011 - val_loss: 1.7134e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 6.4314e-04 - val_loss: 2.2215e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 0.0010 - val_loss: 2.4180e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 51s 195ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 52s 197ms/step - loss: 7.3707e-04 - val_loss: 7.0226e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 0.0010 - val_loss: 2.2164e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 6.5550e-04 - val_loss: 3.1233e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 52s 196ms/step - loss: 8.5614e-04 - val_loss: 1.8769e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 6.6764e-04 - val_loss: 1.4673e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 58s 222ms/step - loss: 7.9845e-04 - val_loss: 3.7225e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 61s 230ms/step - loss: 7.8195e-04 - val_loss: 1.8465e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 62s 236ms/step - loss: 7.6026e-04 - val_loss: 2.5198e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 7.1659e-04 - val_loss: 1.5706e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 53s 202ms/step - loss: 6.2772e-04 - val_loss: 2.2667e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 49s 188ms/step - loss: 7.3887e-04 - val_loss: 3.0444e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 6.9970e-04 - val_loss: 2.7604e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 51s 194ms/step - loss: 7.7501e-04 - val_loss: 1.3895e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 5.8156e-04 - val_loss: 1.8355e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 5.9360e-04 - val_loss: 2.0250e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 50s 192ms/step - loss: 7.1426e-04 - val_loss: 2.0486e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 6.5874e-04 - val_loss: 3.0103e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 49s 188ms/step - loss: 5.9378e-04 - val_loss: 1.4109e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 6.1481e-04 - val_loss: 3.7459e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 6.5451e-04 - val_loss: 1.3318e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 51s 194ms/step - loss: 6.8957e-04 - val_loss: 1.2841e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 6.0308e-04 - val_loss: 2.4282e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 50s 192ms/step - loss: 6.0927e-04 - val_loss: 7.0884e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 55s 210ms/step - loss: 6.1501e-04 - val_loss: 2.1247e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 51s 194ms/step - loss: 6.1756e-04 - val_loss: 2.0215e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 7.4643e-04 - val_loss: 1.2741e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 6.6126e-04 - val_loss: 1.2609e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 5.7757e-04 - val_loss: 5.0072e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 7.0117e-04 - val_loss: 1.5614e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 6.8599e-04 - val_loss: 1.2849e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 6.5662e-04 - val_loss: 1.5064e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 51s 193ms/step - loss: 6.0211e-04 - val_loss: 2.2960e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 52s 198ms/step - loss: 6.8007e-04 - val_loss: 3.2867e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 59s 223ms/step - loss: 5.7473e-04 - val_loss: 1.7992e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 57s 218ms/step - loss: 5.8465e-04 - val_loss: 4.7709e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 52s 200ms/step - loss: 6.5682e-04 - val_loss: 2.7123e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 6.2220e-04 - val_loss: 2.3840e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 60s 229ms/step - loss: 5.6651e-04 - val_loss: 1.3001e-04\n",
      "7/7 [==============================] - 9s 131ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 766.9055257359643\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 32s 90ms/step - loss: 0.0109 - val_loss: 7.8372e-04\n",
      "Epoch 2/50\n",
      "  1/132 [..............................] - ETA: 5s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0038 - val_loss: 6.8135e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0023 - val_loss: 7.3356e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 0.0020 - val_loss: 6.8609e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 0.0018 - val_loss: 3.8668e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 0.0014 - val_loss: 4.2551e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 0.0012 - val_loss: 4.6812e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0012 - val_loss: 3.3180e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0010 - val_loss: 4.4021e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 8.5400e-04 - val_loss: 2.0707e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.9772e-04 - val_loss: 5.5386e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.7860e-04 - val_loss: 1.7842e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 9.7615e-04 - val_loss: 4.9941e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.6120e-04 - val_loss: 2.8632e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 7.9060e-04 - val_loss: 3.2563e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 5.7934e-04 - val_loss: 1.4254e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 8.5017e-04 - val_loss: 1.5445e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 6.2107e-04 - val_loss: 1.6233e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 6.3323e-04 - val_loss: 1.6957e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 7.3555e-04 - val_loss: 1.2814e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 6.3289e-04 - val_loss: 2.8862e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 5.5539e-04 - val_loss: 1.2530e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.6537e-04 - val_loss: 4.6001e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.8534e-04 - val_loss: 1.2483e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 6.2220e-04 - val_loss: 2.3056e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.4515e-04 - val_loss: 1.9518e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 5.8710e-04 - val_loss: 1.1788e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 5.9236e-04 - val_loss: 2.1037e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 5.5521e-04 - val_loss: 1.4463e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 5.9767e-04 - val_loss: 1.3372e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.8487e-04 - val_loss: 1.7257e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.5217e-04 - val_loss: 7.0995e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 8s 60ms/step - loss: 6.1783e-04 - val_loss: 1.2044e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 5.5458e-04 - val_loss: 1.7110e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 5.6075e-04 - val_loss: 1.3603e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 5.5455e-04 - val_loss: 3.3125e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.8406e-04 - val_loss: 2.6208e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.2248e-04 - val_loss: 1.8589e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.2933e-04 - val_loss: 1.8114e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.3764e-04 - val_loss: 2.3379e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 4.9599e-04 - val_loss: 1.2404e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 5.5079e-04 - val_loss: 1.2784e-04\n",
      "9/9 [==============================] - 10s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 672.1835743238328\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 82s 139ms/step - loss: 0.0121 - val_loss: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 12s 89ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 9s 68ms/step - loss: 0.0026 - val_loss: 5.7108e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 9s 68ms/step - loss: 0.0018 - val_loss: 4.7975e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.0019 - val_loss: 4.5699e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0013 - val_loss: 4.1864e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 0.0013 - val_loss: 3.9905e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 9s 69ms/step - loss: 0.0012 - val_loss: 3.0707e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 0.0011 - val_loss: 2.7077e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 0.0011 - val_loss: 5.3615e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 9s 66ms/step - loss: 0.0011 - val_loss: 3.3553e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 8.7280e-04 - val_loss: 2.1943e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 8.8814e-04 - val_loss: 3.9313e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 8.3613e-04 - val_loss: 2.7030e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 9.1926e-04 - val_loss: 3.1303e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 9s 68ms/step - loss: 6.1319e-04 - val_loss: 1.8303e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.5156e-04 - val_loss: 3.7888e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 7.2175e-04 - val_loss: 7.8546e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 6.4199e-04 - val_loss: 3.0035e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 6.8346e-04 - val_loss: 2.0178e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 6.2347e-04 - val_loss: 2.0039e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 6.6392e-04 - val_loss: 1.8367e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 6.1862e-04 - val_loss: 1.6626e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 6.2904e-04 - val_loss: 1.6011e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 9.3282e-04 - val_loss: 2.6830e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 7.0403e-04 - val_loss: 4.5403e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 10s 72ms/step - loss: 6.4608e-04 - val_loss: 3.2956e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.4645e-04 - val_loss: 1.6641e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 6.2301e-04 - val_loss: 1.3692e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.6318e-04 - val_loss: 1.3045e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 7.2115e-04 - val_loss: 2.2404e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.5198e-04 - val_loss: 1.5722e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 7.1639e-04 - val_loss: 5.2241e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.1750e-04 - val_loss: 1.8203e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 7.3909e-04 - val_loss: 1.3109e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.1270e-04 - val_loss: 1.1810e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.5901e-04 - val_loss: 1.1896e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.7900e-04 - val_loss: 1.9600e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.8405e-04 - val_loss: 1.1384e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.3360e-04 - val_loss: 1.1578e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.5046e-04 - val_loss: 2.2722e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 5.3284e-04 - val_loss: 1.8266e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.9829e-04 - val_loss: 1.2825e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.9997e-04 - val_loss: 2.0820e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.5603e-04 - val_loss: 1.9804e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.4749e-04 - val_loss: 1.1110e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.8685e-04 - val_loss: 1.8380e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 6.0192e-04 - val_loss: 1.1473e-04\n",
      "9/9 [==============================] - 10s 37ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 689.5568206767537\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 45s 122ms/step - loss: 0.0095 - val_loss: 9.1457e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0029 - val_loss: 9.3694e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.0025 - val_loss: 5.9522e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.0020 - val_loss: 7.2797e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0014 - val_loss: 4.0796e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0012 - val_loss: 3.9161e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.0011 - val_loss: 2.1820e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 9.8497e-04 - val_loss: 2.0047e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 8.3917e-04 - val_loss: 1.8132e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 8.3471e-04 - val_loss: 2.7424e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.3725e-04 - val_loss: 2.8284e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 7.9179e-04 - val_loss: 1.5516e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 6.5978e-04 - val_loss: 1.5216e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 10s 72ms/step - loss: 7.7686e-04 - val_loss: 2.0801e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 7.5566e-04 - val_loss: 1.6877e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 7.0041e-04 - val_loss: 1.3078e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 6.1370e-04 - val_loss: 4.9604e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 6.9662e-04 - val_loss: 1.6975e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.2178e-04 - val_loss: 3.3608e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 6.9684e-04 - val_loss: 1.7551e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 6.7567e-04 - val_loss: 1.9354e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.5584e-04 - val_loss: 1.8410e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 6.4469e-04 - val_loss: 3.3383e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.8138e-04 - val_loss: 2.5550e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 6.4007e-04 - val_loss: 1.6247e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.5001e-04 - val_loss: 4.3437e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 7.0726e-04 - val_loss: 1.1712e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 5.7184e-04 - val_loss: 2.0922e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 5.3328e-04 - val_loss: 1.7690e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.6362e-04 - val_loss: 2.0575e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.4963e-04 - val_loss: 1.6385e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 5.4810e-04 - val_loss: 1.1763e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 6.0086e-04 - val_loss: 3.1096e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 7.1274e-04 - val_loss: 1.2329e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 5.8423e-04 - val_loss: 1.8146e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.9034e-04 - val_loss: 1.9173e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.6640e-04 - val_loss: 1.6293e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.1085e-04 - val_loss: 1.1555e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 5.2963e-04 - val_loss: 1.2785e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 5.4574e-04 - val_loss: 2.9453e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 5.8614e-04 - val_loss: 2.7876e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 6.6133e-04 - val_loss: 1.0411e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.4443e-04 - val_loss: 2.2061e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 5.7978e-04 - val_loss: 1.8638e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 6.1246e-04 - val_loss: 1.1290e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.2012e-04 - val_loss: 2.1839e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 5.1079e-04 - val_loss: 1.2224e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 5.1654e-04 - val_loss: 1.1687e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 5.9250e-04 - val_loss: 1.2342e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 5.8167e-04 - val_loss: 1.0346e-04\n",
      "9/9 [==============================] - 5s 35ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 655.5508132384374\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 43s 132ms/step - loss: 0.0132 - val_loss: 0.0022\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.0044 - val_loss: 7.0730e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.0023 - val_loss: 6.8344e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0020 - val_loss: 4.6572e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0016 - val_loss: 3.4843e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0013 - val_loss: 2.9931e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0011 - val_loss: 2.9718e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0013 - val_loss: 4.3167e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 9.8382e-04 - val_loss: 2.7478e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 8.0019e-04 - val_loss: 2.9823e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 7.7725e-04 - val_loss: 1.6838e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 8.0312e-04 - val_loss: 2.0454e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 7.1558e-04 - val_loss: 1.9599e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 7.2878e-04 - val_loss: 1.4646e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 5.4769e-04 - val_loss: 2.1010e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 7.1547e-04 - val_loss: 1.7942e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 6.9185e-04 - val_loss: 1.4583e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.2196e-04 - val_loss: 1.4187e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.8899e-04 - val_loss: 1.4305e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 6.1306e-04 - val_loss: 2.7015e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 9.5135e-04 - val_loss: 3.6025e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.1944e-04 - val_loss: 1.3541e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 7.0282e-04 - val_loss: 4.7631e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 7.6242e-04 - val_loss: 1.3366e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 5.7154e-04 - val_loss: 1.2696e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 6.2483e-04 - val_loss: 1.2431e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.1907e-04 - val_loss: 2.8023e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.5516e-04 - val_loss: 1.5702e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 6.2512e-04 - val_loss: 1.3890e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 5.4272e-04 - val_loss: 1.7871e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 7.0255e-04 - val_loss: 1.4475e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 7.1711e-04 - val_loss: 1.3951e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 5.2984e-04 - val_loss: 1.4513e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.5542e-04 - val_loss: 1.1345e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.6592e-04 - val_loss: 1.6469e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.4822e-04 - val_loss: 2.3601e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.7476e-04 - val_loss: 1.1686e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 7.6413e-04 - val_loss: 1.7058e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 5.5417e-04 - val_loss: 1.1108e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 6.1043e-04 - val_loss: 1.2979e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 6.9072e-04 - val_loss: 1.6214e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 6.2523e-04 - val_loss: 1.2016e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.0654e-04 - val_loss: 1.0337e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.2636e-04 - val_loss: 1.2525e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 8.5959e-04 - val_loss: 2.0084e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 5.4819e-04 - val_loss: 1.0388e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.1075e-04 - val_loss: 1.9630e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.3807e-04 - val_loss: 1.0509e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 6.4915e-04 - val_loss: 1.0038e-04\n",
      "9/9 [==============================] - 7s 50ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 701.0558783517782\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 41s 137ms/step - loss: 0.0112 - val_loss: 0.0017\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 18s 135ms/step - loss: 0.0032 - val_loss: 8.5246e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 0.0026 - val_loss: 6.8198e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 0.0021 - val_loss: 5.0777e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0016 - val_loss: 6.0753e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0015 - val_loss: 5.1314e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0013 - val_loss: 3.5951e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 0.0010 - val_loss: 3.4061e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 0.0013 - val_loss: 3.7882e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 8.4552e-04 - val_loss: 4.0594e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 7.5990e-04 - val_loss: 2.3915e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 8.5882e-04 - val_loss: 2.3537e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 12s 95ms/step - loss: 8.0323e-04 - val_loss: 3.3754e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.7581e-04 - val_loss: 1.9903e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 6.2770e-04 - val_loss: 3.4608e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.5356e-04 - val_loss: 5.1992e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 6.5217e-04 - val_loss: 1.8315e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 7.4309e-04 - val_loss: 3.6093e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 6.5820e-04 - val_loss: 1.7211e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 6.2563e-04 - val_loss: 5.4593e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.1861e-04 - val_loss: 1.5048e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 6.8658e-04 - val_loss: 1.6579e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 6.6494e-04 - val_loss: 1.5417e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 6.4760e-04 - val_loss: 1.6860e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 6.0020e-04 - val_loss: 2.2831e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 6.2410e-04 - val_loss: 8.4028e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 6.6688e-04 - val_loss: 1.4949e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.9599e-04 - val_loss: 4.0944e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 5.9113e-04 - val_loss: 2.2569e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.4178e-04 - val_loss: 1.8614e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.7557e-04 - val_loss: 3.4074e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.5831e-04 - val_loss: 4.2652e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.1372e-04 - val_loss: 1.4503e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.1621e-04 - val_loss: 1.5128e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.1042e-04 - val_loss: 1.4249e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 7.0317e-04 - val_loss: 2.1673e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.5995e-04 - val_loss: 2.4940e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 6.0875e-04 - val_loss: 1.4266e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 5.3404e-04 - val_loss: 1.3502e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 7.3835e-04 - val_loss: 2.2053e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.7226e-04 - val_loss: 1.5453e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 5.1164e-04 - val_loss: 1.3432e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 5.5972e-04 - val_loss: 2.9519e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.7844e-04 - val_loss: 1.3540e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 5.8548e-04 - val_loss: 2.3185e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 5.8769e-04 - val_loss: 1.5512e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 5.3058e-04 - val_loss: 1.4413e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 6.0910e-04 - val_loss: 4.7602e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.8471e-04 - val_loss: 3.0856e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 5.6118e-04 - val_loss: 2.0403e-04\n",
      "8/8 [==============================] - 4s 40ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 908.688481758473\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 43s 155ms/step - loss: 0.0112 - val_loss: 0.0012\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0029 - val_loss: 6.5561e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0020 - val_loss: 5.9919e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0023 - val_loss: 6.0170e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0016 - val_loss: 5.0614e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0018 - val_loss: 5.8701e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0012 - val_loss: 6.9988e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0011 - val_loss: 3.7833e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 9.1693e-04 - val_loss: 3.9661e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 9.1937e-04 - val_loss: 3.3089e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.7857e-04 - val_loss: 3.0251e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.9774e-04 - val_loss: 3.0071e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 8.3752e-04 - val_loss: 2.3213e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 7.2084e-04 - val_loss: 2.7856e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 7.3041e-04 - val_loss: 2.9816e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 8.5673e-04 - val_loss: 7.9151e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 6.9480e-04 - val_loss: 1.9233e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.4851e-04 - val_loss: 2.1189e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.9151e-04 - val_loss: 1.8106e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.2773e-04 - val_loss: 1.8928e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.1040e-04 - val_loss: 2.5219e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 8.5709e-04 - val_loss: 2.3087e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.5093e-04 - val_loss: 1.9993e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.3317e-04 - val_loss: 1.6697e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.6604e-04 - val_loss: 2.0536e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 6.8534e-04 - val_loss: 1.9632e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 6.4665e-04 - val_loss: 1.9581e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 6.3319e-04 - val_loss: 5.3947e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.4458e-04 - val_loss: 2.2634e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.2977e-04 - val_loss: 1.6830e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.7405e-04 - val_loss: 2.9062e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.4623e-04 - val_loss: 1.5298e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 8.0918e-04 - val_loss: 2.8364e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 5.8821e-04 - val_loss: 2.6744e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 5.3508e-04 - val_loss: 1.5015e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.6866e-04 - val_loss: 1.5821e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.3112e-04 - val_loss: 1.8316e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 6.0367e-04 - val_loss: 2.6665e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 5.5336e-04 - val_loss: 1.3822e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 5.9550e-04 - val_loss: 1.9045e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 6.8438e-04 - val_loss: 1.3503e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 6.4264e-04 - val_loss: 1.8180e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.4956e-04 - val_loss: 2.2774e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.2698e-04 - val_loss: 1.4763e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.0631e-04 - val_loss: 2.4823e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.3767e-04 - val_loss: 1.4442e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.0026e-04 - val_loss: 1.3608e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.4934e-04 - val_loss: 1.7997e-04\n",
      "8/8 [==============================] - 4s 49ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 874.8506547046675\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 33s 140ms/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "  1/132 [..............................] - ETA: 14s - loss: 0.0083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 15s 112ms/step - loss: 0.0022 - val_loss: 7.9588e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 0.0016 - val_loss: 4.5151e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 0.0013 - val_loss: 4.0911e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0012 - val_loss: 2.2485e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 0.0014 - val_loss: 2.6904e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 9.0304e-04 - val_loss: 5.8327e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 7.3320e-04 - val_loss: 1.6848e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 9.0258e-04 - val_loss: 2.3201e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 24s 183ms/step - loss: 6.4329e-04 - val_loss: 2.1321e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 7.0235e-04 - val_loss: 2.9334e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.0383e-04 - val_loss: 2.4712e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.5407e-04 - val_loss: 4.0175e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 8.2007e-04 - val_loss: 9.6056e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 7.9206e-04 - val_loss: 1.3845e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 5.4734e-04 - val_loss: 3.2324e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 6.6437e-04 - val_loss: 1.6866e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 6.1282e-04 - val_loss: 1.5220e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 6.6167e-04 - val_loss: 1.7433e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 9.5338e-04 - val_loss: 2.0935e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 5.3885e-04 - val_loss: 2.7137e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 6.3582e-04 - val_loss: 1.7126e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 9.4651e-04 - val_loss: 6.8844e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 7.3862e-04 - val_loss: 2.7413e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 17s 126ms/step - loss: 6.2402e-04 - val_loss: 1.5226e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.9816e-04 - val_loss: 1.3140e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 24s 185ms/step - loss: 6.2366e-04 - val_loss: 1.4889e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 5.9086e-04 - val_loss: 1.4250e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 5.8742e-04 - val_loss: 1.5678e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.4388e-04 - val_loss: 2.4820e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 6.0287e-04 - val_loss: 2.9282e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 7.0486e-04 - val_loss: 1.7648e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.7594e-04 - val_loss: 1.1977e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.4043e-04 - val_loss: 4.1347e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 25s 186ms/step - loss: 6.2336e-04 - val_loss: 1.4121e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 6.9278e-04 - val_loss: 1.5886e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 6.3420e-04 - val_loss: 1.6848e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 5.5561e-04 - val_loss: 1.4010e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 24s 184ms/step - loss: 5.7558e-04 - val_loss: 4.3068e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 6.2701e-04 - val_loss: 1.3981e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 5.6508e-04 - val_loss: 1.4268e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 5.6428e-04 - val_loss: 1.3939e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 5.4892e-04 - val_loss: 1.2645e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 24s 181ms/step - loss: 5.6768e-04 - val_loss: 1.7139e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 5.9207e-04 - val_loss: 1.4632e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 5.3861e-04 - val_loss: 3.7610e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 5.7521e-04 - val_loss: 1.5813e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 5.2807e-04 - val_loss: 1.3261e-04\n",
      "8/8 [==============================] - 8s 101ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 656.556306581163\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 66s 249ms/step - loss: 0.0154 - val_loss: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 24s 185ms/step - loss: 0.0041 - val_loss: 9.6024e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 25s 190ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0032 - val_loss: 7.2868e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 27s 201ms/step - loss: 0.0022 - val_loss: 5.7193e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 28s 212ms/step - loss: 0.0022 - val_loss: 5.0646e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0016 - val_loss: 4.8237e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 28s 212ms/step - loss: 0.0013 - val_loss: 7.8913e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 26s 200ms/step - loss: 0.0012 - val_loss: 3.9906e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.0012 - val_loss: 6.1005e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 27s 205ms/step - loss: 0.0011 - val_loss: 8.0293e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 8.8870e-04 - val_loss: 2.9721e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 28s 212ms/step - loss: 8.3229e-04 - val_loss: 1.9642e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 8.0678e-04 - val_loss: 5.3625e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 7.0540e-04 - val_loss: 2.5305e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 0.0015 - val_loss: 2.0463e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.6976e-04 - val_loss: 2.1514e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 6.2615e-04 - val_loss: 4.1115e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 8.7159e-04 - val_loss: 2.5894e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 7.3007e-04 - val_loss: 1.8634e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 7.6955e-04 - val_loss: 5.7540e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 7.8113e-04 - val_loss: 1.5574e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 5.9352e-04 - val_loss: 1.6554e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 25s 185ms/step - loss: 5.4017e-04 - val_loss: 3.0499e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 7.8478e-04 - val_loss: 3.9940e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.6160e-04 - val_loss: 1.5776e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 7.9604e-04 - val_loss: 2.9244e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.7612e-04 - val_loss: 1.9072e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 24s 181ms/step - loss: 7.6379e-04 - val_loss: 1.6270e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 25s 189ms/step - loss: 6.3391e-04 - val_loss: 1.6556e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 27s 203ms/step - loss: 6.5115e-04 - val_loss: 1.7878e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 27s 202ms/step - loss: 5.5958e-04 - val_loss: 1.6010e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 26s 200ms/step - loss: 6.6031e-04 - val_loss: 1.6938e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 27s 202ms/step - loss: 6.4375e-04 - val_loss: 1.6713e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 25s 187ms/step - loss: 5.8225e-04 - val_loss: 3.1228e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 24s 184ms/step - loss: 5.4571e-04 - val_loss: 2.0152e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 24s 185ms/step - loss: 5.3851e-04 - val_loss: 2.2595e-04\n",
      "8/8 [==============================] - 9s 136ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 1064.4170861259977\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 54s 194ms/step - loss: 0.0100 - val_loss: 0.0020\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0034 - val_loss: 6.3047e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 0.0020 - val_loss: 9.2775e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0017 - val_loss: 5.3043e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 0.0013 - val_loss: 3.6995e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 0.0013 - val_loss: 3.1574e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 0.0011 - val_loss: 4.5188e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 8.8709e-04 - val_loss: 2.9682e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 8.9337e-04 - val_loss: 3.2981e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.6261e-04 - val_loss: 5.7563e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 9.1779e-04 - val_loss: 2.2793e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.8517e-04 - val_loss: 1.7057e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 7.1489e-04 - val_loss: 1.7538e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 8.2283e-04 - val_loss: 1.9668e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.3534e-04 - val_loss: 1.5697e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.0115e-04 - val_loss: 1.5824e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 7.5089e-04 - val_loss: 1.6482e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.2657e-04 - val_loss: 1.5522e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 7.1129e-04 - val_loss: 1.8878e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.4034e-04 - val_loss: 1.5405e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.0605e-04 - val_loss: 2.8601e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.9994e-04 - val_loss: 1.4025e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 6.4109e-04 - val_loss: 1.6002e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.4746e-04 - val_loss: 1.8063e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 6.2261e-04 - val_loss: 1.5191e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.6997e-04 - val_loss: 6.2268e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 6.9330e-04 - val_loss: 4.3376e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.9607e-04 - val_loss: 1.5489e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.8877e-04 - val_loss: 2.8439e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 6.5785e-04 - val_loss: 3.1093e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 5.3984e-04 - val_loss: 1.8927e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.5321e-04 - val_loss: 8.0519e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.4403e-04 - val_loss: 1.8710e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 5.8799e-04 - val_loss: 2.0552e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 5.3707e-04 - val_loss: 2.2468e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 5.3563e-04 - val_loss: 2.9570e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 17s 126ms/step - loss: 6.9730e-04 - val_loss: 1.2827e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 17s 127ms/step - loss: 6.4049e-04 - val_loss: 1.8480e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 7.0166e-04 - val_loss: 1.4299e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 5.8148e-04 - val_loss: 1.3994e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.2901e-04 - val_loss: 1.4743e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 6.3174e-04 - val_loss: 1.7454e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.5111e-04 - val_loss: 1.4183e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.6323e-04 - val_loss: 1.2818e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 5.5270e-04 - val_loss: 2.5142e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.6943e-04 - val_loss: 3.5718e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 5.4592e-04 - val_loss: 3.1528e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 5.7332e-04 - val_loss: 1.5444e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 5.1270e-04 - val_loss: 1.2193e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.1500e-04 - val_loss: 3.7150e-04\n",
      "7/7 [==============================] - 4s 60ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 1228.10627648693\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 51s 210ms/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 22s 169ms/step - loss: 0.0040 - val_loss: 9.1282e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 0.0030 - val_loss: 7.1288e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 24s 181ms/step - loss: 0.0025 - val_loss: 7.2313e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 0.0021 - val_loss: 8.2748e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 0.0019 - val_loss: 6.6798e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 24s 183ms/step - loss: 0.0012 - val_loss: 3.5383e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 0.0011 - val_loss: 8.0700e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 9.1372e-04 - val_loss: 7.0817e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 9.7406e-04 - val_loss: 2.2629e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 8.8798e-04 - val_loss: 2.2916e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 6.9092e-04 - val_loss: 1.8617e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 6.7476e-04 - val_loss: 1.9027e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 8.5152e-04 - val_loss: 3.7640e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 7.1211e-04 - val_loss: 2.0455e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 7.3131e-04 - val_loss: 5.4547e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 7.6190e-04 - val_loss: 4.0742e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 8.1646e-04 - val_loss: 3.4443e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 6.5471e-04 - val_loss: 1.7142e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 6.1067e-04 - val_loss: 1.5963e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 7.7033e-04 - val_loss: 3.7997e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 28s 212ms/step - loss: 7.3835e-04 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 27s 204ms/step - loss: 6.5382e-04 - val_loss: 3.6326e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 28s 210ms/step - loss: 7.2837e-04 - val_loss: 1.9685e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 6.6136e-04 - val_loss: 4.4431e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 28s 212ms/step - loss: 6.3878e-04 - val_loss: 1.6830e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 28s 208ms/step - loss: 7.4734e-04 - val_loss: 3.0750e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 28s 211ms/step - loss: 6.3729e-04 - val_loss: 4.8102e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 6.4224e-04 - val_loss: 1.5564e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 8.1729e-04 - val_loss: 1.6450e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 6.4154e-04 - val_loss: 1.5179e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 5.9528e-04 - val_loss: 1.5988e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 32s 239ms/step - loss: 5.9045e-04 - val_loss: 1.4909e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 33s 249ms/step - loss: 7.4946e-04 - val_loss: 1.4726e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 32s 245ms/step - loss: 6.0115e-04 - val_loss: 2.3895e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 33s 250ms/step - loss: 6.8635e-04 - val_loss: 1.4492e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 5.6371e-04 - val_loss: 1.4417e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 6.4616e-04 - val_loss: 1.7858e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 6.3738e-04 - val_loss: 4.8386e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 6.0100e-04 - val_loss: 1.2904e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 36s 273ms/step - loss: 5.6303e-04 - val_loss: 5.3559e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 32s 242ms/step - loss: 6.5928e-04 - val_loss: 1.5187e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 30s 228ms/step - loss: 5.8665e-04 - val_loss: 2.0883e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 5.5263e-04 - val_loss: 1.4823e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 5.3359e-04 - val_loss: 1.8376e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 6.0187e-04 - val_loss: 7.7800e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 7.2865e-04 - val_loss: 2.6538e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 22s 163ms/step - loss: 5.6030e-04 - val_loss: 1.6754e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 21s 163ms/step - loss: 5.9426e-04 - val_loss: 1.5824e-04\n",
      "7/7 [==============================] - 6s 66ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 891.7350772264024\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 43s 190ms/step - loss: 0.0090 - val_loss: 0.0012\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 21s 159ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 0.0021 - val_loss: 5.5599e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 0.0020 - val_loss: 4.0277e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 0.0019 - val_loss: 4.4076e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 0.0013 - val_loss: 3.0395e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 0.0012 - val_loss: 2.8860e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 0.0010 - val_loss: 3.2476e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 0.0014 - val_loss: 2.2212e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 9.2268e-04 - val_loss: 2.0510e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 8.7131e-04 - val_loss: 2.6632e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 6.7118e-04 - val_loss: 1.7190e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 6.3968e-04 - val_loss: 1.5465e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.8228e-04 - val_loss: 1.7785e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 6.5926e-04 - val_loss: 1.5449e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.9096e-04 - val_loss: 1.9680e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 5.6005e-04 - val_loss: 3.4097e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.9392e-04 - val_loss: 2.1082e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.3137e-04 - val_loss: 1.6705e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.8486e-04 - val_loss: 2.5927e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 6.0988e-04 - val_loss: 1.4548e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 7.0966e-04 - val_loss: 4.3779e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 9.0009e-04 - val_loss: 7.8078e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 8.8932e-04 - val_loss: 1.5552e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.6873e-04 - val_loss: 4.1111e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 6.7756e-04 - val_loss: 1.5224e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 6.1609e-04 - val_loss: 1.5804e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 5.1481e-04 - val_loss: 1.8790e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 5.2799e-04 - val_loss: 1.7159e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.4013e-04 - val_loss: 1.2120e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 6.2424e-04 - val_loss: 1.7486e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.9254e-04 - val_loss: 1.3840e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.5834e-04 - val_loss: 1.4219e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 6.1153e-04 - val_loss: 3.3955e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.9135e-04 - val_loss: 2.5168e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.2224e-04 - val_loss: 2.2819e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.8175e-04 - val_loss: 4.7871e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.6909e-04 - val_loss: 1.2469e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.8647e-04 - val_loss: 1.7858e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.0707e-04 - val_loss: 1.6687e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.0794e-04 - val_loss: 1.3152e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.9951e-04 - val_loss: 1.2865e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 4.8710e-04 - val_loss: 1.2228e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.1293e-04 - val_loss: 4.7644e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.0060e-04 - val_loss: 1.8945e-04\n",
      "7/7 [==============================] - 4s 92ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 768.7744006413043\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 50s 221ms/step - loss: 0.0169 - val_loss: 0.0011\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 25s 187ms/step - loss: 0.0050 - val_loss: 7.9187e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 24s 184ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 25s 187ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 26s 200ms/step - loss: 0.0022 - val_loss: 6.9872e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 0.0020 - val_loss: 5.1038e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 0.0016 - val_loss: 4.6364e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 0.0014 - val_loss: 3.2442e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 0.0013 - val_loss: 3.2704e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 9.8888e-04 - val_loss: 3.2855e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 7.6158e-04 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 8.2613e-04 - val_loss: 3.8130e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 8.4122e-04 - val_loss: 3.4981e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 8.7401e-04 - val_loss: 1.8155e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.7672e-04 - val_loss: 2.6753e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 6.4844e-04 - val_loss: 2.5901e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 7.6385e-04 - val_loss: 1.9276e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 25s 190ms/step - loss: 6.9283e-04 - val_loss: 1.7180e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 24s 185ms/step - loss: 7.0122e-04 - val_loss: 1.8456e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 6.2306e-04 - val_loss: 1.9297e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 8.0925e-04 - val_loss: 2.2325e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 7.4372e-04 - val_loss: 1.9818e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 5.8356e-04 - val_loss: 1.7191e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.2267e-04 - val_loss: 2.6409e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 7.0541e-04 - val_loss: 2.5593e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 7.2079e-04 - val_loss: 4.5927e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 7.4305e-04 - val_loss: 6.9325e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.8962e-04 - val_loss: 2.4630e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 8.0470e-04 - val_loss: 2.2384e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 6.7260e-04 - val_loss: 1.6112e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 5.7071e-04 - val_loss: 1.4167e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 25s 189ms/step - loss: 7.9701e-04 - val_loss: 1.8459e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 6.0323e-04 - val_loss: 1.3605e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.7278e-04 - val_loss: 2.1242e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 6.1427e-04 - val_loss: 1.3280e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 5.8793e-04 - val_loss: 1.3516e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 6.7002e-04 - val_loss: 2.3616e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 6.5064e-04 - val_loss: 1.2208e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 6.1656e-04 - val_loss: 1.7756e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 6.5520e-04 - val_loss: 1.2580e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 6.2372e-04 - val_loss: 1.6472e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.1635e-04 - val_loss: 1.5124e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 6.1035e-04 - val_loss: 1.8520e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 5.9234e-04 - val_loss: 5.4309e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 23s 178ms/step - loss: 5.6310e-04 - val_loss: 1.4938e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 5.1355e-04 - val_loss: 1.7388e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 5.6541e-04 - val_loss: 4.4113e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 6.0501e-04 - val_loss: 1.8267e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 5.4247e-04 - val_loss: 1.5216e-04\n",
      "7/7 [==============================] - 5s 100ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 812.0921267636497\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 32s 49ms/step - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 9s - loss: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0034 - val_loss: 9.2699e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.0016 - val_loss: 2.9338e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0015 - val_loss: 8.5208e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 0.0012 - val_loss: 2.8843e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 9.5975e-04 - val_loss: 1.6082e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.3233e-04 - val_loss: 2.5845e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.9259e-04 - val_loss: 5.0557e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 8.9292e-04 - val_loss: 1.5068e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 7.4907e-04 - val_loss: 1.4759e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 7.6454e-04 - val_loss: 1.7281e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 8.4892e-04 - val_loss: 1.2833e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.6242e-04 - val_loss: 1.3182e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.7825e-04 - val_loss: 1.3845e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.6213e-04 - val_loss: 1.1915e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.8036e-04 - val_loss: 1.5118e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.3071e-04 - val_loss: 1.3434e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.0083e-04 - val_loss: 1.2743e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.7706e-04 - val_loss: 1.1288e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.4877e-04 - val_loss: 1.3465e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.9381e-04 - val_loss: 1.1195e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.7091e-04 - val_loss: 1.0803e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.0075e-04 - val_loss: 6.0487e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.2515e-04 - val_loss: 1.2804e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.4009e-04 - val_loss: 1.0443e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.2414e-04 - val_loss: 1.6183e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.3008e-04 - val_loss: 3.6567e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.8979e-04 - val_loss: 6.7473e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.8842e-04 - val_loss: 1.1944e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.9553e-04 - val_loss: 1.7440e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.4082e-04 - val_loss: 1.4272e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.9287e-04 - val_loss: 2.5752e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.5459e-04 - val_loss: 1.0654e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.2499e-04 - val_loss: 9.9820e-05\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.8418e-04 - val_loss: 1.1029e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 5.6738e-04 - val_loss: 2.8846e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 5.7321e-04 - val_loss: 1.6922e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.7347e-04 - val_loss: 1.6872e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.1572e-04 - val_loss: 2.7051e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.3423e-04 - val_loss: 1.0050e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.1843e-04 - val_loss: 2.8703e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.7318e-04 - val_loss: 9.6393e-05\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.8692e-04 - val_loss: 1.2379e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.9560e-04 - val_loss: 2.6635e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.7750e-04 - val_loss: 9.9193e-05\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.7612e-04 - val_loss: 5.2788e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.4681e-04 - val_loss: 1.0659e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.6012e-04 - val_loss: 2.0389e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.7913e-04 - val_loss: 1.7485e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.2029e-04 - val_loss: 2.9827e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 5.3540e-04 - val_loss: 2.0963e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 5.5151e-04 - val_loss: 2.9815e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.3291e-04 - val_loss: 9.7759e-05\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.6135e-04 - val_loss: 1.0526e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.3486e-04 - val_loss: 2.5963e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.2232e-04 - val_loss: 1.1386e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 5.1670e-04 - val_loss: 1.2772e-04\n",
      "9/9 [==============================] - 3s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 668.2466915919753\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 33s 63ms/step - loss: 0.0109 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 12s - loss: 0.0072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0033 - val_loss: 5.8688e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0022 - val_loss: 4.8671e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0019 - val_loss: 5.7582e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0015 - val_loss: 3.6953e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0014 - val_loss: 2.8220e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 9.1294e-04 - val_loss: 2.3906e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 8.4688e-04 - val_loss: 2.5753e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 8.1779e-04 - val_loss: 9.0856e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.7891e-04 - val_loss: 2.3900e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 7.7548e-04 - val_loss: 1.9875e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 9.4239e-04 - val_loss: 1.5360e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 9.8161e-04 - val_loss: 2.7757e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 7.6873e-04 - val_loss: 5.3669e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 9.6458e-04 - val_loss: 2.5217e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.7997e-04 - val_loss: 1.3201e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.9979e-04 - val_loss: 1.4466e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 8.9294e-04 - val_loss: 2.5940e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.8250e-04 - val_loss: 3.1228e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.9463e-04 - val_loss: 3.8794e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.4747e-04 - val_loss: 1.3743e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 7.0179e-04 - val_loss: 1.5407e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.1501e-04 - val_loss: 1.7752e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 7.5899e-04 - val_loss: 1.9398e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 7.3291e-04 - val_loss: 2.6803e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.9567e-04 - val_loss: 1.2227e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.7122e-04 - val_loss: 2.2840e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.8812e-04 - val_loss: 1.0432e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.8746e-04 - val_loss: 1.2417e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 6.4697e-04 - val_loss: 9.9433e-05\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.9618e-04 - val_loss: 1.3004e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.1244e-04 - val_loss: 1.3612e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.2056e-04 - val_loss: 1.1928e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 6.8578e-04 - val_loss: 1.2309e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.9255e-04 - val_loss: 2.4672e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.0295e-04 - val_loss: 1.5511e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.4835e-04 - val_loss: 1.9824e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 5.6848e-04 - val_loss: 1.0122e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 6.2656e-04 - val_loss: 2.0434e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 5.8756e-04 - val_loss: 1.0349e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 15s 55ms/step - loss: 6.0026e-04 - val_loss: 1.6829e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 7.3068e-04 - val_loss: 2.0679e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 5.8605e-04 - val_loss: 1.1001e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.7633e-04 - val_loss: 1.3827e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.7072e-04 - val_loss: 1.4833e-04\n",
      "9/9 [==============================] - 5s 25ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 676.7898352903787\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 34s 68ms/step - loss: 0.0061 - val_loss: 5.2489e-04\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 11s - loss: 0.0022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0027 - val_loss: 5.9288e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0017 - val_loss: 6.4541e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 0.0017 - val_loss: 2.7089e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0011 - val_loss: 3.9141e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 9.4727e-04 - val_loss: 2.8190e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 7.7535e-04 - val_loss: 3.5960e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 7.1176e-04 - val_loss: 2.4741e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 6.5938e-04 - val_loss: 1.2197e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.2622e-04 - val_loss: 2.0528e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 9.0178e-04 - val_loss: 3.7768e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.6279e-04 - val_loss: 2.4043e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 7.4153e-04 - val_loss: 1.2721e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.6907e-04 - val_loss: 1.1024e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 8.1977e-04 - val_loss: 1.7043e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.5421e-04 - val_loss: 1.4948e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 7.2904e-04 - val_loss: 2.7118e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 8.1647e-04 - val_loss: 1.0420e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 7.0377e-04 - val_loss: 2.9910e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 7.7200e-04 - val_loss: 1.0653e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.5144e-04 - val_loss: 1.0672e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.9950e-04 - val_loss: 1.3210e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.6218e-04 - val_loss: 1.2837e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.3388e-04 - val_loss: 1.1280e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.9974e-04 - val_loss: 1.0089e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.1453e-04 - val_loss: 1.1250e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.6180e-04 - val_loss: 3.9035e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.8039e-04 - val_loss: 1.6830e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.8711e-04 - val_loss: 2.3538e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.3343e-04 - val_loss: 1.3074e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4563e-04 - val_loss: 3.3374e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.2281e-04 - val_loss: 1.5914e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.5049e-04 - val_loss: 1.7729e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.7718e-04 - val_loss: 1.3440e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0040e-04 - val_loss: 9.9468e-05\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 7.1757e-04 - val_loss: 2.7249e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0438e-04 - val_loss: 1.2263e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 6.1272e-04 - val_loss: 1.2541e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.7394e-04 - val_loss: 1.3554e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.1003e-04 - val_loss: 1.3278e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0612e-04 - val_loss: 1.0341e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 6.0667e-04 - val_loss: 1.1642e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.6764e-04 - val_loss: 1.1549e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.3907e-04 - val_loss: 1.2255e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 6.4694e-04 - val_loss: 2.8078e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 5.8658e-04 - val_loss: 1.0174e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 6.5915e-04 - val_loss: 1.1622e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0828e-04 - val_loss: 1.3198e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 5.8305e-04 - val_loss: 1.0084e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 6.5786e-04 - val_loss: 1.2209e-04\n",
      "9/9 [==============================] - 4s 33ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 726.0525650726\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 43s 84ms/step - loss: 0.0111 - val_loss: 0.0010\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 17s - loss: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 19s 72ms/step - loss: 0.0032 - val_loss: 6.8911e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 0.0028 - val_loss: 4.1158e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 0.0019 - val_loss: 3.1775e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 0.0014 - val_loss: 3.0069e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 0.0015 - val_loss: 5.5573e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 0.0011 - val_loss: 4.9056e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 8.8446e-04 - val_loss: 1.7670e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 0.0012 - val_loss: 2.0635e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.6034e-04 - val_loss: 1.8819e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 0.0011 - val_loss: 4.6221e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.0042e-04 - val_loss: 1.6167e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 7.1472e-04 - val_loss: 2.0448e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 9.7546e-04 - val_loss: 2.7363e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.8449e-04 - val_loss: 1.5114e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.9403e-04 - val_loss: 1.4081e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.8483e-04 - val_loss: 1.3274e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.7480e-04 - val_loss: 1.1025e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 8.0319e-04 - val_loss: 1.2389e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 6.2907e-04 - val_loss: 9.9781e-05\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.5834e-04 - val_loss: 1.0571e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 7.5131e-04 - val_loss: 9.9000e-05\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 8.7139e-04 - val_loss: 2.9344e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 6.7464e-04 - val_loss: 1.1310e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 8.5727e-04 - val_loss: 2.8649e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.2503e-04 - val_loss: 2.9922e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.9146e-04 - val_loss: 7.1792e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.1339e-04 - val_loss: 9.4146e-05\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.9376e-04 - val_loss: 1.0829e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.7458e-04 - val_loss: 1.2707e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.2896e-04 - val_loss: 1.0080e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 8.7722e-04 - val_loss: 1.2772e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 5.8523e-04 - val_loss: 1.0266e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 6.1047e-04 - val_loss: 1.0043e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 5.8603e-04 - val_loss: 1.4582e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 7.1047e-04 - val_loss: 1.1456e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.2551e-04 - val_loss: 2.9206e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 7.0581e-04 - val_loss: 1.0397e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 6.9382e-04 - val_loss: 1.8925e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 6.5421e-04 - val_loss: 9.8141e-05\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 5.8913e-04 - val_loss: 1.5399e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.4929e-04 - val_loss: 2.9360e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.6612e-04 - val_loss: 1.7696e-04\n",
      "9/9 [==============================] - 3s 30ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 693.3447571122656\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 36s 89ms/step - loss: 0.0067 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 18s - loss: 0.0063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 21s 78ms/step - loss: 0.0028 - val_loss: 7.6363e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.0016 - val_loss: 8.6546e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.0015 - val_loss: 2.5086e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.0010 - val_loss: 6.1406e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 7.8404e-04 - val_loss: 2.5509e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 9.0863e-04 - val_loss: 4.7224e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 8.1219e-04 - val_loss: 3.3958e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.5494e-04 - val_loss: 1.4154e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 6.9928e-04 - val_loss: 1.6810e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 9.2395e-04 - val_loss: 2.0851e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 7.7365e-04 - val_loss: 2.0584e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 8.5049e-04 - val_loss: 3.0867e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 7.0178e-04 - val_loss: 1.3116e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 7.0323e-04 - val_loss: 8.5018e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 6.6123e-04 - val_loss: 1.3973e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.6033e-04 - val_loss: 1.3651e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 6.4182e-04 - val_loss: 1.3874e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.6088e-04 - val_loss: 1.6395e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 5.6359e-04 - val_loss: 1.2705e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.4152e-04 - val_loss: 2.1821e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 6.8618e-04 - val_loss: 1.4414e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 7.7027e-04 - val_loss: 9.6299e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.6327e-04 - val_loss: 1.7454e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 6.5477e-04 - val_loss: 1.7198e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 5.5196e-04 - val_loss: 1.2423e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 6.0981e-04 - val_loss: 1.1994e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 6.2260e-04 - val_loss: 1.3742e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.7532e-04 - val_loss: 8.0478e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.3901e-04 - val_loss: 1.7842e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.4608e-04 - val_loss: 1.2905e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.5681e-04 - val_loss: 1.5776e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.2841e-04 - val_loss: 3.8819e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.4589e-04 - val_loss: 3.4875e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.0775e-04 - val_loss: 1.1496e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.5156e-04 - val_loss: 3.8703e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 8.0698e-04 - val_loss: 4.4437e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.0484e-04 - val_loss: 1.9199e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.5135e-04 - val_loss: 2.8371e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 5.5711e-04 - val_loss: 1.4619e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.0772e-04 - val_loss: 1.6935e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.6078e-04 - val_loss: 1.8254e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.2292e-04 - val_loss: 3.5075e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.5158e-04 - val_loss: 1.1709e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.3791e-04 - val_loss: 2.5562e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.1218e-04 - val_loss: 1.1653e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.3106e-04 - val_loss: 1.9227e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.7763e-04 - val_loss: 1.3894e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 5.3603e-04 - val_loss: 1.5132e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 5.7601e-04 - val_loss: 2.1761e-04\n",
      "8/8 [==============================] - 3s 39ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 850.9188391203899\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 54s 119ms/step - loss: 0.0095 - val_loss: 0.0018\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 27s 105ms/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0020 - val_loss: 9.3248e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0018 - val_loss: 8.4254e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0013 - val_loss: 6.3655e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0012 - val_loss: 2.9701e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0010 - val_loss: 5.7645e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.6247e-04 - val_loss: 2.4350e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.6758e-04 - val_loss: 1.8632e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 0.0011 - val_loss: 2.1240e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 9.1295e-04 - val_loss: 4.9438e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 8.0064e-04 - val_loss: 4.2177e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.7745e-04 - val_loss: 2.3373e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 24s 93ms/step - loss: 7.8501e-04 - val_loss: 3.0300e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 6.8680e-04 - val_loss: 1.6511e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.5303e-04 - val_loss: 2.2683e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.6853e-04 - val_loss: 1.7272e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 8.1768e-04 - val_loss: 5.1833e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 8.8354e-04 - val_loss: 1.7207e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.8654e-04 - val_loss: 2.0236e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.9360e-04 - val_loss: 2.8241e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.3761e-04 - val_loss: 1.3531e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.7637e-04 - val_loss: 3.8482e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.2903e-04 - val_loss: 1.4115e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.3163e-04 - val_loss: 4.4127e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.4621e-04 - val_loss: 1.6612e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 31s 120ms/step - loss: 6.4771e-04 - val_loss: 1.3329e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.9625e-04 - val_loss: 3.7566e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 6.4895e-04 - val_loss: 1.2894e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.8309e-04 - val_loss: 1.1585e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.6682e-04 - val_loss: 1.3009e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.4274e-04 - val_loss: 1.6413e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.9887e-04 - val_loss: 1.1788e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.7343e-04 - val_loss: 2.5565e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.8210e-04 - val_loss: 1.1321e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.9764e-04 - val_loss: 1.3269e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.7396e-04 - val_loss: 1.2005e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 6.1218e-04 - val_loss: 2.2053e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 5.3941e-04 - val_loss: 6.8712e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 28s 106ms/step - loss: 6.5643e-04 - val_loss: 2.1193e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.9973e-04 - val_loss: 3.5990e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.4291e-04 - val_loss: 1.4622e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 5.6938e-04 - val_loss: 1.1542e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 6.0396e-04 - val_loss: 5.7500e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.9166e-04 - val_loss: 1.3586e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.9131e-04 - val_loss: 1.1122e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.8512e-04 - val_loss: 5.9655e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 5.8986e-04 - val_loss: 1.4382e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 7.5807e-04 - val_loss: 1.1384e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.9134e-04 - val_loss: 1.2613e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 5.9853e-04 - val_loss: 3.0451e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.2118e-04 - val_loss: 2.3987e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.3909e-04 - val_loss: 1.1498e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.8491e-04 - val_loss: 1.3957e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.4716e-04 - val_loss: 1.8236e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 6.1224e-04 - val_loss: 1.3138e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.8658e-04 - val_loss: 1.2434e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.7146e-04 - val_loss: 1.2007e-04\n",
      "Epoch 60/100\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 5.7316e-04 - val_loss: 1.1375e-04\n",
      "Epoch 61/100\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 6.1201e-04 - val_loss: 1.8354e-04\n",
      "Epoch 62/100\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 5.5222e-04 - val_loss: 1.4420e-04\n",
      "8/8 [==============================] - 4s 46ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 682.4998176254697\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 41s 108ms/step - loss: 0.0071 - val_loss: 7.2899e-04\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 24s - loss: 1.4346e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 26s 98ms/step - loss: 0.0022 - val_loss: 7.4209e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 0.0020 - val_loss: 3.7225e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 0.0017 - val_loss: 4.7947e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 9.7252e-04 - val_loss: 2.3689e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 0.0010 - val_loss: 4.4086e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.8474e-04 - val_loss: 3.4272e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 0.0011 - val_loss: 2.8217e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 8.1942e-04 - val_loss: 2.4705e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 9.0789e-04 - val_loss: 1.4816e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.0431e-04 - val_loss: 2.4366e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 7.7835e-04 - val_loss: 2.3312e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 7.8083e-04 - val_loss: 2.1932e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 8.6694e-04 - val_loss: 1.3813e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.9787e-04 - val_loss: 3.1931e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.0678e-04 - val_loss: 1.4671e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.0319e-04 - val_loss: 2.6768e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 7.3971e-04 - val_loss: 8.0665e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.3699e-04 - val_loss: 2.5144e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 8.0689e-04 - val_loss: 1.3461e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 8.1584e-04 - val_loss: 1.8895e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.4385e-04 - val_loss: 2.4023e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 7.1395e-04 - val_loss: 2.3735e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.8297e-04 - val_loss: 2.5786e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.2905e-04 - val_loss: 1.6674e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.8521e-04 - val_loss: 1.3265e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.0861e-04 - val_loss: 1.4009e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.0702e-04 - val_loss: 1.3768e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.0416e-04 - val_loss: 1.1938e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.6759e-04 - val_loss: 2.8530e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.7880e-04 - val_loss: 1.3550e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.3077e-04 - val_loss: 1.2232e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 6.0191e-04 - val_loss: 6.6904e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 24s 92ms/step - loss: 7.5401e-04 - val_loss: 1.3827e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 6.1015e-04 - val_loss: 2.3723e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.6444e-04 - val_loss: 1.4774e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.6467e-04 - val_loss: 4.2123e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.9302e-04 - val_loss: 1.1079e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.3663e-04 - val_loss: 1.6754e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 5.8653e-04 - val_loss: 1.2763e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.5780e-04 - val_loss: 2.5743e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.7997e-04 - val_loss: 3.3622e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.4708e-04 - val_loss: 1.2960e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.9215e-04 - val_loss: 1.7341e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 5.3395e-04 - val_loss: 1.7978e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.7549e-04 - val_loss: 1.5612e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.8777e-04 - val_loss: 1.6718e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.6195e-04 - val_loss: 5.7094e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.7779e-04 - val_loss: 1.3326e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.4876e-04 - val_loss: 1.8876e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 5.5438e-04 - val_loss: 2.9343e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 5.6346e-04 - val_loss: 1.6545e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 5.9457e-04 - val_loss: 2.1606e-04\n",
      "8/8 [==============================] - 3s 71ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 771.3469459810814\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 54s 139ms/step - loss: 0.0075 - val_loss: 9.6480e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 32s 124ms/step - loss: 0.0039 - val_loss: 6.5942e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0020 - val_loss: 4.2814e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0018 - val_loss: 9.4176e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0014 - val_loss: 2.4033e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 0.0011 - val_loss: 9.5986e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 0.0010 - val_loss: 1.9392e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.5152e-04 - val_loss: 4.1578e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0011 - val_loss: 2.1642e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.8504e-04 - val_loss: 1.3075e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.3269e-04 - val_loss: 3.8876e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.3052e-04 - val_loss: 1.4700e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 8.1554e-04 - val_loss: 8.1502e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.6464e-04 - val_loss: 2.4179e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.3068e-04 - val_loss: 1.5870e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.0892e-04 - val_loss: 2.8519e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 32s 124ms/step - loss: 6.8901e-04 - val_loss: 1.3343e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 8.1903e-04 - val_loss: 3.0496e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 7.0647e-04 - val_loss: 1.3302e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.5860e-04 - val_loss: 1.6535e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 7.4287e-04 - val_loss: 4.3101e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 7.2506e-04 - val_loss: 4.1960e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 8.2162e-04 - val_loss: 2.6443e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 7.1303e-04 - val_loss: 1.2720e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 36s 135ms/step - loss: 7.2526e-04 - val_loss: 4.0678e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.9795e-04 - val_loss: 2.3998e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.4085e-04 - val_loss: 1.4406e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 8.3189e-04 - val_loss: 1.4919e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.7747e-04 - val_loss: 1.1113e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.8973e-04 - val_loss: 1.2864e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.2794e-04 - val_loss: 1.5801e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.2519e-04 - val_loss: 4.0871e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.5474e-04 - val_loss: 1.4259e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 6.4405e-04 - val_loss: 1.2008e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.2798e-04 - val_loss: 1.6594e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.3366e-04 - val_loss: 1.1887e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.6796e-04 - val_loss: 2.1143e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.3006e-04 - val_loss: 1.1282e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.7754e-04 - val_loss: 1.3851e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 7.4101e-04 - val_loss: 1.8155e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 6.9267e-04 - val_loss: 1.3898e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 7.1805e-04 - val_loss: 1.9868e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.0840e-04 - val_loss: 1.3459e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 6.3346e-04 - val_loss: 2.9948e-04\n",
      "8/8 [==============================] - 6s 82ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 793.9433698231912\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 51s 128ms/step - loss: 0.0094 - val_loss: 0.0033\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 30s 113ms/step - loss: 0.0026 - val_loss: 5.3700e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 0.0024 - val_loss: 6.0561e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 0.0017 - val_loss: 4.3000e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 0.0014 - val_loss: 6.3718e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 0.0011 - val_loss: 3.2939e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 0.0011 - val_loss: 2.6370e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 9.6806e-04 - val_loss: 2.2321e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 8.3662e-04 - val_loss: 3.1879e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 8.6095e-04 - val_loss: 3.1198e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 8.5861e-04 - val_loss: 1.7543e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 8.4694e-04 - val_loss: 1.8478e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 6.9687e-04 - val_loss: 1.6621e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.9477e-04 - val_loss: 3.0849e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 6.8113e-04 - val_loss: 1.5293e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 6.4151e-04 - val_loss: 1.9565e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 6.4364e-04 - val_loss: 1.4411e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 28s 106ms/step - loss: 7.2648e-04 - val_loss: 1.4573e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 6.4554e-04 - val_loss: 1.4248e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 6.7652e-04 - val_loss: 1.6613e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.9628e-04 - val_loss: 2.3226e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.9282e-04 - val_loss: 9.5841e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.7529e-04 - val_loss: 2.8221e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.7393e-04 - val_loss: 1.3127e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 6.2548e-04 - val_loss: 1.2711e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.5290e-04 - val_loss: 1.6335e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.8058e-04 - val_loss: 4.7317e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 7.0032e-04 - val_loss: 1.2169e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.4814e-04 - val_loss: 1.3269e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.3285e-04 - val_loss: 1.3886e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.6677e-04 - val_loss: 4.7678e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.1920e-04 - val_loss: 3.5463e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.9223e-04 - val_loss: 3.0074e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.5267e-04 - val_loss: 2.3373e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.5191e-04 - val_loss: 1.1671e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.2351e-04 - val_loss: 1.2406e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.4677e-04 - val_loss: 1.3278e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.9398e-04 - val_loss: 1.8111e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.7002e-04 - val_loss: 1.6425e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.5442e-04 - val_loss: 1.4831e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.4364e-04 - val_loss: 1.4039e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 5.3300e-04 - val_loss: 1.9281e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.7374e-04 - val_loss: 1.1561e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.2147e-04 - val_loss: 1.3576e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.7034e-04 - val_loss: 2.3688e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.6103e-04 - val_loss: 1.1055e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.2113e-04 - val_loss: 1.1992e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 5.4961e-04 - val_loss: 1.2741e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 5.3241e-04 - val_loss: 1.1718e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 5.7791e-04 - val_loss: 2.4462e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.2731e-04 - val_loss: 1.4011e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.8676e-04 - val_loss: 2.5978e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 5.1358e-04 - val_loss: 1.1780e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 5.7203e-04 - val_loss: 3.9883e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.3676e-04 - val_loss: 1.2784e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.6927e-04 - val_loss: 1.1800e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.7038e-04 - val_loss: 1.2711e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.3952e-04 - val_loss: 1.3293e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.3187e-04 - val_loss: 1.5069e-04\n",
      "Epoch 60/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 5.0975e-04 - val_loss: 2.0355e-04\n",
      "Epoch 61/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 5.6573e-04 - val_loss: 1.2234e-04\n",
      "7/7 [==============================] - 4s 53ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 700.5737490176481\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 65s 167ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 39s 149ms/step - loss: 0.0052 - val_loss: 9.1785e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 0.0022 - val_loss: 5.0472e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 0.0021 - val_loss: 6.4328e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 0.0014 - val_loss: 4.1329e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 0.0012 - val_loss: 4.2962e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.8987e-04 - val_loss: 2.2749e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.7444e-04 - val_loss: 2.1340e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 9.4533e-04 - val_loss: 3.1429e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 8.3221e-04 - val_loss: 3.5709e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.6283e-04 - val_loss: 2.8575e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.5089e-04 - val_loss: 2.4206e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 7.4671e-04 - val_loss: 1.6689e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.6870e-04 - val_loss: 1.7437e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.5251e-04 - val_loss: 1.7772e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.1661e-04 - val_loss: 4.7133e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 8.6867e-04 - val_loss: 1.6342e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.2052e-04 - val_loss: 3.1137e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 7.9228e-04 - val_loss: 1.6280e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.7240e-04 - val_loss: 2.7634e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 7.8396e-04 - val_loss: 1.6681e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 6.4194e-04 - val_loss: 1.4648e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 7.2245e-04 - val_loss: 2.0576e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.1099e-04 - val_loss: 1.5928e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.8387e-04 - val_loss: 1.6241e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 8.1565e-04 - val_loss: 2.1543e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.1422e-04 - val_loss: 1.2334e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.1484e-04 - val_loss: 4.9415e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.3210e-04 - val_loss: 3.6231e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.0068e-04 - val_loss: 1.7082e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.7759e-04 - val_loss: 1.2295e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 6.8652e-04 - val_loss: 1.5188e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0210e-04 - val_loss: 2.2403e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.8060e-04 - val_loss: 2.7754e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.7104e-04 - val_loss: 2.1754e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 6.2678e-04 - val_loss: 1.1406e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 5.9682e-04 - val_loss: 1.5032e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 5.6036e-04 - val_loss: 2.8794e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0076e-04 - val_loss: 1.1911e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 7.0529e-04 - val_loss: 2.7336e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 6.2458e-04 - val_loss: 1.2505e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.3881e-04 - val_loss: 2.7780e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.3025e-04 - val_loss: 2.7272e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.6736e-04 - val_loss: 1.3191e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 6.2234e-04 - val_loss: 4.0260e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.7666e-04 - val_loss: 1.8686e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.9628e-04 - val_loss: 1.1231e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0536e-04 - val_loss: 1.2269e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 5.3396e-04 - val_loss: 1.1321e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.1360e-04 - val_loss: 1.8194e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0968e-04 - val_loss: 1.6051e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 7.2584e-04 - val_loss: 3.4547e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.4926e-04 - val_loss: 1.1710e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.8052e-04 - val_loss: 2.1636e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.4685e-04 - val_loss: 4.4378e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0944e-04 - val_loss: 2.5130e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.4859e-04 - val_loss: 1.0961e-04\n",
      "Epoch 60/100\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 5.4518e-04 - val_loss: 2.1251e-04\n",
      "Epoch 61/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.6598e-04 - val_loss: 3.0330e-04\n",
      "Epoch 62/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.9383e-04 - val_loss: 1.7953e-04\n",
      "Epoch 63/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.4850e-04 - val_loss: 3.5250e-04\n",
      "Epoch 64/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.2711e-04 - val_loss: 1.2152e-04\n",
      "Epoch 65/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.9109e-04 - val_loss: 3.4301e-04\n",
      "Epoch 66/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.7341e-04 - val_loss: 1.2351e-04\n",
      "Epoch 67/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.5668e-04 - val_loss: 1.2768e-04\n",
      "Epoch 68/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.8755e-04 - val_loss: 3.6524e-04\n",
      "Epoch 69/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 5.4941e-04 - val_loss: 2.1348e-04\n",
      "Epoch 70/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.1911e-04 - val_loss: 1.2775e-04\n",
      "Epoch 71/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.1443e-04 - val_loss: 1.1456e-04\n",
      "Epoch 72/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.7275e-04 - val_loss: 3.0220e-04\n",
      "Epoch 73/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 5.7467e-04 - val_loss: 1.1486e-04\n",
      "Epoch 74/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 5.3055e-04 - val_loss: 1.4076e-04\n",
      "7/7 [==============================] - 4s 65ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 682.2736711895725\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 58s 139ms/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 33s 127ms/step - loss: 0.0022 - val_loss: 4.5757e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 0.0016 - val_loss: 5.5112e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 0.0010 - val_loss: 8.4128e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 0.0011 - val_loss: 2.1765e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 8.3255e-04 - val_loss: 1.5968e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 9.0232e-04 - val_loss: 3.1395e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 7.4365e-04 - val_loss: 3.0802e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.8248e-04 - val_loss: 1.4075e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 7.1487e-04 - val_loss: 1.4311e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.2592e-04 - val_loss: 2.0805e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.2416e-04 - val_loss: 2.0792e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.3489e-04 - val_loss: 1.3593e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 7.9776e-04 - val_loss: 1.1880e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 9.3449e-04 - val_loss: 1.4218e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 6.3839e-04 - val_loss: 2.0763e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.6027e-04 - val_loss: 1.4613e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 8.3040e-04 - val_loss: 5.8677e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.9814e-04 - val_loss: 1.2245e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 8.0205e-04 - val_loss: 1.4668e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.1959e-04 - val_loss: 2.4922e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 7.8709e-04 - val_loss: 1.2685e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.7257e-04 - val_loss: 1.1302e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.4342e-04 - val_loss: 1.2448e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.8818e-04 - val_loss: 1.3351e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 5.7647e-04 - val_loss: 1.4362e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.4404e-04 - val_loss: 2.4229e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.2656e-04 - val_loss: 1.2479e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.7062e-04 - val_loss: 2.0042e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 5.5741e-04 - val_loss: 1.2509e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 5.8870e-04 - val_loss: 1.3769e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.0898e-04 - val_loss: 1.7147e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.5817e-04 - val_loss: 4.3031e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.2915e-04 - val_loss: 1.8571e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 5.4410e-04 - val_loss: 1.4897e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.1729e-04 - val_loss: 1.2912e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.7827e-04 - val_loss: 1.4217e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 5.7526e-04 - val_loss: 3.4844e-04\n",
      "7/7 [==============================] - 4s 93ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 690.6325962352221\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 77s 220ms/step - loss: 0.0166 - val_loss: 9.6283e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 49s 185ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 0.0031 - val_loss: 6.7500e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 0.0031 - val_loss: 9.8459e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 0.0018 - val_loss: 4.9742e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 0.0017 - val_loss: 4.2114e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 0.0014 - val_loss: 5.1348e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 0.0016 - val_loss: 4.7230e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 9.0326e-04 - val_loss: 5.8297e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 50s 191ms/step - loss: 8.9243e-04 - val_loss: 1.8448e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.7847e-04 - val_loss: 2.6180e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 9.5007e-04 - val_loss: 4.1758e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 7.2112e-04 - val_loss: 1.5834e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 9.1918e-04 - val_loss: 2.8488e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 6.7756e-04 - val_loss: 3.6934e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.0666e-04 - val_loss: 1.7434e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 6.7503e-04 - val_loss: 1.3779e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 49s 188ms/step - loss: 7.1411e-04 - val_loss: 2.9011e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 7.0706e-04 - val_loss: 1.7217e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 8.8054e-04 - val_loss: 1.3642e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 8.0102e-04 - val_loss: 2.0250e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.3926e-04 - val_loss: 1.5115e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 8.1569e-04 - val_loss: 2.8213e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 7.2742e-04 - val_loss: 4.1956e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 9.4142e-04 - val_loss: 1.7375e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 6.9931e-04 - val_loss: 1.8425e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 8.2146e-04 - val_loss: 1.3899e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.2515e-04 - val_loss: 1.3452e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 7.0288e-04 - val_loss: 2.0353e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 6.3875e-04 - val_loss: 1.3565e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 5.9610e-04 - val_loss: 1.5842e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 7.4498e-04 - val_loss: 1.6394e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 5.8040e-04 - val_loss: 1.4638e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 6.1048e-04 - val_loss: 2.5606e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.8595e-04 - val_loss: 1.9948e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 6.0515e-04 - val_loss: 5.3227e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.1242e-04 - val_loss: 1.6716e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 6.5728e-04 - val_loss: 2.2865e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 7.0576e-04 - val_loss: 1.2066e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.2438e-04 - val_loss: 2.8984e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 48s 181ms/step - loss: 7.2913e-04 - val_loss: 1.2284e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 6.7037e-04 - val_loss: 2.6345e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.1353e-04 - val_loss: 2.2802e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 5.5016e-04 - val_loss: 4.3356e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 6.6934e-04 - val_loss: 1.5074e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 5.7059e-04 - val_loss: 1.1933e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 5.5135e-04 - val_loss: 1.4830e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 7.4706e-04 - val_loss: 2.0223e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 6.0019e-04 - val_loss: 1.1327e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 5.6110e-04 - val_loss: 1.6805e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 5.7519e-04 - val_loss: 3.4509e-04\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 50s 188ms/step - loss: 5.5101e-04 - val_loss: 4.3869e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 5.6605e-04 - val_loss: 1.6794e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 5.9879e-04 - val_loss: 1.1751e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 6.2767e-04 - val_loss: 2.3043e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 6.3859e-04 - val_loss: 1.2786e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 5.9385e-04 - val_loss: 2.5698e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 44s 165ms/step - loss: 5.6508e-04 - val_loss: 1.2721e-04\n",
      "Epoch 60/100\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 6.0390e-04 - val_loss: 1.2472e-04\n",
      "Epoch 61/100\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 5.5235e-04 - val_loss: 1.2194e-04\n",
      "Epoch 62/100\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 5.9308e-04 - val_loss: 1.4355e-04\n",
      "Epoch 63/100\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 5.8925e-04 - val_loss: 1.1699e-04\n",
      "Epoch 64/100\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 6.2990e-04 - val_loss: 3.7390e-04\n",
      "Epoch 65/100\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 5.9505e-04 - val_loss: 1.4755e-04\n",
      "7/7 [==============================] - 5s 105ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 674.0056046546372\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 17s 52ms/step - loss: 0.0117 - val_loss: 8.0178e-04\n",
      "Epoch 2/100\n",
      "  1/132 [..............................] - ETA: 4s - loss: 0.0027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 5s 37ms/step - loss: 0.0039 - val_loss: 9.5960e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 5s 37ms/step - loss: 0.0024 - val_loss: 6.3350e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 0.0019 - val_loss: 4.3577e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 0.0018 - val_loss: 4.0055e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 0.0014 - val_loss: 3.8582e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0013 - val_loss: 3.8622e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0012 - val_loss: 8.2586e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0012 - val_loss: 2.6721e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0012 - val_loss: 2.1340e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 9.4187e-04 - val_loss: 2.1425e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.9991e-04 - val_loss: 3.2553e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.3684e-04 - val_loss: 1.7636e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.4848e-04 - val_loss: 1.5178e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.6694e-04 - val_loss: 2.1520e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.6768e-04 - val_loss: 1.5853e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.9438e-04 - val_loss: 3.2448e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.8597e-04 - val_loss: 2.1339e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.8104e-04 - val_loss: 1.4439e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.4975e-04 - val_loss: 1.3135e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.4810e-04 - val_loss: 1.3748e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.5865e-04 - val_loss: 1.6795e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.6978e-04 - val_loss: 2.6310e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 7.3964e-04 - val_loss: 1.2946e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.8472e-04 - val_loss: 2.4261e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.5882e-04 - val_loss: 2.7818e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 8.0155e-04 - val_loss: 1.7160e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.4529e-04 - val_loss: 1.3099e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.8473e-04 - val_loss: 1.2508e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.6283e-04 - val_loss: 1.4584e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.7941e-04 - val_loss: 1.7084e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.3168e-04 - val_loss: 1.5101e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.1536e-04 - val_loss: 2.7944e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.9928e-04 - val_loss: 1.1537e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.8069e-04 - val_loss: 1.9558e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.4156e-04 - val_loss: 1.1397e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.5819e-04 - val_loss: 1.7532e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.9382e-04 - val_loss: 1.2343e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 4.9351e-04 - val_loss: 2.3670e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.5325e-04 - val_loss: 1.0964e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 6.1603e-04 - val_loss: 1.4393e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.5362e-04 - val_loss: 1.8028e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.3747e-04 - val_loss: 1.1068e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.3618e-04 - val_loss: 2.4952e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.1952e-04 - val_loss: 4.3260e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.2955e-04 - val_loss: 1.1220e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 4.9467e-04 - val_loss: 1.2227e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.3248e-04 - val_loss: 1.2454e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.6507e-04 - val_loss: 1.8000e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.8789e-04 - val_loss: 1.1199e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 4.9222e-04 - val_loss: 1.1198e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.2580e-04 - val_loss: 1.2265e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.8307e-04 - val_loss: 1.0544e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.9373e-04 - val_loss: 1.0970e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.1023e-04 - val_loss: 1.4478e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.4789e-04 - val_loss: 1.3914e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.2842e-04 - val_loss: 1.8490e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.1366e-04 - val_loss: 1.0683e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.2954e-04 - val_loss: 1.0736e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 6.1042e-04 - val_loss: 1.4887e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.3687e-04 - val_loss: 1.4936e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.6404e-04 - val_loss: 1.7593e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 4.8745e-04 - val_loss: 1.0090e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.7314e-04 - val_loss: 2.0898e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 5.7430e-04 - val_loss: 9.8823e-05\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.2059e-04 - val_loss: 1.4102e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.5971e-04 - val_loss: 1.1155e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 5.3480e-04 - val_loss: 1.2136e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 5s 37ms/step - loss: 5.1946e-04 - val_loss: 2.6655e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 5.6866e-04 - val_loss: 1.0022e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 5s 34ms/step - loss: 5.2405e-04 - val_loss: 3.6413e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 5s 34ms/step - loss: 5.4900e-04 - val_loss: 1.1146e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 5s 34ms/step - loss: 5.1495e-04 - val_loss: 2.3868e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 5.7568e-04 - val_loss: 1.0194e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 5s 37ms/step - loss: 6.1316e-04 - val_loss: 1.0560e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.1756e-04 - val_loss: 3.3075e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 5.3262e-04 - val_loss: 9.7541e-05\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.2386e-04 - val_loss: 1.0377e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.1454e-04 - val_loss: 1.8837e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.0492e-04 - val_loss: 9.8143e-05\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.2196e-04 - val_loss: 2.0624e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.5524e-04 - val_loss: 1.9933e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 4.8810e-04 - val_loss: 1.1590e-04\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.9553e-04 - val_loss: 1.0892e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 5.3101e-04 - val_loss: 2.1687e-04\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 4.7576e-04 - val_loss: 9.5709e-05\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 5.6245e-04 - val_loss: 1.2900e-04\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.4190e-04 - val_loss: 1.0081e-04\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.0864e-04 - val_loss: 2.7818e-04\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.3528e-04 - val_loss: 1.3419e-04\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 5.1625e-04 - val_loss: 1.0966e-04\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.0606e-04 - val_loss: 9.7433e-05\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.1889e-04 - val_loss: 1.0582e-04\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.4870e-04 - val_loss: 1.4476e-04\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 5.5682e-04 - val_loss: 1.8147e-04\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 4.8510e-04 - val_loss: 1.0023e-04\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.5397e-04 - val_loss: 1.1172e-04\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 5.5234e-04 - val_loss: 1.8931e-04\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 5.2056e-04 - val_loss: 1.4177e-04\n",
      "9/9 [==============================] - 4s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 701.6406549005283\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 36s 95ms/step - loss: 0.0115 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0033 - val_loss: 8.7983e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0026 - val_loss: 5.7352e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0023 - val_loss: 5.6839e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0018 - val_loss: 5.4394e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0015 - val_loss: 3.5110e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0013 - val_loss: 3.1663e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0011 - val_loss: 2.6869e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0013 - val_loss: 2.9257e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 9.3435e-04 - val_loss: 3.3713e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 8.4511e-04 - val_loss: 2.2767e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.5808e-04 - val_loss: 2.3904e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.7018e-04 - val_loss: 2.4355e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 7.7245e-04 - val_loss: 1.9988e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 7.4521e-04 - val_loss: 2.5748e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 8.5271e-04 - val_loss: 1.8855e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.3765e-04 - val_loss: 6.7814e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.1999e-04 - val_loss: 1.5937e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.2928e-04 - val_loss: 3.5117e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.3379e-04 - val_loss: 1.8145e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.4154e-04 - val_loss: 1.6336e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 8.3590e-04 - val_loss: 1.6117e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 6.1589e-04 - val_loss: 1.4788e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 7.5212e-04 - val_loss: 1.6525e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.4914e-04 - val_loss: 2.8750e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.4841e-04 - val_loss: 3.3797e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.7737e-04 - val_loss: 1.9964e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.2360e-04 - val_loss: 1.8174e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.4336e-04 - val_loss: 2.4911e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.6905e-04 - val_loss: 2.0555e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 6.2196e-04 - val_loss: 3.2249e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 7.1895e-04 - val_loss: 2.6202e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 7.9239e-04 - val_loss: 1.5742e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 5.7041e-04 - val_loss: 1.4138e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 6s 44ms/step - loss: 6.7939e-04 - val_loss: 1.4320e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 6.5449e-04 - val_loss: 1.2148e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 6.1378e-04 - val_loss: 1.3158e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 6.2716e-04 - val_loss: 1.1879e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 5.5278e-04 - val_loss: 1.5537e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.4909e-04 - val_loss: 1.3476e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.3107e-04 - val_loss: 1.8093e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.2697e-04 - val_loss: 1.3208e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.0879e-04 - val_loss: 1.1143e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.8469e-04 - val_loss: 1.2111e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.0854e-04 - val_loss: 6.0918e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.8359e-04 - val_loss: 1.4938e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.6459e-04 - val_loss: 2.9077e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.3645e-04 - val_loss: 3.0323e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 7.3324e-04 - val_loss: 1.9286e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.3353e-04 - val_loss: 1.7014e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.4233e-04 - val_loss: 1.2226e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.7793e-04 - val_loss: 1.3171e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.3746e-04 - val_loss: 1.0294e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.0735e-04 - val_loss: 1.8140e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.5315e-04 - val_loss: 1.0289e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.4904e-04 - val_loss: 1.2525e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.4382e-04 - val_loss: 3.2083e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.1106e-04 - val_loss: 1.4976e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.3530e-04 - val_loss: 1.7507e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.3229e-04 - val_loss: 9.8487e-05\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.2553e-04 - val_loss: 1.3883e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.6999e-04 - val_loss: 1.3444e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.1057e-04 - val_loss: 1.3500e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.6310e-04 - val_loss: 1.4097e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.0066e-04 - val_loss: 1.1913e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.2459e-04 - val_loss: 9.9041e-05\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.5703e-04 - val_loss: 1.0955e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 5.6404e-04 - val_loss: 1.0313e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.4141e-04 - val_loss: 1.7958e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.5213e-04 - val_loss: 1.6706e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.2597e-04 - val_loss: 9.8780e-05\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 5.5746e-04 - val_loss: 1.2458e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.2020e-04 - val_loss: 9.9471e-05\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 5.4181e-04 - val_loss: 2.3754e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 7.0470e-04 - val_loss: 9.9344e-05\n",
      "9/9 [==============================] - 5s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 678.613977468504\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 29s 87ms/step - loss: 0.0106 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "  1/132 [..............................] - ETA: 7s - loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 7s 57ms/step - loss: 0.0030 - val_loss: 5.3810e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 7s 57ms/step - loss: 0.0028 - val_loss: 7.9737e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0020 - val_loss: 3.6194e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0016 - val_loss: 4.9168e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 0.0014 - val_loss: 2.5221e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0011 - val_loss: 2.5141e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 8.7939e-04 - val_loss: 2.1301e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 9.8169e-04 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 8.5850e-04 - val_loss: 1.6326e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 7.7683e-04 - val_loss: 2.3141e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 6.8895e-04 - val_loss: 1.4492e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 8.2720e-04 - val_loss: 1.5611e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 5.5331e-04 - val_loss: 1.6495e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 5.7239e-04 - val_loss: 1.9779e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 6.7637e-04 - val_loss: 1.6295e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 9.0744e-04 - val_loss: 1.8523e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 6.9851e-04 - val_loss: 1.9327e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 9.0130e-04 - val_loss: 1.1865e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 6.2694e-04 - val_loss: 1.4071e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 6.2071e-04 - val_loss: 1.2053e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 5.1611e-04 - val_loss: 2.3886e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 5.9174e-04 - val_loss: 1.3550e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 6.4331e-04 - val_loss: 1.1531e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 6.2230e-04 - val_loss: 1.1286e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 5.7623e-04 - val_loss: 1.3996e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 5.8368e-04 - val_loss: 1.6119e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 6.5022e-04 - val_loss: 2.3332e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 6.4095e-04 - val_loss: 1.1454e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 6.4850e-04 - val_loss: 6.4396e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 7.0759e-04 - val_loss: 1.5585e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 7.4665e-04 - val_loss: 1.2727e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 6.3270e-04 - val_loss: 1.2180e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 6.6415e-04 - val_loss: 2.2223e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 6.5228e-04 - val_loss: 1.5064e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6434e-04 - val_loss: 1.1565e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.4491e-04 - val_loss: 1.1000e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.8610e-04 - val_loss: 2.6748e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.0744e-04 - val_loss: 1.1207e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6838e-04 - val_loss: 1.7109e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.9148e-04 - val_loss: 1.2069e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.8459e-04 - val_loss: 1.0429e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.9639e-04 - val_loss: 1.2131e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.3314e-04 - val_loss: 1.2589e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.2087e-04 - val_loss: 1.0297e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.3712e-04 - val_loss: 1.3386e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.1429e-04 - val_loss: 1.1007e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6818e-04 - val_loss: 3.0661e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.2183e-04 - val_loss: 1.4929e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.2084e-04 - val_loss: 2.1205e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 5.4511e-04 - val_loss: 2.1855e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.2441e-04 - val_loss: 1.1133e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.6030e-04 - val_loss: 1.3386e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.3198e-04 - val_loss: 9.6478e-05\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.9395e-04 - val_loss: 1.0943e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6037e-04 - val_loss: 1.3252e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.8250e-04 - val_loss: 1.7447e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2884e-04 - val_loss: 1.0995e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 5.2138e-04 - val_loss: 9.3994e-05\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2001e-04 - val_loss: 4.6974e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.4572e-04 - val_loss: 1.2633e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 4.8758e-04 - val_loss: 1.1264e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.0235e-04 - val_loss: 1.8229e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.7030e-04 - val_loss: 1.0281e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.0880e-04 - val_loss: 9.9497e-05\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6287e-04 - val_loss: 9.8824e-05\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6998e-04 - val_loss: 1.0238e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 5.3869e-04 - val_loss: 1.8125e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.2977e-04 - val_loss: 1.6648e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2579e-04 - val_loss: 2.2253e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.3814e-04 - val_loss: 1.0573e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 4.7702e-04 - val_loss: 9.9819e-05\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.3320e-04 - val_loss: 9.3895e-05\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.2174e-04 - val_loss: 1.0251e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.2458e-04 - val_loss: 2.0695e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.0438e-04 - val_loss: 1.0441e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.0626e-04 - val_loss: 1.0776e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.3917e-04 - val_loss: 1.1293e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.9202e-04 - val_loss: 2.8368e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6022e-04 - val_loss: 1.4595e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.7071e-04 - val_loss: 2.0336e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.2394e-04 - val_loss: 1.3406e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.3112e-04 - val_loss: 9.7912e-05\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.4724e-04 - val_loss: 9.6399e-05\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.4234e-04 - val_loss: 1.1534e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.0040e-04 - val_loss: 2.2155e-04\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.7022e-04 - val_loss: 1.0937e-04\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.7479e-04 - val_loss: 1.2968e-04\n",
      "9/9 [==============================] - 3s 30ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 653.0798253454027\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 31s 95ms/step - loss: 0.0133 - val_loss: 0.0015\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0038 - val_loss: 6.3698e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 0.0022 - val_loss: 5.1526e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 0.0018 - val_loss: 3.8850e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 0.0015 - val_loss: 2.8530e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 0.0012 - val_loss: 3.0748e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.7804e-04 - val_loss: 2.3943e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.9968e-04 - val_loss: 2.5472e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 6.4074e-04 - val_loss: 2.2963e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0010 - val_loss: 1.5997e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 7.1610e-04 - val_loss: 1.5143e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.7312e-04 - val_loss: 1.4574e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 8.0270e-04 - val_loss: 1.4991e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.9567e-04 - val_loss: 1.8665e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 7.3131e-04 - val_loss: 3.8592e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 9s 64ms/step - loss: 5.8380e-04 - val_loss: 1.2872e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.7478e-04 - val_loss: 1.4419e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 7.1890e-04 - val_loss: 2.0747e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.5362e-04 - val_loss: 1.6734e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.6380e-04 - val_loss: 1.7949e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 7.6867e-04 - val_loss: 1.5337e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 7.1093e-04 - val_loss: 1.4870e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 6.3273e-04 - val_loss: 1.3575e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 5.6131e-04 - val_loss: 2.6192e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 8.8866e-04 - val_loss: 1.5092e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.6522e-04 - val_loss: 1.6790e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.7904e-04 - val_loss: 1.7696e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.2814e-04 - val_loss: 4.1710e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 7.4576e-04 - val_loss: 1.4149e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 7.1561e-04 - val_loss: 1.7825e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.0262e-04 - val_loss: 1.2078e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 6.5719e-04 - val_loss: 1.0392e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 6.1668e-04 - val_loss: 1.7609e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 4.8853e-04 - val_loss: 2.0446e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 5.7637e-04 - val_loss: 1.2688e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.7912e-04 - val_loss: 1.2276e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.8541e-04 - val_loss: 1.1930e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.1921e-04 - val_loss: 9.7843e-05\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 5.2015e-04 - val_loss: 1.0637e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.1650e-04 - val_loss: 1.0473e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.3615e-04 - val_loss: 9.5775e-05\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.1941e-04 - val_loss: 2.4354e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 7.6398e-04 - val_loss: 1.0447e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 5.8091e-04 - val_loss: 2.1200e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 5.9226e-04 - val_loss: 2.4908e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.6403e-04 - val_loss: 1.3779e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 5.5215e-04 - val_loss: 1.8366e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.0381e-04 - val_loss: 1.2105e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.6852e-04 - val_loss: 1.0114e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 5.5170e-04 - val_loss: 2.5501e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.6837e-04 - val_loss: 1.0305e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.8882e-04 - val_loss: 1.4013e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.8540e-04 - val_loss: 2.4248e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 6.7590e-04 - val_loss: 1.2031e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.7200e-04 - val_loss: 1.2414e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.7420e-04 - val_loss: 1.0661e-04\n",
      "9/9 [==============================] - 4s 37ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 664.1999757615662\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 28s 107ms/step - loss: 0.0131 - val_loss: 0.0022\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0037 - val_loss: 7.5986e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0030 - val_loss: 6.7444e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0019 - val_loss: 5.6397e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0020 - val_loss: 8.4379e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0014 - val_loss: 4.0012e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0012 - val_loss: 3.6195e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.0011 - val_loss: 4.6069e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 9.5577e-04 - val_loss: 3.4802e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 8.8381e-04 - val_loss: 3.0874e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 8.6014e-04 - val_loss: 2.3883e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.7158e-04 - val_loss: 6.7180e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.7971e-04 - val_loss: 2.1198e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0010 - val_loss: 8.6695e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.7559e-04 - val_loss: 1.9029e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 9.0766e-04 - val_loss: 1.6934e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.4901e-04 - val_loss: 1.7065e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.4154e-04 - val_loss: 2.6306e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.0547e-04 - val_loss: 2.0639e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.2665e-04 - val_loss: 7.5490e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 8.5501e-04 - val_loss: 2.2358e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.9381e-04 - val_loss: 1.5313e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.7065e-04 - val_loss: 2.4329e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.5541e-04 - val_loss: 1.8760e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.3341e-04 - val_loss: 5.5586e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.5613e-04 - val_loss: 2.0115e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.5191e-04 - val_loss: 1.4770e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.3621e-04 - val_loss: 2.3091e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.9547e-04 - val_loss: 1.7788e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.2912e-04 - val_loss: 2.8316e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.1446e-04 - val_loss: 2.3847e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.6089e-04 - val_loss: 2.5361e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.5387e-04 - val_loss: 2.0031e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.6040e-04 - val_loss: 3.8439e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 6.0210e-04 - val_loss: 1.9578e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.9342e-04 - val_loss: 1.3242e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.4792e-04 - val_loss: 1.3861e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.3970e-04 - val_loss: 6.0312e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.3045e-04 - val_loss: 2.0872e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.6364e-04 - val_loss: 1.6242e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.6141e-04 - val_loss: 3.3287e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 5.8505e-04 - val_loss: 1.2665e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.3750e-04 - val_loss: 1.4547e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.5619e-04 - val_loss: 1.5570e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.7862e-04 - val_loss: 2.7744e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.8700e-04 - val_loss: 1.3828e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.4865e-04 - val_loss: 1.5973e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.9989e-04 - val_loss: 1.3082e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 5.8898e-04 - val_loss: 1.4804e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.8512e-04 - val_loss: 6.4497e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.6080e-04 - val_loss: 1.2652e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.0012e-04 - val_loss: 2.4939e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.4086e-04 - val_loss: 1.3710e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.2456e-04 - val_loss: 1.7550e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.4295e-04 - val_loss: 1.2646e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 5.0777e-04 - val_loss: 2.5260e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 5.4777e-04 - val_loss: 1.1958e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.2613e-04 - val_loss: 1.3893e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.0436e-04 - val_loss: 6.0201e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.8099e-04 - val_loss: 1.1815e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 4.8416e-04 - val_loss: 2.6764e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.6211e-04 - val_loss: 1.6459e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.1566e-04 - val_loss: 1.2059e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.1376e-04 - val_loss: 1.6594e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.2823e-04 - val_loss: 1.7178e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.7950e-04 - val_loss: 1.2018e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.4008e-04 - val_loss: 3.2219e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.5747e-04 - val_loss: 1.2040e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 5.3071e-04 - val_loss: 1.1726e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.0369e-04 - val_loss: 1.1825e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.6412e-04 - val_loss: 1.7126e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.5668e-04 - val_loss: 1.1539e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 5.2171e-04 - val_loss: 3.0342e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 4.7652e-04 - val_loss: 1.8666e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 4.6743e-04 - val_loss: 1.7658e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 5.0579e-04 - val_loss: 2.9154e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 5.3323e-04 - val_loss: 1.2069e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 5.6885e-04 - val_loss: 1.2879e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 5.2201e-04 - val_loss: 1.7151e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 5.2036e-04 - val_loss: 2.2603e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 5.0095e-04 - val_loss: 1.2517e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 4.8757e-04 - val_loss: 2.6306e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 5.1303e-04 - val_loss: 1.1768e-04\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 5.3560e-04 - val_loss: 1.6168e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.2660e-04 - val_loss: 1.3668e-04\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 13s 95ms/step - loss: 5.2874e-04 - val_loss: 1.2951e-04\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 5.4914e-04 - val_loss: 1.4832e-04\n",
      "8/8 [==============================] - 4s 40ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 668.5093473536323\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 45s 166ms/step - loss: 0.0111 - val_loss: 0.0012\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0050 - val_loss: 8.2572e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0044 - val_loss: 8.1990e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 16s 117ms/step - loss: 0.0028 - val_loss: 9.3932e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0020 - val_loss: 6.6688e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0020 - val_loss: 5.7569e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0017 - val_loss: 7.1751e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0013 - val_loss: 4.7731e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0016 - val_loss: 4.7916e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0012 - val_loss: 7.7813e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0011 - val_loss: 9.2472e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.0012 - val_loss: 4.2983e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.4379e-04 - val_loss: 2.3816e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 8.4394e-04 - val_loss: 1.9399e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.8105e-04 - val_loss: 1.9275e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.3586e-04 - val_loss: 2.2956e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.7262e-04 - val_loss: 1.9095e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.1474e-04 - val_loss: 2.3155e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.3001e-04 - val_loss: 2.5776e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.8231e-04 - val_loss: 3.2732e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 9.6523e-04 - val_loss: 1.8036e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.4188e-04 - val_loss: 2.0628e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.4831e-04 - val_loss: 7.0664e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 8.0438e-04 - val_loss: 3.4421e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.1147e-04 - val_loss: 2.2087e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.1078e-04 - val_loss: 2.2906e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 7.6381e-04 - val_loss: 1.8874e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.1843e-04 - val_loss: 3.6754e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.4865e-04 - val_loss: 1.8572e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.7593e-04 - val_loss: 4.1626e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.0626e-04 - val_loss: 1.4777e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 8.0884e-04 - val_loss: 2.3156e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.2684e-04 - val_loss: 1.7594e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 16s 117ms/step - loss: 6.3112e-04 - val_loss: 5.2816e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 9.2372e-04 - val_loss: 1.6456e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.6507e-04 - val_loss: 1.7626e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.8072e-04 - val_loss: 1.6878e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 5.7071e-04 - val_loss: 1.5638e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 6.6822e-04 - val_loss: 1.5077e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.5308e-04 - val_loss: 1.8118e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.0614e-04 - val_loss: 1.3043e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.9427e-04 - val_loss: 1.8228e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 7.3091e-04 - val_loss: 1.5547e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.7668e-04 - val_loss: 1.4343e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 5.8970e-04 - val_loss: 1.2420e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.1120e-04 - val_loss: 1.2815e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.2812e-04 - val_loss: 1.5881e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.5441e-04 - val_loss: 1.1474e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.0006e-04 - val_loss: 1.2081e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.2499e-04 - val_loss: 1.4542e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 16s 117ms/step - loss: 6.3242e-04 - val_loss: 1.9633e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.2580e-04 - val_loss: 1.4569e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.3035e-04 - val_loss: 1.7723e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.6738e-04 - val_loss: 1.3086e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.4680e-04 - val_loss: 1.9542e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.6139e-04 - val_loss: 2.0243e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.2888e-04 - val_loss: 2.1786e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.4434e-04 - val_loss: 1.5829e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.5460e-04 - val_loss: 1.2767e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.2960e-04 - val_loss: 1.7363e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.3447e-04 - val_loss: 1.2370e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.3793e-04 - val_loss: 2.1381e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.6006e-04 - val_loss: 1.3698e-04\n",
      "8/8 [==============================] - 6s 52ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 728.6729113180012\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 37s 147ms/step - loss: 0.0104 - val_loss: 0.0012\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0036 - val_loss: 6.8461e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 0.0024 - val_loss: 4.9300e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0025 - val_loss: 5.0420e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.0016 - val_loss: 4.1337e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0013 - val_loss: 3.5259e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 9.1765e-04 - val_loss: 6.3195e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 8.9240e-04 - val_loss: 2.8301e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0012 - val_loss: 2.4485e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.6142e-04 - val_loss: 1.7393e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.3573e-04 - val_loss: 1.9283e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.6964e-04 - val_loss: 1.6639e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.1288e-04 - val_loss: 1.4818e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0013 - val_loss: 1.6497e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.3370e-04 - val_loss: 1.8528e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.5042e-04 - val_loss: 7.0248e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.4468e-04 - val_loss: 5.0288e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.2967e-04 - val_loss: 3.8967e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0556e-04 - val_loss: 1.5297e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.3451e-04 - val_loss: 2.0248e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.4711e-04 - val_loss: 3.6812e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.7991e-04 - val_loss: 2.8491e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.9308e-04 - val_loss: 2.4453e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.6577e-04 - val_loss: 2.6107e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.4406e-04 - val_loss: 3.2536e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.6532e-04 - val_loss: 1.5566e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.9557e-04 - val_loss: 1.2890e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.6977e-04 - val_loss: 1.3070e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.1808e-04 - val_loss: 1.6925e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.7516e-04 - val_loss: 1.4689e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 5.4713e-04 - val_loss: 1.6802e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 8.0293e-04 - val_loss: 2.2571e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.2901e-04 - val_loss: 2.2997e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.0622e-04 - val_loss: 1.2129e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.0929e-04 - val_loss: 6.0449e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.1263e-04 - val_loss: 1.3260e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.7278e-04 - val_loss: 1.2290e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 4.9271e-04 - val_loss: 8.0679e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.7500e-04 - val_loss: 1.7516e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.7470e-04 - val_loss: 1.3849e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.3009e-04 - val_loss: 1.3328e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.1094e-04 - val_loss: 2.1184e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.3650e-04 - val_loss: 1.1994e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.8232e-04 - val_loss: 1.9589e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.4814e-04 - val_loss: 1.1799e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.3289e-04 - val_loss: 1.6384e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0090e-04 - val_loss: 1.6824e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.4380e-04 - val_loss: 1.4448e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 5.8749e-04 - val_loss: 1.9033e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 5.4822e-04 - val_loss: 3.1991e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 5.5549e-04 - val_loss: 2.5993e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 5.4912e-04 - val_loss: 1.5835e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 5.9946e-04 - val_loss: 2.4578e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.2609e-04 - val_loss: 1.8738e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.7766e-04 - val_loss: 1.5221e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 5.1873e-04 - val_loss: 2.3885e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.9692e-04 - val_loss: 1.4191e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 5.1494e-04 - val_loss: 2.5930e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.5349e-04 - val_loss: 1.2299e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 5.2658e-04 - val_loss: 1.6831e-04\n",
      "8/8 [==============================] - 3s 64ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 655.4334846159994\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 43s 187ms/step - loss: 0.0118 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 0.0031 - val_loss: 9.9027e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 0.0024 - val_loss: 9.9162e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0018 - val_loss: 6.1391e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 0.0013 - val_loss: 4.0986e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0012 - val_loss: 3.0841e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 0.0016 - val_loss: 2.7576e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 0.0011 - val_loss: 7.6368e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 8.4853e-04 - val_loss: 3.0437e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 7.7704e-04 - val_loss: 3.6945e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 8.9426e-04 - val_loss: 2.2857e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 6.8315e-04 - val_loss: 5.2375e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.7484e-04 - val_loss: 1.7934e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 7.3751e-04 - val_loss: 3.6638e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 7.9780e-04 - val_loss: 2.9935e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 7.8128e-04 - val_loss: 2.6306e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 0.0010 - val_loss: 2.5077e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.3048e-04 - val_loss: 4.0956e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 7.0674e-04 - val_loss: 4.1304e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.7758e-04 - val_loss: 1.4935e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 7.5148e-04 - val_loss: 5.1688e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.8915e-04 - val_loss: 1.5057e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 8.7577e-04 - val_loss: 1.8343e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 7.5874e-04 - val_loss: 1.3639e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 7.2181e-04 - val_loss: 1.5433e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.1671e-04 - val_loss: 2.0856e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.5976e-04 - val_loss: 1.4363e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 8.5924e-04 - val_loss: 3.2906e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.4289e-04 - val_loss: 1.9028e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.7259e-04 - val_loss: 1.4611e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.8489e-04 - val_loss: 2.0926e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.7211e-04 - val_loss: 1.3347e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.8160e-04 - val_loss: 1.5697e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.8142e-04 - val_loss: 1.3101e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.7302e-04 - val_loss: 2.1539e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.3415e-04 - val_loss: 1.7641e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.2956e-04 - val_loss: 1.9341e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.9360e-04 - val_loss: 1.4298e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 7.8549e-04 - val_loss: 1.3789e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 5.7361e-04 - val_loss: 2.1466e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.7303e-04 - val_loss: 1.7989e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 7.1049e-04 - val_loss: 1.3589e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 5.8621e-04 - val_loss: 4.2028e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 7.1968e-04 - val_loss: 2.1749e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.3947e-04 - val_loss: 1.3113e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 8.5724e-04 - val_loss: 1.3657e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.0548e-04 - val_loss: 3.6296e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.6060e-04 - val_loss: 1.2001e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.4656e-04 - val_loss: 1.2280e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.6894e-04 - val_loss: 1.8699e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.9075e-04 - val_loss: 1.8010e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 6.4530e-04 - val_loss: 1.6747e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.0848e-04 - val_loss: 1.9437e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 5.7473e-04 - val_loss: 1.4134e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 5.9988e-04 - val_loss: 2.2267e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.7026e-04 - val_loss: 1.2101e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.4659e-04 - val_loss: 1.4388e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.7464e-04 - val_loss: 1.5827e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.6419e-04 - val_loss: 1.1985e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 6.1337e-04 - val_loss: 1.2731e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.8422e-04 - val_loss: 2.8838e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.6422e-04 - val_loss: 2.6735e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 5.8854e-04 - val_loss: 1.4791e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.2195e-04 - val_loss: 1.1420e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 5.1899e-04 - val_loss: 3.6098e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.7164e-04 - val_loss: 1.2110e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.2178e-04 - val_loss: 1.2676e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 4.9976e-04 - val_loss: 4.7508e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.0830e-04 - val_loss: 1.2745e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 5.7966e-04 - val_loss: 1.1116e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.8732e-04 - val_loss: 1.2514e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 5.6218e-04 - val_loss: 2.2638e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.1549e-04 - val_loss: 1.3027e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.1206e-04 - val_loss: 2.2973e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.5991e-04 - val_loss: 1.3532e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.2186e-04 - val_loss: 1.4696e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.4037e-04 - val_loss: 2.4092e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.3461e-04 - val_loss: 2.0043e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.9448e-04 - val_loss: 1.1806e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 5.0187e-04 - val_loss: 1.1924e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 5.1517e-04 - val_loss: 1.1182e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.2813e-04 - val_loss: 2.8851e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 5.8157e-04 - val_loss: 2.7931e-04\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.0108e-04 - val_loss: 1.4045e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.6731e-04 - val_loss: 1.4090e-04\n",
      "8/8 [==============================] - 5s 80ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 670.0449523856812\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 35s 139ms/step - loss: 0.0120 - val_loss: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0036 - val_loss: 8.2688e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0030 - val_loss: 6.6544e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0022 - val_loss: 9.9924e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0015 - val_loss: 3.7292e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0013 - val_loss: 5.3147e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0012 - val_loss: 3.0436e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 9.7688e-04 - val_loss: 2.7644e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 8.7702e-04 - val_loss: 8.1955e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0012 - val_loss: 2.4190e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 8.7889e-04 - val_loss: 2.4949e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 6.8380e-04 - val_loss: 4.6617e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.4278e-04 - val_loss: 1.8636e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 7.9047e-04 - val_loss: 1.9242e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.2260e-04 - val_loss: 1.7702e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 6.7800e-04 - val_loss: 2.3195e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.1214e-04 - val_loss: 2.5214e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0981e-04 - val_loss: 5.0091e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.1073e-04 - val_loss: 1.6163e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.4602e-04 - val_loss: 1.5266e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 7.0943e-04 - val_loss: 1.5703e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.6542e-04 - val_loss: 8.5250e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 8.3095e-04 - val_loss: 1.7144e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 6.1406e-04 - val_loss: 1.5866e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0637e-04 - val_loss: 1.4382e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.7022e-04 - val_loss: 2.2665e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.3585e-04 - val_loss: 1.7806e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 5.9342e-04 - val_loss: 1.5075e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.2706e-04 - val_loss: 3.1585e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.8384e-04 - val_loss: 4.0673e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.3318e-04 - val_loss: 1.9956e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.9507e-04 - val_loss: 6.3809e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0366e-04 - val_loss: 1.3418e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.5333e-04 - val_loss: 1.4019e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 6.1985e-04 - val_loss: 2.5757e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.0434e-04 - val_loss: 1.6737e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 6.4688e-04 - val_loss: 1.4756e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.0182e-04 - val_loss: 3.2203e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.2659e-04 - val_loss: 1.4470e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.2407e-04 - val_loss: 1.5275e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.6885e-04 - val_loss: 1.6944e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.8160e-04 - val_loss: 1.2283e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 6.4055e-04 - val_loss: 5.4166e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.3706e-04 - val_loss: 1.2986e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.5614e-04 - val_loss: 1.5981e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 4.9769e-04 - val_loss: 2.4578e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 4.9875e-04 - val_loss: 3.8745e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.1607e-04 - val_loss: 1.4952e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.4327e-04 - val_loss: 1.6367e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.3301e-04 - val_loss: 1.9134e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.9877e-04 - val_loss: 1.2068e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.3827e-04 - val_loss: 2.2483e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.6264e-04 - val_loss: 4.9883e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.1413e-04 - val_loss: 2.5646e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.3049e-04 - val_loss: 1.2721e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0032e-04 - val_loss: 1.5879e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0728e-04 - val_loss: 2.8210e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0588e-04 - val_loss: 1.2204e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.6190e-04 - val_loss: 1.2389e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 5.6564e-04 - val_loss: 1.2129e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.7053e-04 - val_loss: 1.3192e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.4692e-04 - val_loss: 1.4914e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.5085e-04 - val_loss: 1.8165e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.2358e-04 - val_loss: 1.2779e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.6970e-04 - val_loss: 1.2477e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 4.8768e-04 - val_loss: 2.6702e-04\n",
      "7/7 [==============================] - 4s 50ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 723.3833320223914\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 40s 170ms/step - loss: 0.0135 - val_loss: 0.0056\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0044 - val_loss: 8.4905e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0033 - val_loss: 9.2036e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0020 - val_loss: 6.5331e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 0.0019 - val_loss: 7.7104e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0017 - val_loss: 4.3222e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0015 - val_loss: 4.0717e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0012 - val_loss: 3.6301e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0011 - val_loss: 4.0757e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 8.4142e-04 - val_loss: 3.1397e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0010 - val_loss: 2.4622e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 8.6389e-04 - val_loss: 2.4634e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 8.9289e-04 - val_loss: 2.5225e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 7.6224e-04 - val_loss: 3.7145e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 8.3523e-04 - val_loss: 3.3993e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 8.2687e-04 - val_loss: 2.4250e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.9635e-04 - val_loss: 1.9401e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 7.8287e-04 - val_loss: 3.2494e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 9.8688e-04 - val_loss: 2.6207e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.9969e-04 - val_loss: 3.2001e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 8.5179e-04 - val_loss: 6.2668e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.6345e-04 - val_loss: 2.1852e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.8955e-04 - val_loss: 5.4442e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.1513e-04 - val_loss: 3.1165e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.6670e-04 - val_loss: 1.9078e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 8.7763e-04 - val_loss: 1.7882e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.6930e-04 - val_loss: 1.5775e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 7.5677e-04 - val_loss: 1.7199e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.9035e-04 - val_loss: 3.2269e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.3460e-04 - val_loss: 2.0099e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.3269e-04 - val_loss: 2.3819e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 7.8011e-04 - val_loss: 4.3541e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.9900e-04 - val_loss: 3.1353e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.8255e-04 - val_loss: 4.0009e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 7.8975e-04 - val_loss: 1.4673e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 7.0524e-04 - val_loss: 8.3338e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 8.4411e-04 - val_loss: 2.8327e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 6.2632e-04 - val_loss: 2.3559e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.6718e-04 - val_loss: 1.8592e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.7858e-04 - val_loss: 2.1244e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.3331e-04 - val_loss: 1.3677e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.7819e-04 - val_loss: 1.4040e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 6.1799e-04 - val_loss: 1.5109e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 7.3567e-04 - val_loss: 4.0431e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 22s 163ms/step - loss: 6.3011e-04 - val_loss: 1.4752e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.2625e-04 - val_loss: 1.9553e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.2132e-04 - val_loss: 1.2107e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.2749e-04 - val_loss: 2.8170e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.9447e-04 - val_loss: 1.5442e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.2266e-04 - val_loss: 1.9280e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.2970e-04 - val_loss: 2.1223e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 6.5394e-04 - val_loss: 1.2878e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.2927e-04 - val_loss: 1.3512e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.3748e-04 - val_loss: 1.3121e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.4167e-04 - val_loss: 1.1850e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.4555e-04 - val_loss: 2.8090e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.6273e-04 - val_loss: 1.7778e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.1557e-04 - val_loss: 2.4779e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.9038e-04 - val_loss: 2.3651e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.6464e-04 - val_loss: 1.1410e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 5.4668e-04 - val_loss: 2.3418e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.4968e-04 - val_loss: 1.4434e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.8925e-04 - val_loss: 1.1523e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.3726e-04 - val_loss: 1.9124e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 7.2651e-04 - val_loss: 2.6021e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.7506e-04 - val_loss: 1.1257e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 19s 148ms/step - loss: 5.3565e-04 - val_loss: 1.6581e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 5.4773e-04 - val_loss: 2.9457e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 5.1520e-04 - val_loss: 2.5432e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 6.2876e-04 - val_loss: 1.7502e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.2766e-04 - val_loss: 1.2026e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.1302e-04 - val_loss: 1.2592e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.9223e-04 - val_loss: 1.9324e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.9782e-04 - val_loss: 1.2509e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 4.8593e-04 - val_loss: 1.3387e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 5.9365e-04 - val_loss: 1.1838e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.1438e-04 - val_loss: 1.8032e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.8488e-04 - val_loss: 1.2392e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.2061e-04 - val_loss: 1.9264e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 5.1663e-04 - val_loss: 2.6334e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.8176e-04 - val_loss: 1.3307e-04\n",
      "7/7 [==============================] - 6s 62ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 675.9676374185542\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 43s 189ms/step - loss: 0.0096 - val_loss: 0.0016\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 22s 165ms/step - loss: 0.0027 - val_loss: 7.8588e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 0.0027 - val_loss: 9.3593e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 0.0014 - val_loss: 4.8886e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 0.0015 - val_loss: 4.3051e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 0.0014 - val_loss: 3.3468e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 0.0012 - val_loss: 3.2999e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 0.0011 - val_loss: 2.0972e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 8.9038e-04 - val_loss: 3.0849e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.9675e-04 - val_loss: 1.7959e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.3743e-04 - val_loss: 1.6224e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 9.4595e-04 - val_loss: 1.7152e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 6.1660e-04 - val_loss: 2.8601e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 5.8349e-04 - val_loss: 1.8197e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 8.0792e-04 - val_loss: 3.1960e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.2903e-04 - val_loss: 1.7637e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 5.9352e-04 - val_loss: 5.1938e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.3220e-04 - val_loss: 1.8132e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.2161e-04 - val_loss: 2.3615e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 7.9881e-04 - val_loss: 1.3987e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 7.5325e-04 - val_loss: 1.4781e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.9589e-04 - val_loss: 1.9671e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.9446e-04 - val_loss: 1.6377e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.6786e-04 - val_loss: 1.4494e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.2510e-04 - val_loss: 1.7592e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.8995e-04 - val_loss: 4.7949e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 6.3178e-04 - val_loss: 1.4500e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 7.7948e-04 - val_loss: 1.3246e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.4789e-04 - val_loss: 1.2923e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 5.4939e-04 - val_loss: 2.1298e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 5.7538e-04 - val_loss: 2.3869e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.3724e-04 - val_loss: 1.9456e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.0544e-04 - val_loss: 2.6665e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 5.5996e-04 - val_loss: 1.6169e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.3505e-04 - val_loss: 2.2820e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 7.1781e-04 - val_loss: 2.3037e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.2352e-04 - val_loss: 1.9993e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.2471e-04 - val_loss: 1.2203e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 5.5876e-04 - val_loss: 1.4098e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.3728e-04 - val_loss: 1.2250e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 21s 155ms/step - loss: 5.4219e-04 - val_loss: 1.3669e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 5.8090e-04 - val_loss: 1.2164e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 5.1953e-04 - val_loss: 1.2220e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 5.2279e-04 - val_loss: 1.1852e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.6229e-04 - val_loss: 3.8005e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.5277e-04 - val_loss: 1.8840e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.5020e-04 - val_loss: 2.5305e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.4038e-04 - val_loss: 2.1628e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.5433e-04 - val_loss: 1.8060e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.5761e-04 - val_loss: 1.4140e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.8701e-04 - val_loss: 1.2124e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.3594e-04 - val_loss: 1.4213e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.0931e-04 - val_loss: 1.2846e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.6142e-04 - val_loss: 2.3661e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.4037e-04 - val_loss: 1.2691e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.7800e-04 - val_loss: 1.2289e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.3102e-04 - val_loss: 1.1669e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.2472e-04 - val_loss: 1.5870e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.8443e-04 - val_loss: 1.3704e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.5934e-04 - val_loss: 2.4128e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.1967e-04 - val_loss: 1.1989e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 4.8050e-04 - val_loss: 1.1996e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.3503e-04 - val_loss: 2.1189e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.2562e-04 - val_loss: 2.1676e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 4.7497e-04 - val_loss: 1.4435e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.7001e-04 - val_loss: 1.1838e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.0059e-04 - val_loss: 1.1965e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 4.9441e-04 - val_loss: 1.7074e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.7749e-04 - val_loss: 1.1002e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.3339e-04 - val_loss: 3.4617e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.5931e-04 - val_loss: 1.1326e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.3028e-04 - val_loss: 1.1100e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.1967e-04 - val_loss: 2.3802e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.8797e-04 - val_loss: 3.8419e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.3427e-04 - val_loss: 1.1856e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.8447e-04 - val_loss: 4.4902e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 6.2573e-04 - val_loss: 1.2650e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.8778e-04 - val_loss: 2.4701e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.1203e-04 - val_loss: 1.1295e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 15s 112ms/step - loss: 5.6885e-04 - val_loss: 1.4183e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.6774e-04 - val_loss: 2.2155e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 5.9818e-04 - val_loss: 2.0210e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.2962e-04 - val_loss: 1.5940e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.1881e-04 - val_loss: 1.1420e-04\n",
      "7/7 [==============================] - 2s 71ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 675.7180892648191\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 33s 163ms/step - loss: 0.0128 - val_loss: 0.0012\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0031 - val_loss: 8.8607e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0031 - val_loss: 8.6377e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0018 - val_loss: 4.5002e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0017 - val_loss: 3.6849e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0016 - val_loss: 6.5273e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0013 - val_loss: 2.8394e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 0.0010 - val_loss: 4.9188e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 0.0011 - val_loss: 5.3700e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 8.8930e-04 - val_loss: 2.3108e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0011 - val_loss: 3.1713e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 7.0968e-04 - val_loss: 5.7083e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 8.1364e-04 - val_loss: 1.8223e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 0.0011 - val_loss: 7.8992e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.6405e-04 - val_loss: 2.4843e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 8.0762e-04 - val_loss: 1.5188e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.0713e-04 - val_loss: 2.9506e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.7959e-04 - val_loss: 1.5187e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.0296e-04 - val_loss: 1.8017e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 6.4110e-04 - val_loss: 1.4646e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.2867e-04 - val_loss: 3.8007e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.8083e-04 - val_loss: 1.6547e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.6088e-04 - val_loss: 5.1990e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 7.9271e-04 - val_loss: 4.6168e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.0120e-04 - val_loss: 1.5358e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.2671e-04 - val_loss: 1.4942e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.1059e-04 - val_loss: 2.1555e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.0265e-04 - val_loss: 2.4636e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.1432e-04 - val_loss: 1.5962e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 5.8562e-04 - val_loss: 1.8472e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 7.0522e-04 - val_loss: 1.9575e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 8.0689e-04 - val_loss: 2.2507e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.3810e-04 - val_loss: 1.6587e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.8328e-04 - val_loss: 4.1820e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.0020e-04 - val_loss: 3.0175e-04\n",
      "7/7 [==============================] - 3s 82ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 710.3599190996612\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba101e3-c4b6-4b42-b47a-39b96f135bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 947.3022114119542}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 674.5037989615822}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 655.7679438763513}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 658.2745992730383}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 676.491914964014}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 805.7078025252819}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 741.108645534591}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 719.6021348839267}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 701.3365197432306}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 715.692186694386}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 700.1169735624156}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 766.9055257359643}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 672.1835743238328}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 689.5568206767537}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 655.5508132384374}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 701.0558783517782}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 908.688481758473}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 874.8506547046675}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 656.556306581163}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 1064.4170861259977}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 1228.10627648693}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 891.7350772264024}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 768.7744006413043}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 812.0921267636497}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 668.2466915919753}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 676.7898352903787}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 726.0525650726}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 693.3447571122656}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 850.9188391203899}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 682.4998176254697}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 771.3469459810814}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 793.9433698231912}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 700.5737490176481}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 682.2736711895725}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 690.6325962352221}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 674.0056046546372}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 701.6406549005283}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 678.613977468504}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 653.0798253454027}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 664.1999757615662}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 668.5093473536323}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 728.6729113180012}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 655.4334846159994}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 670.0449523856812}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 723.3833320223914}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 675.9676374185542}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 675.7180892648191}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 710.3599190996612}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63ce70-b9b9-4036-9894-26cac2249cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
