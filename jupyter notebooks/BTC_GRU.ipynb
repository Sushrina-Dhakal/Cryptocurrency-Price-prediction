{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d995c4f2-4435-40f6-84c6-f3e03a52499d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a98cec-d2ba-4e62-9996-bc884cb910f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_rmse = 5000\n",
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcba3eb1-d1f1-4f09-bba9-a24dcbee5edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ce8e36-cc3f-4206-a096-5df8dc50e378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_gru_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(GRU(units, return_sequences=True))\n",
    "    model.add(GRU(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6246ed-05dc-40b6-8ff0-c84912e400cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'GRUmodel_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    gru_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    gru_predictions = model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, gru_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"BTC_model_gru.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(gru_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BTC_actual_vs_predicted_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BTC_loss_curve_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b225ee1-7d44-4346-a7a5-cfa08bf84caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'BTC-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'\n",
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,20]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1f7b64-4718-45b5-8afb-382941e597f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688ca0ab-0832-4653-8215-51f35a6375b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 22s 41ms/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 16s - loss: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0015 - val_loss: 4.2353e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.9498e-04 - val_loss: 1.8995e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.1301e-04 - val_loss: 2.1477e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.9932e-04 - val_loss: 4.7180e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.4371e-04 - val_loss: 1.8559e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.4894e-04 - val_loss: 2.9932e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.4549e-04 - val_loss: 2.2185e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 5.6605e-04 - val_loss: 1.3921e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.3662e-04 - val_loss: 1.3414e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.8914e-04 - val_loss: 1.5400e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.6162e-04 - val_loss: 3.1624e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.7939e-04 - val_loss: 1.3702e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.0082e-04 - val_loss: 2.6475e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.4864e-04 - val_loss: 1.7662e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.3319e-04 - val_loss: 1.4147e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.3810e-04 - val_loss: 1.8241e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.6902e-04 - val_loss: 1.2260e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.5480e-04 - val_loss: 1.3965e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.0403e-04 - val_loss: 1.8305e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.7653e-04 - val_loss: 1.2427e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.1158e-04 - val_loss: 1.3563e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.2258e-04 - val_loss: 3.8195e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.2981e-04 - val_loss: 3.1547e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.3651e-04 - val_loss: 1.8132e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.1995e-04 - val_loss: 1.4566e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.3333e-04 - val_loss: 1.5272e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.3985e-04 - val_loss: 2.1891e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.7686e-04 - val_loss: 3.5512e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.2917e-04 - val_loss: 1.2783e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.0023e-04 - val_loss: 1.2429e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.0923e-04 - val_loss: 1.5782e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.7255e-04 - val_loss: 1.6629e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.9898e-04 - val_loss: 2.1327e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 5.7861e-04 - val_loss: 2.0759e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.1252e-04 - val_loss: 1.6067e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.5499e-04 - val_loss: 1.5001e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.3998e-04 - val_loss: 1.7378e-04\n",
      "9/9 [==============================] - 3s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 832.456450107897\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 28s 52ms/step - loss: 0.0042 - val_loss: 5.1868e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 9s - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0015 - val_loss: 5.0593e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.7270e-04 - val_loss: 3.3324e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.6990e-04 - val_loss: 1.6082e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.9999e-04 - val_loss: 6.3959e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.2410e-04 - val_loss: 2.5152e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.8949e-04 - val_loss: 5.5319e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.7632e-04 - val_loss: 2.2216e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0010 - val_loss: 1.7434e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 8.9775e-04 - val_loss: 2.2347e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.8409e-04 - val_loss: 4.4649e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.8014e-04 - val_loss: 1.5205e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.9739e-04 - val_loss: 2.0563e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.0338e-04 - val_loss: 1.8072e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.3342e-04 - val_loss: 1.6581e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.9598e-04 - val_loss: 4.4207e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.8597e-04 - val_loss: 1.8581e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.7119e-04 - val_loss: 1.4488e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.1915e-04 - val_loss: 1.2088e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.0853e-04 - val_loss: 1.3017e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.3139e-04 - val_loss: 1.8316e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.7748e-04 - val_loss: 4.5999e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.3033e-04 - val_loss: 2.6364e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.8683e-04 - val_loss: 2.3100e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2986e-04 - val_loss: 1.4735e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.9867e-04 - val_loss: 2.4379e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.0329e-04 - val_loss: 1.1525e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.6747e-04 - val_loss: 3.3489e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.7320e-04 - val_loss: 2.0505e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.9965e-04 - val_loss: 1.2022e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.3080e-04 - val_loss: 1.4175e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2410e-04 - val_loss: 1.8513e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.5717e-04 - val_loss: 1.7268e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.4673e-04 - val_loss: 1.6878e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.9475e-04 - val_loss: 1.1344e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.8323e-04 - val_loss: 1.8237e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.5638e-04 - val_loss: 6.8399e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.7754e-04 - val_loss: 2.9928e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.1287e-04 - val_loss: 1.3223e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.6368e-04 - val_loss: 2.1357e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2047e-04 - val_loss: 1.2476e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.1012e-04 - val_loss: 5.9039e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.5017e-04 - val_loss: 1.6843e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2945e-04 - val_loss: 5.3479e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.3543e-04 - val_loss: 1.9185e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.0975e-04 - val_loss: 2.9232e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.3658e-04 - val_loss: 2.4755e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2720e-04 - val_loss: 1.5897e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.6682e-04 - val_loss: 2.9147e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.8979e-04 - val_loss: 1.9522e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.2048e-04 - val_loss: 4.7962e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.0557e-04 - val_loss: 1.2742e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.4268e-04 - val_loss: 1.4273e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.3792e-04 - val_loss: 2.1002e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.1574e-04 - val_loss: 1.3638e-04\n",
      "9/9 [==============================] - 3s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 748.4604107033904\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 23s 47ms/step - loss: 0.0039 - val_loss: 2.6115e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 10s - loss: 4.7637e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 9.0140e-04 - val_loss: 3.1365e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0011 - val_loss: 7.2087e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.7411e-04 - val_loss: 0.0022\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.7189e-04 - val_loss: 1.3770e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 9.5584e-04 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 1.6264e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.7928e-04 - val_loss: 4.6064e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.2238e-04 - val_loss: 9.2701e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.9070e-04 - val_loss: 1.6908e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.5051e-04 - val_loss: 1.6976e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.1024e-04 - val_loss: 1.4113e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.0844e-04 - val_loss: 1.2576e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.2796e-04 - val_loss: 3.8701e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.2761e-04 - val_loss: 2.1552e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.3481e-04 - val_loss: 1.3279e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.1284e-04 - val_loss: 2.6949e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.9037e-04 - val_loss: 1.3453e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.0276e-04 - val_loss: 1.9772e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.7982e-04 - val_loss: 1.6226e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.2284e-04 - val_loss: 1.7142e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.4535e-04 - val_loss: 1.2748e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.6848e-04 - val_loss: 1.5791e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.6099e-04 - val_loss: 1.7034e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.2205e-04 - val_loss: 1.6205e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.0911e-04 - val_loss: 1.1157e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.4173e-04 - val_loss: 2.0258e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.4759e-04 - val_loss: 5.7143e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8134e-04 - val_loss: 1.7457e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.8922e-04 - val_loss: 1.8882e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.0779e-04 - val_loss: 1.2523e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7398e-04 - val_loss: 1.7321e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.3977e-04 - val_loss: 1.1892e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.7560e-04 - val_loss: 1.3735e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.3253e-04 - val_loss: 1.9953e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7020e-04 - val_loss: 4.2164e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.9566e-04 - val_loss: 1.1888e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.6664e-04 - val_loss: 2.5555e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8347e-04 - val_loss: 2.6034e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7920e-04 - val_loss: 2.6211e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.4165e-04 - val_loss: 1.3086e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.5132e-04 - val_loss: 1.2655e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.7411e-04 - val_loss: 1.5807e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.6911e-04 - val_loss: 1.0994e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7713e-04 - val_loss: 1.1563e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.3557e-04 - val_loss: 1.4051e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.3604e-04 - val_loss: 1.1929e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.5009e-04 - val_loss: 1.1471e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.8184e-04 - val_loss: 1.3945e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.4538e-04 - val_loss: 2.4010e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.1083e-04 - val_loss: 9.4759e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8394e-04 - val_loss: 1.2614e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8964e-04 - val_loss: 1.1541e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.0382e-04 - val_loss: 1.1460e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.5582e-04 - val_loss: 1.6929e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.3896e-04 - val_loss: 1.4699e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.6753e-04 - val_loss: 1.1171e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 5.6684e-04 - val_loss: 1.1416e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.5982e-04 - val_loss: 2.3581e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.0466e-04 - val_loss: 3.1234e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 5.0026e-04 - val_loss: 1.2531e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.4817e-04 - val_loss: 1.3413e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9431e-04 - val_loss: 1.4452e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 5.7116e-04 - val_loss: 1.2959e-04\n",
      "9/9 [==============================] - 2s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 751.0444186266182\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 33s 65ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 13s - loss: 0.0023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 49ms/step - loss: 0.0017 - val_loss: 3.1357e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.5058e-04 - val_loss: 3.3521e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0010 - val_loss: 1.8509e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0013 - val_loss: 2.7893e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.1671e-04 - val_loss: 1.5841e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.5409e-04 - val_loss: 9.1533e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.0193e-04 - val_loss: 2.5219e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 9.3651e-04 - val_loss: 1.7862e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.5229e-04 - val_loss: 1.9940e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.1183e-04 - val_loss: 1.4510e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 9.0093e-04 - val_loss: 1.7153e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.0348e-04 - val_loss: 7.1395e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.4898e-04 - val_loss: 1.6700e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.0519e-04 - val_loss: 3.0458e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 14s 50ms/step - loss: 7.4440e-04 - val_loss: 2.1121e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.6207e-04 - val_loss: 2.3229e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.5939e-04 - val_loss: 1.3521e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.6753e-04 - val_loss: 1.5436e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.1409e-04 - val_loss: 5.6367e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 7.1722e-04 - val_loss: 1.6414e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.4999e-04 - val_loss: 5.7971e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.0132e-04 - val_loss: 2.0279e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.2121e-04 - val_loss: 1.3727e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.1296e-04 - val_loss: 1.1315e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.6172e-04 - val_loss: 1.8117e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.8149e-04 - val_loss: 1.1266e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.2403e-04 - val_loss: 4.4626e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.2769e-04 - val_loss: 3.1432e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.9421e-04 - val_loss: 1.2746e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.5808e-04 - val_loss: 1.1591e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.0931e-04 - val_loss: 1.1592e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.0028e-04 - val_loss: 2.8788e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.6906e-04 - val_loss: 2.7702e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.8563e-04 - val_loss: 1.1975e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.7738e-04 - val_loss: 1.9071e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0864e-04 - val_loss: 1.7371e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.4500e-04 - val_loss: 2.2688e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.3358e-04 - val_loss: 2.3168e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 5.5243e-04 - val_loss: 2.0241e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.4621e-04 - val_loss: 1.6140e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.6303e-04 - val_loss: 1.4545e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.1052e-04 - val_loss: 1.2729e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.0734e-04 - val_loss: 2.6030e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.4834e-04 - val_loss: 1.1897e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.2015e-04 - val_loss: 1.8808e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.3423e-04 - val_loss: 2.0339e-04\n",
      "9/9 [==============================] - 3s 33ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 744.9672838049554\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 19s 34ms/step - loss: 0.0045 - val_loss: 2.9317e-04\n",
      "Epoch 2/100\n",
      "  4/268 [..............................] - ETA: 6s - loss: 0.0012    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0014 - val_loss: 2.7095e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 9.2202e-04 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.4271e-04 - val_loss: 2.3330e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.8635e-04 - val_loss: 1.4776e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.3601e-04 - val_loss: 4.8399e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.6782e-04 - val_loss: 1.4881e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1818e-04 - val_loss: 4.3382e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.1080e-04 - val_loss: 1.8034e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.4245e-04 - val_loss: 1.6340e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.7337e-04 - val_loss: 3.7233e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.6927e-04 - val_loss: 1.7658e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7505e-04 - val_loss: 6.7787e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0010 - val_loss: 4.4739e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0927e-04 - val_loss: 1.2640e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2101e-04 - val_loss: 3.0740e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.6412e-04 - val_loss: 2.6019e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.4443e-04 - val_loss: 1.4177e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0563e-04 - val_loss: 1.4732e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2002e-04 - val_loss: 1.3173e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.3215e-04 - val_loss: 5.3673e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2048e-04 - val_loss: 1.1521e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2616e-04 - val_loss: 2.8287e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7833e-04 - val_loss: 2.8725e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.7758e-04 - val_loss: 2.2238e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7058e-04 - val_loss: 5.0806e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1992e-04 - val_loss: 1.1041e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.0772e-04 - val_loss: 1.2098e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.5450e-04 - val_loss: 3.1016e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.2074e-04 - val_loss: 1.1237e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2593e-04 - val_loss: 4.0219e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.9186e-04 - val_loss: 1.1232e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.7543e-04 - val_loss: 3.2507e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7653e-04 - val_loss: 1.2616e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7368e-04 - val_loss: 3.0986e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0711e-04 - val_loss: 5.0567e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0440e-04 - val_loss: 1.1527e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7234e-04 - val_loss: 1.8699e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.7816e-04 - val_loss: 1.2366e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 5.8992e-04 - val_loss: 1.0917e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.6976e-04 - val_loss: 1.4215e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5254e-04 - val_loss: 1.3046e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.9734e-04 - val_loss: 1.2326e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.0905e-04 - val_loss: 3.0950e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1514e-04 - val_loss: 1.2802e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0059e-04 - val_loss: 1.9426e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.0934e-04 - val_loss: 4.4115e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.9081e-04 - val_loss: 1.0726e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5012e-04 - val_loss: 3.2498e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.6633e-04 - val_loss: 3.0545e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5263e-04 - val_loss: 1.2227e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.4254e-04 - val_loss: 1.0878e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1224e-04 - val_loss: 4.6098e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1725e-04 - val_loss: 1.9117e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2948e-04 - val_loss: 1.1774e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7465e-04 - val_loss: 3.2971e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.6662e-04 - val_loss: 3.0349e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2705e-04 - val_loss: 1.0887e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.4615e-04 - val_loss: 1.1146e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1880e-04 - val_loss: 2.2906e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7960e-04 - val_loss: 1.6420e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.4326e-04 - val_loss: 2.8864e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5599e-04 - val_loss: 1.8434e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5222e-04 - val_loss: 1.0781e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.3582e-04 - val_loss: 1.2026e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.5187e-04 - val_loss: 2.1765e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7565e-04 - val_loss: 5.0693e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.2573e-04 - val_loss: 1.0731e-04\n",
      "9/9 [==============================] - 2s 15ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 739.0995196881445\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 25s 43ms/step - loss: 0.0038 - val_loss: 3.8286e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0020 - val_loss: 2.4652e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.0840e-04 - val_loss: 3.4344e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.8593e-04 - val_loss: 7.3424e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.4257e-04 - val_loss: 2.0029e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.5600e-04 - val_loss: 1.4373e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 9.9561e-04 - val_loss: 1.5743e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0011 - val_loss: 5.9749e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 8.0784e-04 - val_loss: 7.3247e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.1734e-04 - val_loss: 1.4363e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.3512e-04 - val_loss: 2.5121e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.8280e-04 - val_loss: 1.4527e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.8569e-04 - val_loss: 2.1302e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.4320e-04 - val_loss: 1.7673e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.1485e-04 - val_loss: 9.0219e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.0825e-04 - val_loss: 8.0746e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.4871e-04 - val_loss: 7.9096e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 7.4528e-04 - val_loss: 1.6837e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.8142e-04 - val_loss: 1.2267e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.9145e-04 - val_loss: 8.2857e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.8125e-04 - val_loss: 1.5308e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.1718e-04 - val_loss: 1.2812e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.2246e-04 - val_loss: 1.2999e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.0151e-04 - val_loss: 1.0906e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.1241e-04 - val_loss: 1.1266e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 5.5878e-04 - val_loss: 1.4731e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.4358e-04 - val_loss: 1.3879e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9104e-04 - val_loss: 1.2068e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.5625e-04 - val_loss: 1.2554e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 7.4849e-04 - val_loss: 1.7133e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.4346e-04 - val_loss: 1.2213e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.8249e-04 - val_loss: 1.1962e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.4793e-04 - val_loss: 1.0922e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.8715e-04 - val_loss: 1.0751e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.0667e-04 - val_loss: 1.2518e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 5.2843e-04 - val_loss: 1.5562e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.0555e-04 - val_loss: 1.5106e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.8155e-04 - val_loss: 1.1619e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.1658e-04 - val_loss: 1.8108e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.4652e-04 - val_loss: 1.7679e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.2916e-04 - val_loss: 1.4014e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.4180e-04 - val_loss: 1.1623e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 5.9588e-04 - val_loss: 1.1319e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.1367e-04 - val_loss: 1.0880e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.1513e-04 - val_loss: 1.6082e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 5.4295e-04 - val_loss: 1.1092e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.6620e-04 - val_loss: 1.0948e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.2520e-04 - val_loss: 1.3041e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 5.8858e-04 - val_loss: 1.0827e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9026e-04 - val_loss: 1.2313e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.4975e-04 - val_loss: 2.5234e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.6960e-04 - val_loss: 1.2840e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.6858e-04 - val_loss: 6.9204e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.3157e-04 - val_loss: 5.0617e-04\n",
      "9/9 [==============================] - 3s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 738.0897380165186\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 21s 42ms/step - loss: 0.0046 - val_loss: 2.9151e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 4.1672e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0013 - val_loss: 1.9048e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.5057e-04 - val_loss: 3.6044e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.8607e-04 - val_loss: 3.9308e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.6818e-04 - val_loss: 1.5243e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.3472e-04 - val_loss: 7.3655e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.6391e-04 - val_loss: 3.3813e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.2304e-04 - val_loss: 1.4754e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.4107e-04 - val_loss: 1.3261e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.7989e-04 - val_loss: 5.0440e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.2811e-04 - val_loss: 2.8241e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.1414e-04 - val_loss: 1.2067e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.8149e-04 - val_loss: 5.7914e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.0311e-04 - val_loss: 3.0450e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.4588e-04 - val_loss: 1.5990e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.8506e-04 - val_loss: 4.9270e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.5400e-04 - val_loss: 1.3258e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.9887e-04 - val_loss: 3.0216e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.5482e-04 - val_loss: 3.2961e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2068e-04 - val_loss: 1.8419e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.5788e-04 - val_loss: 6.4426e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 6.6290e-04 - val_loss: 1.1937e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.0429e-04 - val_loss: 1.1258e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.5500e-04 - val_loss: 1.2398e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.6805e-04 - val_loss: 1.1136e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 5.7235e-04 - val_loss: 1.1418e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2387e-04 - val_loss: 1.5090e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.2720e-04 - val_loss: 1.4765e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.4288e-04 - val_loss: 1.1108e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2696e-04 - val_loss: 1.6393e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2007e-04 - val_loss: 1.5184e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.7227e-04 - val_loss: 1.8645e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.3117e-04 - val_loss: 1.9413e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.0617e-04 - val_loss: 1.3904e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.0287e-04 - val_loss: 2.3323e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.8491e-04 - val_loss: 1.6195e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.4341e-04 - val_loss: 2.3086e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.1627e-04 - val_loss: 1.2404e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.8450e-04 - val_loss: 2.5600e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.0506e-04 - val_loss: 1.3795e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.3194e-04 - val_loss: 1.5920e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9733e-04 - val_loss: 1.9074e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.5977e-04 - val_loss: 5.7063e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.8096e-04 - val_loss: 1.4263e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.6251e-04 - val_loss: 1.4275e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.6631e-04 - val_loss: 1.3441e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2869e-04 - val_loss: 1.5711e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.1805e-04 - val_loss: 1.3455e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.5585e-04 - val_loss: 1.3516e-04\n",
      "9/9 [==============================] - 3s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 788.2587605921552\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 27s 51ms/step - loss: 0.0072 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 10s - loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0018 - val_loss: 2.8583e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0010 - val_loss: 2.8096e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.0068e-04 - val_loss: 3.1554e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0014 - val_loss: 3.9786e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.4829e-04 - val_loss: 3.2165e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0011 - val_loss: 1.8552e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.3612e-04 - val_loss: 2.5382e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 9.2923e-04 - val_loss: 4.2210e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.0199e-04 - val_loss: 1.5426e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.9604e-04 - val_loss: 8.3815e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 0.0011 - val_loss: 3.8252e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.9564e-04 - val_loss: 3.1216e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.9067e-04 - val_loss: 1.5872e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.4713e-04 - val_loss: 4.6574e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.8089e-04 - val_loss: 1.5589e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.4602e-04 - val_loss: 1.1424e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.4663e-04 - val_loss: 1.4651e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.6358e-04 - val_loss: 1.2601e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.7265e-04 - val_loss: 6.4136e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 0.0011 - val_loss: 4.0608e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.1634e-04 - val_loss: 2.9312e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.3144e-04 - val_loss: 1.4962e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.0880e-04 - val_loss: 1.2870e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.4933e-04 - val_loss: 2.5993e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.1342e-04 - val_loss: 9.0042e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.8785e-04 - val_loss: 1.1622e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.6763e-04 - val_loss: 1.0702e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.7941e-04 - val_loss: 1.1881e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.3934e-04 - val_loss: 1.3606e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.6721e-04 - val_loss: 2.1088e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0897e-04 - val_loss: 1.0600e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.9958e-04 - val_loss: 1.0510e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 5.6285e-04 - val_loss: 1.5181e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.2836e-04 - val_loss: 1.4012e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.9616e-04 - val_loss: 6.5479e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.6357e-04 - val_loss: 1.8888e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.6462e-04 - val_loss: 1.0795e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.7853e-04 - val_loss: 2.6672e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.2995e-04 - val_loss: 5.4051e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.2996e-04 - val_loss: 1.5941e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.3719e-04 - val_loss: 1.6694e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.9718e-04 - val_loss: 1.2034e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.6712e-04 - val_loss: 2.4363e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.1494e-04 - val_loss: 1.5824e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.8385e-04 - val_loss: 1.1408e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.3225e-04 - val_loss: 1.2845e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8213e-04 - val_loss: 1.9908e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.6372e-04 - val_loss: 0.0013\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0520e-04 - val_loss: 2.7091e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.5024e-04 - val_loss: 2.8436e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 5.7541e-04 - val_loss: 1.0796e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.4962e-04 - val_loss: 1.3830e-04\n",
      "9/9 [==============================] - 3s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 797.4305103443014\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 50ms/step - loss: 0.0064 - val_loss: 4.4709e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 0.0010    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0011 - val_loss: 6.1910e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 9.9445e-04 - val_loss: 2.3957e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.5098e-04 - val_loss: 2.4878e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.2960e-04 - val_loss: 1.8386e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.8649e-04 - val_loss: 2.3331e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.4545e-04 - val_loss: 2.0375e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.8622e-04 - val_loss: 1.5752e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.5042e-04 - val_loss: 1.4949e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.6673e-04 - val_loss: 2.7810e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.7234e-04 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.3328e-04 - val_loss: 2.3993e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.2435e-04 - val_loss: 1.7071e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.0285e-04 - val_loss: 2.5313e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8130e-04 - val_loss: 1.7398e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.6587e-04 - val_loss: 1.2228e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.8569e-04 - val_loss: 1.9515e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.2581e-04 - val_loss: 1.6490e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.7620e-04 - val_loss: 1.5838e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.6854e-04 - val_loss: 1.3812e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.3341e-04 - val_loss: 3.6610e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.6053e-04 - val_loss: 3.7222e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.2536e-04 - val_loss: 1.8350e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.7103e-04 - val_loss: 2.4968e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.4513e-04 - val_loss: 1.4298e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.7221e-04 - val_loss: 1.2866e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.4600e-04 - val_loss: 2.6850e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.9138e-04 - val_loss: 1.3592e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.3682e-04 - val_loss: 1.4000e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3621e-04 - val_loss: 6.3058e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.8668e-04 - val_loss: 2.5061e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.3363e-04 - val_loss: 4.0245e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.5206e-04 - val_loss: 1.2301e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.3454e-04 - val_loss: 1.5671e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.5561e-04 - val_loss: 2.3779e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.6399e-04 - val_loss: 1.4324e-04\n",
      "9/9 [==============================] - 3s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 827.3478302313071\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 22s 64ms/step - loss: 0.0103 - val_loss: 4.1774e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0013 - val_loss: 4.6620e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0015 - val_loss: 8.1300e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.8025e-04 - val_loss: 2.2494e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.7903e-04 - val_loss: 2.3119e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.9576e-04 - val_loss: 1.8472e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3744e-04 - val_loss: 2.2858e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.5879e-04 - val_loss: 1.5483e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.3839e-04 - val_loss: 1.9687e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.8855e-04 - val_loss: 1.5980e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.0397e-04 - val_loss: 1.8250e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.6852e-04 - val_loss: 3.8374e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.1771e-04 - val_loss: 1.3205e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.2153e-04 - val_loss: 2.1694e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.6091e-04 - val_loss: 1.6816e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.5199e-04 - val_loss: 4.8338e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.6260e-04 - val_loss: 2.6595e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.5179e-04 - val_loss: 1.7978e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.3322e-04 - val_loss: 1.4803e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.6360e-04 - val_loss: 4.3466e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.7153e-04 - val_loss: 1.4868e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.7397e-04 - val_loss: 1.8305e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1359e-04 - val_loss: 1.3290e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.1653e-04 - val_loss: 4.1198e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.4246e-04 - val_loss: 3.2574e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3184e-04 - val_loss: 1.6330e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.4287e-04 - val_loss: 1.8603e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1113e-04 - val_loss: 2.9350e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3415e-04 - val_loss: 1.4226e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.2300e-04 - val_loss: 3.8337e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.0242e-04 - val_loss: 1.2594e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.9513e-04 - val_loss: 1.3739e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.8860e-04 - val_loss: 2.8086e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 4.9752e-04 - val_loss: 4.9113e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3504e-04 - val_loss: 2.6333e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.4091e-04 - val_loss: 2.4235e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.1875e-04 - val_loss: 1.7198e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.8965e-04 - val_loss: 3.3401e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.0994e-04 - val_loss: 2.1737e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.2715e-04 - val_loss: 1.5845e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.5506e-04 - val_loss: 1.6251e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.1348e-04 - val_loss: 2.0243e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.7577e-04 - val_loss: 1.2290e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.6220e-04 - val_loss: 1.1291e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.3544e-04 - val_loss: 1.7727e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.7085e-04 - val_loss: 2.6383e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.0644e-04 - val_loss: 1.8828e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.2290e-04 - val_loss: 2.8987e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.7402e-04 - val_loss: 1.3169e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.6454e-04 - val_loss: 1.4781e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.4094e-04 - val_loss: 3.3337e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.3036e-04 - val_loss: 3.6896e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.3956e-04 - val_loss: 4.9851e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.5029e-04 - val_loss: 1.7268e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.3895e-04 - val_loss: 1.2053e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.4788e-04 - val_loss: 1.5391e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.7914e-04 - val_loss: 4.0831e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.5438e-04 - val_loss: 3.2481e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.4317e-04 - val_loss: 3.0196e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.9499e-04 - val_loss: 1.4764e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.2353e-04 - val_loss: 4.0569e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.5469e-04 - val_loss: 2.4958e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.1804e-04 - val_loss: 1.2526e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.1968e-04 - val_loss: 1.1942e-04\n",
      "9/9 [==============================] - 4s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 798.2193347642196\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 18s 60ms/step - loss: 0.0057 - val_loss: 3.9218e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0011 - val_loss: 3.6572e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 8.4282e-04 - val_loss: 2.8673e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.4322e-04 - val_loss: 2.0889e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.3121e-04 - val_loss: 1.4262e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.7538e-04 - val_loss: 1.4631e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.0268e-04 - val_loss: 1.5293e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 7.5885e-04 - val_loss: 1.5656e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 9.5536e-04 - val_loss: 3.9808e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.1326e-04 - val_loss: 2.4711e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 7.6857e-04 - val_loss: 3.7771e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.1141e-04 - val_loss: 3.5835e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.4727e-04 - val_loss: 2.0266e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.2860e-04 - val_loss: 2.1770e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 7.1135e-04 - val_loss: 7.5648e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.3032e-04 - val_loss: 2.2157e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 7.0290e-04 - val_loss: 4.0301e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.4179e-04 - val_loss: 2.5497e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 6.3750e-04 - val_loss: 1.3097e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.2914e-04 - val_loss: 2.3535e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.0902e-04 - val_loss: 1.8115e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.4415e-04 - val_loss: 3.5662e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 9.1010e-04 - val_loss: 1.8205e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.3416e-04 - val_loss: 1.2456e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.5770e-04 - val_loss: 1.4968e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.7044e-04 - val_loss: 1.2881e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.6322e-04 - val_loss: 2.3748e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.2978e-04 - val_loss: 2.3219e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.5223e-04 - val_loss: 1.1836e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 7.0872e-04 - val_loss: 1.4074e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.3357e-04 - val_loss: 1.1504e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.0837e-04 - val_loss: 7.0419e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.3897e-04 - val_loss: 3.9924e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.2303e-04 - val_loss: 2.9094e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 5.2898e-04 - val_loss: 2.2336e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.3214e-04 - val_loss: 1.2908e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.6431e-04 - val_loss: 1.1144e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.5792e-04 - val_loss: 1.2983e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.3179e-04 - val_loss: 1.7235e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.7821e-04 - val_loss: 1.2477e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.5380e-04 - val_loss: 2.2128e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.8089e-04 - val_loss: 1.2517e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.2583e-04 - val_loss: 3.6562e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 5.5185e-04 - val_loss: 8.2407e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.0516e-04 - val_loss: 6.8206e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.0901e-04 - val_loss: 1.3451e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.8393e-04 - val_loss: 1.4758e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.3791e-04 - val_loss: 1.6044e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 5.3336e-04 - val_loss: 1.2336e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 5.4322e-04 - val_loss: 2.0728e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.3380e-04 - val_loss: 1.3870e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.7993e-04 - val_loss: 2.6068e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.6856e-04 - val_loss: 1.7426e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.3089e-04 - val_loss: 1.3434e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.2256e-04 - val_loss: 1.2687e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 4.7282e-04 - val_loss: 1.3932e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.5821e-04 - val_loss: 1.3136e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 838.9994803811081\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 25s 85ms/step - loss: 0.0063 - val_loss: 6.1346e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 9.3272e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 65ms/step - loss: 0.0012 - val_loss: 2.8290e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0012 - val_loss: 2.3930e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.8344e-04 - val_loss: 3.3751e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 9.5606e-04 - val_loss: 4.0121e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 8.0020e-04 - val_loss: 1.6427e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.7458e-04 - val_loss: 1.5308e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.9861e-04 - val_loss: 1.6144e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0010 - val_loss: 2.9009e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.4607e-04 - val_loss: 4.8518e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0010 - val_loss: 1.3220e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 7.7601e-04 - val_loss: 4.9774e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 8.3917e-04 - val_loss: 3.3840e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.8112e-04 - val_loss: 1.6146e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.1661e-04 - val_loss: 1.7336e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.0824e-04 - val_loss: 6.0745e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 9.6310e-04 - val_loss: 3.9191e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.8970e-04 - val_loss: 2.6466e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 8.2715e-04 - val_loss: 4.8415e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.9784e-04 - val_loss: 1.2577e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.7012e-04 - val_loss: 1.5706e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 5.6208e-04 - val_loss: 2.7462e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 8.3903e-04 - val_loss: 1.7231e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.9082e-04 - val_loss: 1.5075e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.3561e-04 - val_loss: 2.7825e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.5597e-04 - val_loss: 1.4873e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.2209e-04 - val_loss: 1.3352e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.3369e-04 - val_loss: 4.7062e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.8111e-04 - val_loss: 1.1772e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.9064e-04 - val_loss: 1.7935e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.7651e-04 - val_loss: 1.2553e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.9745e-04 - val_loss: 2.0793e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.0785e-04 - val_loss: 1.1619e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.3835e-04 - val_loss: 4.8831e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.6537e-04 - val_loss: 1.6310e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.6920e-04 - val_loss: 1.3958e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 6.6841e-04 - val_loss: 1.6567e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 5.8382e-04 - val_loss: 2.3582e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.4851e-04 - val_loss: 1.1603e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 5.5914e-04 - val_loss: 1.5917e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 8.0659e-04 - val_loss: 1.7043e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 5.9400e-04 - val_loss: 1.1236e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.2715e-04 - val_loss: 1.6947e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 5.8132e-04 - val_loss: 1.3191e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.9329e-04 - val_loss: 1.2777e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.6786e-04 - val_loss: 1.4317e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 5.0316e-04 - val_loss: 1.3400e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.3782e-04 - val_loss: 2.9905e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.7378e-04 - val_loss: 2.4428e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.1796e-04 - val_loss: 5.5659e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.2085e-04 - val_loss: 4.5688e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.6135e-04 - val_loss: 4.4151e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.0784e-04 - val_loss: 1.8271e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 6.1806e-04 - val_loss: 1.6519e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.8549e-04 - val_loss: 1.2066e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.5991e-04 - val_loss: 1.1630e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.7556e-04 - val_loss: 1.6648e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 5.4074e-04 - val_loss: 1.4774e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.3147e-04 - val_loss: 1.1392e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.4758e-04 - val_loss: 1.2866e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 7.0841e-04 - val_loss: 1.1214e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.2157e-04 - val_loss: 1.4428e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.2491e-04 - val_loss: 4.9468e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.4445e-04 - val_loss: 1.3729e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 6.0672e-04 - val_loss: 1.6337e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.1261e-04 - val_loss: 1.1516e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 5.3925e-04 - val_loss: 1.1012e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.7809e-04 - val_loss: 1.1129e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 5.1040e-04 - val_loss: 2.2361e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 5.7964e-04 - val_loss: 1.2186e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 5.4094e-04 - val_loss: 1.9094e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 5.6492e-04 - val_loss: 1.9828e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.8897e-04 - val_loss: 1.5979e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.6334e-04 - val_loss: 2.8158e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 5.7175e-04 - val_loss: 1.3209e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 5.9369e-04 - val_loss: 1.3513e-04\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.5212e-04 - val_loss: 1.4132e-04\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 5.2819e-04 - val_loss: 2.0521e-04\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 5.4034e-04 - val_loss: 1.5367e-04\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 6.9100e-04 - val_loss: 1.7752e-04\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 5.2092e-04 - val_loss: 1.6605e-04\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 5.4398e-04 - val_loss: 1.2592e-04\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 5.4805e-04 - val_loss: 2.0049e-04\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 5.2578e-04 - val_loss: 1.2697e-04\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.2504e-04 - val_loss: 1.2157e-04\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 5.8472e-04 - val_loss: 2.0248e-04\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 5.2723e-04 - val_loss: 1.1874e-04\n",
      "9/9 [==============================] - 5s 38ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 779.181369503373\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 23s 63ms/step - loss: 0.0090 - val_loss: 7.4287e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 3s - loss: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0011 - val_loss: 2.5974e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.2844e-04 - val_loss: 3.4287e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6088e-04 - val_loss: 1.8759e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.0095e-04 - val_loss: 5.1114e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.5713e-04 - val_loss: 3.4496e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.5371e-04 - val_loss: 1.8549e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.8905e-04 - val_loss: 2.4513e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.4178e-04 - val_loss: 5.8266e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.9671e-04 - val_loss: 1.2426e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.5783e-04 - val_loss: 1.4293e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.6817e-04 - val_loss: 2.2246e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 5.8062e-04 - val_loss: 7.7974e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.7841e-04 - val_loss: 1.6462e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.3915e-04 - val_loss: 5.0675e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 8.2383e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9925e-04 - val_loss: 1.3954e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.6645e-04 - val_loss: 1.2176e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.5911e-04 - val_loss: 1.7131e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9670e-04 - val_loss: 3.0066e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.7353e-04 - val_loss: 1.7375e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.4168e-04 - val_loss: 2.4408e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.1787e-04 - val_loss: 7.4778e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.8639e-04 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.5414e-04 - val_loss: 5.1729e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.4561e-04 - val_loss: 1.9972e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.4115e-04 - val_loss: 1.1805e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 34ms/step - loss: 5.3316e-04 - val_loss: 1.1801e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.6076e-04 - val_loss: 5.2443e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.9949e-04 - val_loss: 2.4284e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.4914e-04 - val_loss: 1.8807e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.9071e-04 - val_loss: 1.8409e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.2100e-04 - val_loss: 1.1492e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.3465e-04 - val_loss: 1.1518e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.6920e-04 - val_loss: 1.8841e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.4732e-04 - val_loss: 3.3682e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.7501e-04 - val_loss: 1.4155e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.7162e-04 - val_loss: 1.3505e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.3579e-04 - val_loss: 1.1818e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.6578e-04 - val_loss: 1.6355e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.7107e-04 - val_loss: 1.3165e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8991e-04 - val_loss: 2.2418e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.3651e-04 - val_loss: 3.1523e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.5474e-04 - val_loss: 1.2278e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.2486e-04 - val_loss: 1.6363e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.2330e-04 - val_loss: 1.2145e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.2363e-04 - val_loss: 1.9657e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.5408e-04 - val_loss: 1.2375e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.5430e-04 - val_loss: 6.1354e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.7258e-04 - val_loss: 1.5214e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.2330e-04 - val_loss: 1.4269e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.4611e-04 - val_loss: 1.5788e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.5006e-04 - val_loss: 1.7467e-04\n",
      "9/9 [==============================] - 4s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 748.9246928013114\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 27s 69ms/step - loss: 0.0068 - val_loss: 4.9110e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 4s - loss: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0018 - val_loss: 4.1540e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0010 - val_loss: 2.6228e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.9033e-04 - val_loss: 2.1695e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.5127e-04 - val_loss: 5.6622e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.2802e-04 - val_loss: 2.8315e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.5440e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.3825e-04 - val_loss: 3.8906e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.1161e-04 - val_loss: 1.3446e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.7343e-04 - val_loss: 1.5077e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.1736e-04 - val_loss: 1.4696e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.6516e-04 - val_loss: 1.4014e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.2804e-04 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.0581e-04 - val_loss: 3.4885e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.6359e-04 - val_loss: 2.2647e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.5399e-04 - val_loss: 2.6457e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.6392e-04 - val_loss: 2.0333e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.3055e-04 - val_loss: 6.2353e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.4978e-04 - val_loss: 1.6661e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.8458e-04 - val_loss: 3.2211e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.5783e-04 - val_loss: 1.9631e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.8871e-04 - val_loss: 5.9481e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.3457e-04 - val_loss: 3.5385e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.9533e-04 - val_loss: 1.6135e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.9270e-04 - val_loss: 1.9353e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.2122e-04 - val_loss: 1.3177e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1439e-04 - val_loss: 1.8030e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.2964e-04 - val_loss: 1.2069e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.6575e-04 - val_loss: 2.4850e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.8991e-04 - val_loss: 1.5765e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.6562e-04 - val_loss: 2.3157e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.2079e-04 - val_loss: 1.2937e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.8327e-04 - val_loss: 1.5925e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.1504e-04 - val_loss: 1.9428e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.5509e-04 - val_loss: 1.2466e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.3546e-04 - val_loss: 1.3760e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.9833e-04 - val_loss: 1.3234e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.6261e-04 - val_loss: 1.3598e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8179e-04 - val_loss: 5.7558e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.3969e-04 - val_loss: 2.3913e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.9247e-04 - val_loss: 2.0396e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.3522e-04 - val_loss: 3.5658e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.0756e-04 - val_loss: 2.3076e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.6786e-04 - val_loss: 1.4302e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.2619e-04 - val_loss: 1.1730e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.2592e-04 - val_loss: 3.0226e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.5745e-04 - val_loss: 1.1971e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 4.9755e-04 - val_loss: 1.0891e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.1284e-04 - val_loss: 1.6416e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.1803e-04 - val_loss: 1.5585e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.1743e-04 - val_loss: 1.3944e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.8462e-04 - val_loss: 1.8242e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.2019e-04 - val_loss: 1.9398e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8889e-04 - val_loss: 2.0264e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.3389e-04 - val_loss: 1.3207e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.3885e-04 - val_loss: 1.3209e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8751e-04 - val_loss: 1.8083e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 4.8958e-04 - val_loss: 1.4544e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.1376e-04 - val_loss: 1.2758e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.9298e-04 - val_loss: 1.4308e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.5398e-04 - val_loss: 1.7471e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.4202e-04 - val_loss: 1.1916e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.6804e-04 - val_loss: 1.5141e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1539e-04 - val_loss: 1.1922e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.3294e-04 - val_loss: 1.4975e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.5569e-04 - val_loss: 1.3840e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.1231e-04 - val_loss: 1.2897e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8212e-04 - val_loss: 1.2293e-04\n",
      "9/9 [==============================] - 5s 20ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 736.084888853663\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 24s 78ms/step - loss: 0.0057 - val_loss: 4.7596e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 4s - loss: 4.9084e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 9.5787e-04 - val_loss: 2.2244e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0012 - val_loss: 2.0397e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.4612e-04 - val_loss: 2.3379e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.6277e-04 - val_loss: 1.3251e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.7740e-04 - val_loss: 1.4099e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.6896e-04 - val_loss: 3.1072e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 6.4231e-04 - val_loss: 1.8691e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.8438e-04 - val_loss: 1.3228e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.3009e-04 - val_loss: 1.3119e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.0238e-04 - val_loss: 5.7102e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.3198e-04 - val_loss: 1.5412e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.7417e-04 - val_loss: 1.5360e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 7.2619e-04 - val_loss: 1.8613e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.9649e-04 - val_loss: 1.2656e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.4518e-04 - val_loss: 1.3176e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.5923e-04 - val_loss: 4.0413e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.8700e-04 - val_loss: 4.5351e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.0812e-04 - val_loss: 7.1582e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.8980e-04 - val_loss: 3.4097e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.5906e-04 - val_loss: 1.8593e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.5204e-04 - val_loss: 1.4669e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.6435e-04 - val_loss: 1.5231e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.0527e-04 - val_loss: 1.2886e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.9881e-04 - val_loss: 1.1971e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.3208e-04 - val_loss: 2.3455e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.5568e-04 - val_loss: 1.8032e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 7.0749e-04 - val_loss: 1.1459e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.5313e-04 - val_loss: 1.8457e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 7.6446e-04 - val_loss: 3.2037e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.3053e-04 - val_loss: 3.3270e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.6780e-04 - val_loss: 8.1113e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.7125e-04 - val_loss: 1.1842e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.8886e-04 - val_loss: 1.8221e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.9425e-04 - val_loss: 1.2867e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.2973e-04 - val_loss: 1.2372e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.6974e-04 - val_loss: 6.1960e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.2918e-04 - val_loss: 1.1067e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.5591e-04 - val_loss: 2.4508e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.7190e-04 - val_loss: 1.0871e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.9698e-04 - val_loss: 1.0958e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.8913e-04 - val_loss: 1.2229e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.7236e-04 - val_loss: 3.6587e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 6.3238e-04 - val_loss: 1.8602e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.2629e-04 - val_loss: 1.3246e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.8076e-04 - val_loss: 1.0891e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.4039e-04 - val_loss: 1.2321e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.0432e-04 - val_loss: 1.2966e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.2618e-04 - val_loss: 1.4360e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.7912e-04 - val_loss: 1.1288e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.3546e-04 - val_loss: 1.6080e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.1020e-04 - val_loss: 1.3119e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.6467e-04 - val_loss: 1.4832e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.1546e-04 - val_loss: 1.4051e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.0878e-04 - val_loss: 1.0622e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.3503e-04 - val_loss: 2.1929e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.2664e-04 - val_loss: 3.3527e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.7455e-04 - val_loss: 3.4277e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.4947e-04 - val_loss: 2.7765e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.2191e-04 - val_loss: 1.5043e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.5620e-04 - val_loss: 1.6239e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.9323e-04 - val_loss: 2.2784e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.2177e-04 - val_loss: 1.2445e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.7356e-04 - val_loss: 1.2623e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.5763e-04 - val_loss: 3.8240e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.2996e-04 - val_loss: 1.3220e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.1994e-04 - val_loss: 1.8927e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.8847e-04 - val_loss: 1.1441e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.6951e-04 - val_loss: 2.1431e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.6372e-04 - val_loss: 1.6350e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.5291e-04 - val_loss: 1.2215e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.4658e-04 - val_loss: 1.1725e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.7522e-04 - val_loss: 2.4485e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.2945e-04 - val_loss: 3.1040e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.5731e-04 - val_loss: 1.1769e-04\n",
      "9/9 [==============================] - 4s 27ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 816.2689849825612\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 29s 81ms/step - loss: 0.0059 - val_loss: 5.4049e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0012 - val_loss: 2.5343e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.1880e-04 - val_loss: 2.6289e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 8.8936e-04 - val_loss: 2.2825e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.6288e-04 - val_loss: 1.8019e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.7138e-04 - val_loss: 5.0215e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 7.7198e-04 - val_loss: 5.0566e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.6236e-04 - val_loss: 1.6366e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0011 - val_loss: 3.6125e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.4649e-04 - val_loss: 2.8087e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.6020e-04 - val_loss: 1.5055e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.3011e-04 - val_loss: 1.3374e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.9628e-04 - val_loss: 8.4913e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.2884e-04 - val_loss: 1.3714e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.3721e-04 - val_loss: 2.6968e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0011 - val_loss: 5.0462e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.3476e-04 - val_loss: 2.8000e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.5892e-04 - val_loss: 1.3490e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.6349e-04 - val_loss: 2.7841e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.9104e-04 - val_loss: 7.2009e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.8805e-04 - val_loss: 3.4217e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 8.0886e-04 - val_loss: 1.6293e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 5.9960e-04 - val_loss: 1.2944e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.8198e-04 - val_loss: 1.1495e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.5576e-04 - val_loss: 1.2431e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.5825e-04 - val_loss: 4.1940e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 7.3802e-04 - val_loss: 2.1557e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.2591e-04 - val_loss: 1.1541e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.1621e-04 - val_loss: 3.6347e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.6492e-04 - val_loss: 1.7846e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.7627e-04 - val_loss: 1.0918e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.2910e-04 - val_loss: 1.1157e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.2788e-04 - val_loss: 1.8330e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.6028e-04 - val_loss: 1.3448e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.6095e-04 - val_loss: 2.7424e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.1632e-04 - val_loss: 1.1995e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 5.9523e-04 - val_loss: 1.3547e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.9755e-04 - val_loss: 3.5090e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.7737e-04 - val_loss: 1.1668e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.0600e-04 - val_loss: 1.5055e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.8307e-04 - val_loss: 1.0795e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.2939e-04 - val_loss: 1.0625e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.4634e-04 - val_loss: 1.6796e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 5.7305e-04 - val_loss: 1.5602e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 5.9263e-04 - val_loss: 1.1659e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.6392e-04 - val_loss: 1.8619e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.3294e-04 - val_loss: 2.1119e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.8669e-04 - val_loss: 1.1538e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.6124e-04 - val_loss: 1.5640e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.2795e-04 - val_loss: 1.1434e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.5532e-04 - val_loss: 2.0007e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.7249e-04 - val_loss: 2.2642e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 6.3321e-04 - val_loss: 1.1954e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.2536e-04 - val_loss: 1.0649e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.9535e-04 - val_loss: 1.2709e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.8232e-04 - val_loss: 1.1303e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.1782e-04 - val_loss: 1.0754e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.7439e-04 - val_loss: 1.7906e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.3035e-04 - val_loss: 1.8786e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 5.2156e-04 - val_loss: 2.0825e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.0645e-04 - val_loss: 1.1025e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 5.8977e-04 - val_loss: 1.5086e-04\n",
      "9/9 [==============================] - 5s 37ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 748.2305518735043\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_gru_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb47724-ed7d-4118-b12e-283c322ba18c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 832.456450107897}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 748.4604107033904}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 751.0444186266182}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 744.9672838049554}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 739.0995196881445}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 738.0897380165186}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 788.2587605921552}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 797.4305103443014}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 827.3478302313071}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 798.2193347642196}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 838.9994803811081}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 779.181369503373}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 748.9246928013114}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 736.084888853663}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 816.2689849825612}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 748.2305518735043}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad361e05-8c9b-42de-a715-70c3db257b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df1 = yf.download(\"BTC-USD\", \"2020-01-01\", \"2024-01-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a523be2e-968f-4c7d-b513-1fc11cef916e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df1[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9a3ecc-684f-4364-bc3c-0e978891b7a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67566.828125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4bf4992-fbb2-4408-958f-a9c1aeaeb7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4970.7880859375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b35a1-944c-4431-9fce-8fdfb63191ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
