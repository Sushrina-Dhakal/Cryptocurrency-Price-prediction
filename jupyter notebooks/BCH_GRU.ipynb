{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847153b4-d4af-41a4-992b-b9a5bf35210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09cf3a6-af8d-4283-8ea6-6097de7a8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d77eebe-b055-46d9-b90c-c46ad9dc2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02c85f3-4356-4564-b497-5f75c98edb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    df = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values #optional\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8eee78-6d1f-4147-9676-97cb22e77dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(GRU(units, return_sequences=True))\n",
    "    model.add(GRU(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3d5711-1704-4f19-b1b8-2dcf75ae3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    gru_loss_history = loss_history.history['loss'] # unnecessary line\n",
    "    \n",
    "    gru_predictions = model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, gru_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"BCH_model_gru.pkl\")\n",
    "        \n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(gru_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BCH_actual_vs_predicted_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BCH_loss_curve_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19aeb2ff-cc11-4447-9edb-13e79e510935",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'BCH-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70870bf8-c413-4cb1-a503-fc6ed13ea1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,20]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecfab0a-8ee1-4ac1-8bb4-5fed2c4046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b52e73e-2dd8-496a-912a-c41ed65ca9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f90938b-a84e-40a4-b60d-6c48dd629f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 17s 34ms/step - loss: 0.0026 - val_loss: 1.5717e-05\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 2.2549e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0010 - val_loss: 2.1172e-05\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0012 - val_loss: 4.2607e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 9.7470e-04 - val_loss: 8.0175e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.2481e-04 - val_loss: 4.7924e-05\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0010 - val_loss: 4.7075e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.6563e-04 - val_loss: 1.9392e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.5841e-04 - val_loss: 2.1505e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.4789e-04 - val_loss: 8.0729e-06\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.3741e-04 - val_loss: 1.0675e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 8.7260e-04 - val_loss: 6.6573e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 7.9280e-04 - val_loss: 2.7051e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0010 - val_loss: 8.2124e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0012 - val_loss: 4.0876e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.3682e-04 - val_loss: 1.0264e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.5826e-04 - val_loss: 1.5020e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 7.7975e-04 - val_loss: 7.6500e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.6914e-04 - val_loss: 7.7068e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.6851e-04 - val_loss: 3.4037e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.5407e-04 - val_loss: 7.2848e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.8913e-04 - val_loss: 4.6419e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.9631e-04 - val_loss: 7.9331e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.0172e-04 - val_loss: 3.1421e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.4907e-04 - val_loss: 1.5261e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.0455e-04 - val_loss: 1.1163e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.0130e-04 - val_loss: 1.4981e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.6770e-04 - val_loss: 1.4665e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.1316e-04 - val_loss: 1.6627e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1948e-04 - val_loss: 2.1492e-04\n",
      "9/9 [==============================] - 2s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.516443595185972\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 21s 44ms/step - loss: 0.0030 - val_loss: 1.0548e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 3.3167e-04 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 9.6274e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0017 - val_loss: 1.8496e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.1269e-04 - val_loss: 4.2344e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.7246e-04 - val_loss: 1.7848e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.0928e-04 - val_loss: 2.3844e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.9112e-04 - val_loss: 3.5405e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0012 - val_loss: 3.2595e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.5019e-04 - val_loss: 8.6341e-06\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0010 - val_loss: 1.9724e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.1282e-04 - val_loss: 5.5152e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.7518e-04 - val_loss: 7.8888e-06\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.5490e-04 - val_loss: 1.3063e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.9911e-04 - val_loss: 1.6579e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0013 - val_loss: 1.0456e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.5484e-04 - val_loss: 8.9935e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.2156e-04 - val_loss: 1.8224e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8722e-04 - val_loss: 4.1759e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.3435e-04 - val_loss: 9.7652e-06\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.2195e-04 - val_loss: 5.4857e-05\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.9317e-04 - val_loss: 3.1721e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.7601e-04 - val_loss: 1.2208e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.1642e-04 - val_loss: 2.8162e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.1857e-04 - val_loss: 3.7791e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.3276e-04 - val_loss: 7.5459e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.5484e-04 - val_loss: 6.5802e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8351e-04 - val_loss: 2.5264e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.4780e-04 - val_loss: 6.8463e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8388e-04 - val_loss: 1.0776e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.2828e-04 - val_loss: 1.3840e-05\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.9067e-04 - val_loss: 3.0819e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.7974e-04 - val_loss: 1.4532e-04\n",
      "9/9 [==============================] - 2s 20ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.932642231243596\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 19s 42ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 9s - loss: 0.0023 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0016 - val_loss: 8.3485e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0013 - val_loss: 1.7268e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.1548e-04 - val_loss: 0.0028\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0010 - val_loss: 5.6300e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0010 - val_loss: 7.2312e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 4.3009e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 3.7000e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0013 - val_loss: 8.3840e-06\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.9224e-04 - val_loss: 1.8346e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.4368e-04 - val_loss: 3.6096e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.1286e-04 - val_loss: 2.8994e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.8763e-04 - val_loss: 1.5352e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0010 - val_loss: 8.1275e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 9.0966e-04 - val_loss: 2.3958e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.7980e-04 - val_loss: 6.9105e-06\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.0717e-04 - val_loss: 6.3995e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.8506e-04 - val_loss: 0.0031\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.1973e-04 - val_loss: 1.4480e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.8418e-04 - val_loss: 1.6291e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.0174e-04 - val_loss: 0.0014\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.8999e-04 - val_loss: 2.6882e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.3862e-04 - val_loss: 5.1143e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.8031e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.2495e-04 - val_loss: 1.6630e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.8837e-04 - val_loss: 5.5882e-05\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.9658e-04 - val_loss: 1.1864e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.3510e-04 - val_loss: 1.7125e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.7316e-04 - val_loss: 7.4903e-06\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.2225e-04 - val_loss: 1.3012e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6453e-04 - val_loss: 3.6749e-05\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.3657e-04 - val_loss: 1.5062e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.9365e-04 - val_loss: 1.4434e-05\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6993e-04 - val_loss: 7.1584e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.2310e-04 - val_loss: 2.8131e-05\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.2964e-04 - val_loss: 4.5106e-05\n",
      "9/9 [==============================] - 2s 26ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.406238655525629\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 23s 49ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 10s - loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0019 - val_loss: 6.3875e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0019 - val_loss: 5.7354e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0011 - val_loss: 4.9729e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.3896e-04 - val_loss: 9.3956e-05\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.7202e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0011 - val_loss: 3.1155e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.3104e-04 - val_loss: 4.1283e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.4894e-04 - val_loss: 0.0033\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0013 - val_loss: 9.8282e-06\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.1029e-04 - val_loss: 0.0020\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0016 - val_loss: 9.1146e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.0217e-04 - val_loss: 1.5349e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.7933e-04 - val_loss: 1.9922e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.5277e-04 - val_loss: 5.1687e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 8.0443e-04 - val_loss: 1.4138e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.0996e-04 - val_loss: 3.3266e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8892e-04 - val_loss: 9.2591e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.0976e-04 - val_loss: 8.2456e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.7039e-04 - val_loss: 3.0902e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.9733e-04 - val_loss: 1.2481e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 6.8957e-04 - val_loss: 8.4686e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.4386e-04 - val_loss: 6.3598e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 6.9762e-04 - val_loss: 4.4797e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 8.4266e-04 - val_loss: 0.0010\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 8.1192e-04 - val_loss: 1.1965e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 8.9002e-04 - val_loss: 4.4493e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.6637e-04 - val_loss: 4.1979e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.4642e-04 - val_loss: 2.1004e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.7351e-04 - val_loss: 6.4769e-06\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.1927e-04 - val_loss: 6.0158e-06\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.6449e-04 - val_loss: 9.9934e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.7215e-04 - val_loss: 4.7293e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.5325e-04 - val_loss: 1.6814e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.2179e-04 - val_loss: 1.3217e-05\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.7366e-04 - val_loss: 8.0303e-05\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.5875e-04 - val_loss: 1.1777e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.1588e-04 - val_loss: 4.1204e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.9615e-04 - val_loss: 4.6859e-05\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.3111e-04 - val_loss: 1.0694e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.5912e-04 - val_loss: 1.7068e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.8851e-04 - val_loss: 3.3536e-05\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.2462e-04 - val_loss: 8.0134e-06\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 7.5680e-04 - val_loss: 1.2857e-05\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.2426e-04 - val_loss: 4.0922e-05\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.0667e-04 - val_loss: 2.6928e-05\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 5.7269e-04 - val_loss: 1.7366e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 5.9666e-04 - val_loss: 1.8148e-05\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.6906e-04 - val_loss: 4.9523e-05\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.0299e-04 - val_loss: 1.9440e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.6732e-04 - val_loss: 0.0012\n",
      "9/9 [==============================] - 4s 35ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.59071982924709\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 24s 46ms/step - loss: 0.0023 - val_loss: 3.9193e-05\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 1.5186e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0014 - val_loss: 1.5083e-05\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.4834e-04 - val_loss: 1.7312e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.0010 - val_loss: 8.8820e-06\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.8670e-04 - val_loss: 4.4292e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.3276e-04 - val_loss: 2.0961e-05\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.9322e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 8.5483e-04 - val_loss: 3.4678e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.8089e-04 - val_loss: 1.8131e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0011 - val_loss: 3.3354e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0010 - val_loss: 2.6195e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 7.4770e-04 - val_loss: 6.0975e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.0356e-04 - val_loss: 1.2031e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.4086e-04 - val_loss: 6.7421e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 7.9142e-04 - val_loss: 4.2765e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.7380e-04 - val_loss: 1.0536e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.8584e-04 - val_loss: 5.5055e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1857e-04 - val_loss: 4.5262e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.2225e-04 - val_loss: 4.3641e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.9835e-04 - val_loss: 8.0563e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.9253e-04 - val_loss: 1.2043e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.1087e-04 - val_loss: 6.4573e-06\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 8.2881e-04 - val_loss: 4.0497e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.1588e-04 - val_loss: 3.7826e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.0461e-04 - val_loss: 3.0521e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 6.9490e-04 - val_loss: 7.0102e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.3588e-04 - val_loss: 1.5350e-05\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.8182e-04 - val_loss: 1.1952e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 6.6541e-04 - val_loss: 2.2695e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.4910e-04 - val_loss: 3.2591e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.6368e-04 - val_loss: 1.1564e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.0304e-04 - val_loss: 2.3834e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.0109e-04 - val_loss: 3.5318e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 6.6751e-04 - val_loss: 8.4170e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.0148e-04 - val_loss: 1.0524e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.9814e-04 - val_loss: 7.6725e-05\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.1087e-04 - val_loss: 1.3295e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.0537e-04 - val_loss: 2.1107e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.1699e-04 - val_loss: 7.5907e-05\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.2845e-04 - val_loss: 1.0173e-05\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 6.2903e-04 - val_loss: 3.2422e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.9456e-04 - val_loss: 1.3228e-04\n",
      "9/9 [==============================] - 2s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.632178224732975\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 23s 43ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0010 - val_loss: 8.4478e-05\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0011 - val_loss: 3.7871e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0011 - val_loss: 1.1781e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.8767e-04 - val_loss: 9.7484e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 3.6341e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0010 - val_loss: 3.9058e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.2006e-04 - val_loss: 2.3395e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0013 - val_loss: 1.1527e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.3927e-04 - val_loss: 7.6460e-06\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.4658e-04 - val_loss: 4.9270e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.5735e-04 - val_loss: 1.3635e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.1718e-04 - val_loss: 9.7581e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.8491e-04 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 9.2070e-04 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.2861e-04 - val_loss: 9.1159e-06\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.5168e-04 - val_loss: 1.2879e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.8520e-04 - val_loss: 1.2982e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.3727e-04 - val_loss: 1.8061e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 7.3300e-04 - val_loss: 6.4235e-06\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.5752e-04 - val_loss: 7.0777e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.3880e-04 - val_loss: 2.7324e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.4847e-04 - val_loss: 1.5897e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.8178e-04 - val_loss: 3.5488e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.0783e-04 - val_loss: 1.8670e-05\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.1378e-04 - val_loss: 6.2600e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.5637e-04 - val_loss: 3.9843e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6047e-04 - val_loss: 1.0511e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.3761e-04 - val_loss: 9.1351e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4884e-04 - val_loss: 1.3911e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.5911e-04 - val_loss: 2.1168e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0011 - val_loss: 2.2983e-05\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.0826e-04 - val_loss: 1.1432e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9936e-04 - val_loss: 7.8464e-06\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.6281e-04 - val_loss: 8.1898e-05\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.2534e-04 - val_loss: 1.2930e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.6143e-04 - val_loss: 8.6127e-06\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.2454e-04 - val_loss: 9.3288e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.3914e-04 - val_loss: 1.3856e-05\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.3891e-04 - val_loss: 3.6513e-04\n",
      "9/9 [==============================] - 3s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.36574959062417\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 19s 41ms/step - loss: 0.0032 - val_loss: 8.5659e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 0.0013    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0017 - val_loss: 2.7688e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0013 - val_loss: 2.8844e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0011 - val_loss: 2.2178e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.8475e-04 - val_loss: 1.7789e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 4.3974e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.9243e-04 - val_loss: 2.9947e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.1705e-04 - val_loss: 7.3036e-05\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.1122e-04 - val_loss: 1.2884e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 3.9937e-05\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.7721e-04 - val_loss: 8.0177e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.9147e-04 - val_loss: 2.6419e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.7865e-04 - val_loss: 3.6678e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 1.9972e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.9648e-04 - val_loss: 7.5740e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.1204e-04 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 9.2825e-04 - val_loss: 1.0066e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.4611e-04 - val_loss: 8.9074e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.0686e-04 - val_loss: 3.0939e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.3765e-04 - val_loss: 6.5814e-06\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.4408e-04 - val_loss: 4.0686e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.4692e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0013 - val_loss: 3.9109e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.9507e-04 - val_loss: 7.0249e-06\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.3401e-04 - val_loss: 7.4598e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.7923e-04 - val_loss: 9.3198e-06\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.4438e-04 - val_loss: 0.0016\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.5122e-04 - val_loss: 2.0257e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.5206e-04 - val_loss: 6.5058e-06\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.1755e-04 - val_loss: 1.0529e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.5185e-04 - val_loss: 6.8511e-05\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.8150e-04 - val_loss: 6.0480e-06\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 6.4166e-04 - val_loss: 7.1364e-06\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.8322e-04 - val_loss: 2.2553e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.4996e-04 - val_loss: 4.2574e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.1324e-04 - val_loss: 2.4019e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.8955e-04 - val_loss: 1.1269e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 6.3297e-04 - val_loss: 2.4302e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.0607e-04 - val_loss: 1.2638e-05\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.1124e-04 - val_loss: 4.5852e-05\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.6308e-04 - val_loss: 2.1990e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.5431e-04 - val_loss: 1.5442e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.0259e-04 - val_loss: 1.6025e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.5099e-04 - val_loss: 3.5356e-05\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.0075e-04 - val_loss: 6.8418e-05\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 5.9287e-04 - val_loss: 1.2370e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.1915e-04 - val_loss: 8.3538e-05\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.1926e-04 - val_loss: 1.5736e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.1649e-04 - val_loss: 5.8677e-05\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 5.8927e-04 - val_loss: 1.4154e-05\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.6548e-04 - val_loss: 9.7322e-06\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.9305e-04 - val_loss: 3.4333e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 11.241165129959544\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 26s 52ms/step - loss: 0.0031 - val_loss: 1.3295e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 11s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0013 - val_loss: 5.0335e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 0.0013 - val_loss: 1.1223e-05\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0016 - val_loss: 1.5162e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 8.7233e-04 - val_loss: 9.5376e-05\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.0533e-04 - val_loss: 5.2300e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.6140e-04 - val_loss: 6.9431e-06\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 9.8347e-06\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.8476e-04 - val_loss: 0.0056\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0011 - val_loss: 5.4799e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.9987e-04 - val_loss: 5.9032e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.6865e-04 - val_loss: 1.1182e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.7880e-04 - val_loss: 6.3944e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0011 - val_loss: 7.3062e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.9756e-04 - val_loss: 1.4513e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.0747e-04 - val_loss: 2.5160e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.8148e-04 - val_loss: 1.9007e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.8944e-04 - val_loss: 2.5711e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.9516e-04 - val_loss: 5.2192e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.4772e-04 - val_loss: 1.4215e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 7.1909e-04 - val_loss: 1.8330e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.9919e-04 - val_loss: 1.6698e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.6839e-04 - val_loss: 2.5359e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.4922e-04 - val_loss: 2.6727e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 6.7763e-04 - val_loss: 0.0011\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 7.5736e-04 - val_loss: 2.5732e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.7988e-04 - val_loss: 1.3982e-04\n",
      "9/9 [==============================] - 4s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.968086892611783\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 15s 45ms/step - loss: 0.0027 - val_loss: 3.3181e-05\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 4.9262e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 3.8178e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 3.7067e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 9.1970e-04 - val_loss: 2.0054e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2275e-04 - val_loss: 3.7913e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.4319e-04 - val_loss: 1.3912e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.5215e-04 - val_loss: 1.6376e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.5583e-04 - val_loss: 1.0299e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.2675e-04 - val_loss: 3.3048e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.9383e-04 - val_loss: 2.7675e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7665e-04 - val_loss: 2.1723e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.5090e-04 - val_loss: 8.9223e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7139e-04 - val_loss: 1.2585e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7351e-04 - val_loss: 1.3560e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.0131e-04 - val_loss: 8.4421e-06\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.6180e-04 - val_loss: 3.9703e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7225e-04 - val_loss: 1.5111e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.9091e-04 - val_loss: 8.7261e-06\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.3430e-04 - val_loss: 6.1606e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.1416e-04 - val_loss: 2.2021e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.9762e-04 - val_loss: 7.1953e-06\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.1512e-04 - val_loss: 7.2053e-06\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.3039e-04 - val_loss: 1.7226e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.8644e-04 - val_loss: 1.9424e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.2599e-04 - val_loss: 1.3789e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.2227e-04 - val_loss: 1.1459e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8558e-04 - val_loss: 6.1091e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.0063e-04 - val_loss: 1.1573e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.1735e-04 - val_loss: 6.2450e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.3727e-04 - val_loss: 1.2749e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.7569e-04 - val_loss: 1.6259e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.9821e-04 - val_loss: 1.2431e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.9338e-04 - val_loss: 4.2839e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.0328e-04 - val_loss: 3.3814e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.7887e-04 - val_loss: 1.0439e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.1267e-04 - val_loss: 6.7329e-06\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3815e-04 - val_loss: 7.1495e-06\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.6146e-04 - val_loss: 2.8865e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.9515e-04 - val_loss: 7.9404e-06\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.0634e-04 - val_loss: 6.8105e-06\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.0419e-04 - val_loss: 8.0583e-06\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3593e-04 - val_loss: 4.5689e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.1216e-04 - val_loss: 4.2356e-05\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.5682e-04 - val_loss: 1.7822e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.9121e-04 - val_loss: 1.1448e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.2558e-04 - val_loss: 1.0733e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.4191e-04 - val_loss: 6.8116e-06\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.3922e-04 - val_loss: 9.1251e-05\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.5921e-04 - val_loss: 9.0364e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.6479e-04 - val_loss: 1.1895e-05\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.0741e-04 - val_loss: 2.4931e-05\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.1186e-04 - val_loss: 5.6108e-05\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.5700e-04 - val_loss: 1.9416e-05\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.7665e-04 - val_loss: 3.8713e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.0293e-04 - val_loss: 2.8281e-05\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.1478e-04 - val_loss: 2.7084e-05\n",
      "9/9 [==============================] - 2s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.337277593510477\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 19s 60ms/step - loss: 0.0047 - val_loss: 8.7299e-05\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 6.9987e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0016 - val_loss: 1.7644e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0013 - val_loss: 1.5485e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0011 - val_loss: 9.5696e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.7342e-04 - val_loss: 3.0220e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.6582e-04 - val_loss: 9.1383e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.1145e-04 - val_loss: 4.1334e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.6504e-04 - val_loss: 2.6927e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.4619e-04 - val_loss: 1.6271e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.5813e-04 - val_loss: 6.6432e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.4382e-04 - val_loss: 5.4879e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.3276e-04 - val_loss: 3.1351e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.4017e-04 - val_loss: 6.3606e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.1253e-04 - val_loss: 2.9493e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.6755e-04 - val_loss: 1.0665e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 9.1070e-04 - val_loss: 5.0595e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.1041e-04 - val_loss: 6.0506e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.9735e-04 - val_loss: 4.8665e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 9.5531e-04 - val_loss: 1.6248e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.2873e-04 - val_loss: 5.6551e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.4477e-04 - val_loss: 4.2409e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.7893e-04 - val_loss: 4.3824e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.4394e-04 - val_loss: 6.9126e-04\n",
      "9/9 [==============================] - 3s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 14.88408315888637\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 60ms/step - loss: 0.0034 - val_loss: 6.5652e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 6s - loss: 7.5153e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0011 - val_loss: 6.3809e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.5083e-04 - val_loss: 1.9383e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.1537e-04 - val_loss: 2.5830e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.3220e-04 - val_loss: 1.3511e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0010 - val_loss: 1.9267e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.5144e-04 - val_loss: 4.5713e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.0096e-04 - val_loss: 2.8074e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0011 - val_loss: 4.0858e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.4524e-04 - val_loss: 1.7943e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.2532e-04 - val_loss: 2.2602e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.7873e-04 - val_loss: 1.3764e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.1367e-04 - val_loss: 9.7547e-06\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.6410e-04 - val_loss: 1.9371e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0935e-04 - val_loss: 8.3458e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.8133e-04 - val_loss: 3.3019e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.8289e-04 - val_loss: 1.1518e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.7079e-04 - val_loss: 8.9052e-06\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.6133e-04 - val_loss: 8.2431e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.7845e-04 - val_loss: 7.8074e-06\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.9043e-04 - val_loss: 5.4901e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.8323e-04 - val_loss: 4.5915e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 6.7942e-04 - val_loss: 2.2866e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.0078e-04 - val_loss: 5.4419e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.4025e-04 - val_loss: 4.3813e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.9183e-04 - val_loss: 1.3600e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.8847e-04 - val_loss: 2.4290e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.8348e-04 - val_loss: 1.6476e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.5291e-04 - val_loss: 2.2099e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.4779e-04 - val_loss: 9.0533e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.2005e-04 - val_loss: 1.1629e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.9866e-04 - val_loss: 6.0122e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.2549e-04 - val_loss: 2.1947e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.8838e-04 - val_loss: 4.0718e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 6.8740e-04 - val_loss: 6.9611e-06\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.5885e-04 - val_loss: 5.4661e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 5.7786e-04 - val_loss: 3.5747e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.9681e-04 - val_loss: 0.0013\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.8302e-04 - val_loss: 1.1744e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.1397e-04 - val_loss: 2.1092e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.4208e-04 - val_loss: 7.3840e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.5211e-04 - val_loss: 8.2148e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.6732e-04 - val_loss: 1.4188e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.5921e-04 - val_loss: 3.5490e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.2089e-04 - val_loss: 6.1085e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.4851e-04 - val_loss: 7.0765e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.5470e-04 - val_loss: 8.3235e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.3672e-04 - val_loss: 8.1962e-06\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.5985e-04 - val_loss: 2.4178e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.2609e-04 - val_loss: 1.1820e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.0042e-04 - val_loss: 1.2166e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.9792e-04 - val_loss: 1.1266e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.7323e-04 - val_loss: 3.1100e-05\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.6289e-04 - val_loss: 6.9887e-05\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.4344e-04 - val_loss: 2.3218e-05\n",
      "9/9 [==============================] - 2s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.867631470330732\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 21s 75ms/step - loss: 0.0037 - val_loss: 4.3977e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 6s - loss: 8.4543e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0013 - val_loss: 2.7948e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0013 - val_loss: 6.9900e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.5779e-04 - val_loss: 7.1155e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.9664e-04 - val_loss: 1.1411e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0010 - val_loss: 1.6924e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 9.3045e-04 - val_loss: 4.5015e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.4114e-04 - val_loss: 2.5849e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.9616e-04 - val_loss: 8.9064e-06\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 9.5236e-04 - val_loss: 3.6916e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.8383e-04 - val_loss: 8.4337e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 8.8952e-04 - val_loss: 1.8919e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.7560e-04 - val_loss: 3.1984e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 7.8081e-04 - val_loss: 2.0515e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 9.5471e-04 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.2506e-04 - val_loss: 1.4351e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 8.5831e-04 - val_loss: 9.2716e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0010 - val_loss: 1.4364e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.4732e-04 - val_loss: 1.7009e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 8.1416e-04 - val_loss: 3.4464e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.4381e-04 - val_loss: 1.7804e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.0779e-04 - val_loss: 1.8653e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 8.6563e-04 - val_loss: 4.5229e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.8347e-04 - val_loss: 1.4848e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.2205e-04 - val_loss: 4.5558e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.8090e-04 - val_loss: 6.8345e-06\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.2659e-04 - val_loss: 1.9614e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.2398e-04 - val_loss: 6.5827e-06\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.7015e-04 - val_loss: 8.0801e-06\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.5712e-04 - val_loss: 3.8491e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.2008e-04 - val_loss: 4.8503e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.3809e-04 - val_loss: 1.2916e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.4679e-04 - val_loss: 2.1364e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.3322e-04 - val_loss: 4.0593e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 7.4119e-04 - val_loss: 1.1982e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 7.6130e-04 - val_loss: 2.6557e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 6.5381e-04 - val_loss: 1.5528e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 6.0655e-04 - val_loss: 7.0651e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 6.1976e-04 - val_loss: 5.1586e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.4678e-04 - val_loss: 9.8887e-06\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 6.3523e-04 - val_loss: 5.9298e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.3986e-04 - val_loss: 1.1833e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.7399e-04 - val_loss: 3.0524e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.4014e-04 - val_loss: 1.4895e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.4643e-04 - val_loss: 1.0048e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 6.2355e-04 - val_loss: 4.3497e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 7.3143e-04 - val_loss: 6.0579e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 6.0174e-04 - val_loss: 7.5548e-04\n",
      "9/9 [==============================] - 3s 35ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.27892555711441\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 41ms/step - loss: 0.0032 - val_loss: 2.4560e-05\n",
      "Epoch 2/100\n",
      "  4/134 [..............................] - ETA: 2s - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0012 - val_loss: 3.6767e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 9.7709e-04 - val_loss: 8.3235e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.8210e-04 - val_loss: 0.0031\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 9.2988e-04 - val_loss: 2.5043e-05\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.0086e-04 - val_loss: 2.4244e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.0304e-04 - val_loss: 3.8433e-05\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.6791e-04 - val_loss: 9.3090e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.4366e-04 - val_loss: 4.3287e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.6275e-04 - val_loss: 4.6492e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.1646e-04 - val_loss: 2.3440e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.5334e-04 - val_loss: 1.5714e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.6928e-04 - val_loss: 3.2887e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.6509e-04 - val_loss: 2.7145e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.4992e-04 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.6498e-04 - val_loss: 4.3202e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.0177e-04 - val_loss: 8.2149e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.6884e-04 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.2815e-04 - val_loss: 1.7086e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.1245e-04 - val_loss: 3.7014e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.5506e-04 - val_loss: 1.1058e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.6234e-04 - val_loss: 8.2083e-06\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.1174e-04 - val_loss: 1.0686e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.2563e-04 - val_loss: 9.3938e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 8.7955e-04 - val_loss: 4.8007e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.0723e-04 - val_loss: 8.8625e-06\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.4845e-04 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.6925e-04 - val_loss: 1.4433e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.7882e-04 - val_loss: 1.7907e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.0570e-04 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.5097e-04 - val_loss: 7.8099e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.4113e-04 - val_loss: 9.8043e-06\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.6456e-04 - val_loss: 3.0977e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.0149e-04 - val_loss: 4.0905e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.5732e-04 - val_loss: 1.5090e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 7.2608e-04 - val_loss: 2.0640e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 7.5050e-04 - val_loss: 1.0098e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.9182e-04 - val_loss: 6.9836e-06\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2680e-04 - val_loss: 1.7504e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.7930e-04 - val_loss: 3.8697e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1519e-04 - val_loss: 8.5651e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.9945e-04 - val_loss: 5.5782e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.1696e-04 - val_loss: 2.5594e-05\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.6623e-04 - val_loss: 1.2283e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2593e-04 - val_loss: 3.4899e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.0886e-04 - val_loss: 1.8621e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.4446e-04 - val_loss: 1.7540e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.5783e-04 - val_loss: 3.6425e-05\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4907e-04 - val_loss: 7.3453e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.9764e-04 - val_loss: 2.7587e-05\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.9230e-04 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.2511e-04 - val_loss: 6.8480e-06\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.8844e-04 - val_loss: 1.6607e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.0949e-04 - val_loss: 2.5737e-05\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.9825e-04 - val_loss: 3.0619e-05\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.3462e-04 - val_loss: 9.6244e-06\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.4510e-04 - val_loss: 2.4842e-05\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.0619e-04 - val_loss: 1.3591e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.7244e-04 - val_loss: 3.5606e-05\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.4830e-04 - val_loss: 1.5547e-05\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.3244e-04 - val_loss: 2.9803e-05\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.7750e-04 - val_loss: 9.6990e-06\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.8434e-04 - val_loss: 5.6184e-05\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.6685e-04 - val_loss: 8.2168e-06\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.5599e-04 - val_loss: 7.5009e-06\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.8908e-04 - val_loss: 1.3026e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1807e-04 - val_loss: 1.3163e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 5.4517e-04 - val_loss: 1.7069e-05\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.3212e-04 - val_loss: 1.7180e-05\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.5594e-04 - val_loss: 6.5633e-06\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4925e-04 - val_loss: 1.2163e-05\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.3853e-04 - val_loss: 9.0600e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.7497e-04 - val_loss: 5.5483e-05\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.6208e-04 - val_loss: 3.8278e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.3781e-04 - val_loss: 2.1622e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.7875e-04 - val_loss: 1.6443e-04\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2659e-04 - val_loss: 1.0512e-05\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.2186e-04 - val_loss: 1.8600e-04\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 5.6819e-04 - val_loss: 2.5747e-05\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.9066e-04 - val_loss: 1.6339e-05\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.1002e-04 - val_loss: 1.8730e-05\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.1200e-04 - val_loss: 8.9952e-06\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.6089e-04 - val_loss: 9.6855e-05\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.9596e-04 - val_loss: 1.3608e-04\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.7362e-04 - val_loss: 1.1865e-04\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.1299e-04 - val_loss: 1.0165e-04\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.3941e-04 - val_loss: 4.5170e-05\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.8964e-04 - val_loss: 7.6494e-06\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.3257e-04 - val_loss: 6.7770e-05\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.5007e-04 - val_loss: 7.4638e-06\n",
      "9/9 [==============================] - 2s 14ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.782099038402551\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 18s 53ms/step - loss: 0.0039 - val_loss: 1.8551e-05\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 5.4198e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 32ms/step - loss: 0.0016 - val_loss: 8.7817e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0013 - val_loss: 3.0855e-05\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0013 - val_loss: 1.2547e-05\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 9.4406e-04 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 9.0031e-04 - val_loss: 3.7073e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.1993e-04 - val_loss: 0.0021\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.9857e-04 - val_loss: 7.9563e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.8054e-04 - val_loss: 4.7455e-05\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.0704e-04 - val_loss: 9.6201e-06\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.3400e-04 - val_loss: 1.1142e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.9343e-04 - val_loss: 8.0467e-06\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.6323e-04 - val_loss: 2.1495e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.0507e-04 - val_loss: 2.0599e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.3812e-04 - val_loss: 1.0309e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.1906e-04 - val_loss: 6.4861e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.4713e-04 - val_loss: 3.1943e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.6154e-04 - val_loss: 1.0218e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.6727e-04 - val_loss: 1.0805e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 34ms/step - loss: 9.5579e-04 - val_loss: 8.9827e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.0392e-04 - val_loss: 6.1066e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.4284e-04 - val_loss: 1.1671e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.7287e-04 - val_loss: 2.9620e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.1246e-04 - val_loss: 1.1409e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.5312e-04 - val_loss: 0.0023\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.2551e-04 - val_loss: 8.1161e-06\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.5792e-04 - val_loss: 1.6129e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.4532e-04 - val_loss: 1.2064e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.8706e-04 - val_loss: 8.4170e-06\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.6412e-04 - val_loss: 2.1683e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.0482e-04 - val_loss: 8.0701e-06\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.3705e-04 - val_loss: 6.8171e-05\n",
      "9/9 [==============================] - 3s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 11.204555705333124\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 52ms/step - loss: 0.0026 - val_loss: 1.7624e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 7s - loss: 3.2075e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0012 - val_loss: 7.8976e-05\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.3564e-04 - val_loss: 8.4254e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0010 - val_loss: 7.3648e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.3490e-04 - val_loss: 3.1647e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.6205e-04 - val_loss: 6.1639e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.9823e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0011 - val_loss: 7.0195e-06\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.0749e-04 - val_loss: 1.7867e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.8495e-04 - val_loss: 7.8074e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0850e-04 - val_loss: 6.6461e-06\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.0872e-04 - val_loss: 6.0367e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.6008e-04 - val_loss: 6.4103e-06\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6477e-04 - val_loss: 7.5427e-06\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 8.0441e-04 - val_loss: 2.1231e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 9.4957e-04 - val_loss: 3.7053e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.0985e-04 - val_loss: 1.7121e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.5097e-04 - val_loss: 8.0007e-06\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.0304e-04 - val_loss: 8.3813e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.1281e-04 - val_loss: 1.0705e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.5860e-04 - val_loss: 7.3085e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 8.4948e-04 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.2453e-04 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.5210e-04 - val_loss: 1.1138e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 8.4127e-04 - val_loss: 1.0355e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.8356e-04 - val_loss: 5.6205e-05\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 8.3145e-04 - val_loss: 3.8404e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.7348e-04 - val_loss: 7.4060e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.5262e-04 - val_loss: 1.4029e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.7476e-04 - val_loss: 1.3861e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.3131e-04 - val_loss: 1.4858e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.1720e-04 - val_loss: 2.2398e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.5376e-04 - val_loss: 1.0171e-05\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.410613076017835\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 20s 63ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0019 - val_loss: 1.2887e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0013 - val_loss: 2.4305e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.8231e-04 - val_loss: 8.8079e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.0873e-04 - val_loss: 1.2465e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.8859e-04 - val_loss: 8.7651e-06\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0012 - val_loss: 8.5369e-06\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.6229e-04 - val_loss: 6.5466e-05\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0012 - val_loss: 7.5085e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.9050e-04 - val_loss: 5.5092e-05\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.1605e-04 - val_loss: 1.9709e-05\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.0202e-04 - val_loss: 1.0307e-05\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.6759e-04 - val_loss: 9.7394e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0010 - val_loss: 3.5742e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.4080e-04 - val_loss: 2.5061e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 9.8051e-04 - val_loss: 8.7802e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.3735e-04 - val_loss: 6.8714e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.8246e-04 - val_loss: 5.2841e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.6006e-04 - val_loss: 4.4764e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.9693e-04 - val_loss: 2.0874e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.1988e-04 - val_loss: 6.3459e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.6898e-04 - val_loss: 3.8037e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.4741e-04 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 7.2149e-04 - val_loss: 7.5272e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 9.2741e-04 - val_loss: 2.4710e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.7465e-04 - val_loss: 0.0013\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.6805e-04 - val_loss: 5.1800e-04\n",
      "9/9 [==============================] - 3s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 11.413589269155445\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range: #[50, 100]\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_gru_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e12d1fd-830d-49c2-a171-a4c0ae04bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 10.516443595185972}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 10.932642231243596}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 10.406238655525629}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 10.59071982924709}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 9.632178224732975}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 9.36574959062417}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 11.241165129959544}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 9.968086892611783}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 9.337277593510477}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 14.88408315888637}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 9.867631470330732}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 9.27892555711441}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 9.782099038402551}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 11.204555705333124}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 10.410613076017835}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 11.413589269155445}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
