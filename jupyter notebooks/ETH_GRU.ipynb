{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847153b4-d4af-41a4-992b-b9a5bf35210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09cf3a6-af8d-4283-8ea6-6097de7a8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d77eebe-b055-46d9-b90c-c46ad9dc2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02c85f3-4356-4564-b497-5f75c98edb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8eee78-6d1f-4147-9676-97cb22e77dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(GRU(units, return_sequences=True))\n",
    "    model.add(GRU(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3d5711-1704-4f19-b1b8-2dcf75ae3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    gru_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    gru_predictions = model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, gru_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"ETH_model_gru.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(gru_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'ETH_actual_vs_predicted_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'ETH_loss_curve_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19aeb2ff-cc11-4447-9edb-13e79e510935",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'ETH-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70870bf8-c413-4cb1-a503-fc6ed13ea1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,20]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecfab0a-8ee1-4ac1-8bb4-5fed2c4046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b52e73e-2dd8-496a-912a-c41ed65ca9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f90938b-a84e-40a4-b60d-6c48dd629f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 21s 40ms/step - loss: 0.0037 - val_loss: 3.0381e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 8.1418e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0011 - val_loss: 1.5563e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0011 - val_loss: 5.3086e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0011 - val_loss: 7.5514e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0011 - val_loss: 1.6102e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.6842e-04 - val_loss: 2.2835e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.9419e-04 - val_loss: 1.0897e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.8173e-04 - val_loss: 1.2137e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.0702e-04 - val_loss: 2.5913e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.8037e-04 - val_loss: 1.2213e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.4210e-04 - val_loss: 3.1664e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.1961e-04 - val_loss: 2.4780e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.0919e-04 - val_loss: 2.7717e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.1773e-04 - val_loss: 3.2329e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.8454e-04 - val_loss: 2.9366e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.5703e-04 - val_loss: 1.6738e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.6872e-04 - val_loss: 1.7149e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.0951e-04 - val_loss: 2.1153e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.8847e-04 - val_loss: 1.6386e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.3759e-04 - val_loss: 3.0389e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.5317e-04 - val_loss: 2.2170e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.8285e-04 - val_loss: 1.3135e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.2063e-04 - val_loss: 1.2069e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.3502e-04 - val_loss: 1.8781e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.5281e-04 - val_loss: 1.3767e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.5045e-04 - val_loss: 4.4458e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.2830e-04 - val_loss: 1.0629e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.3045e-04 - val_loss: 1.1717e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.7693e-04 - val_loss: 1.0206e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.3480e-04 - val_loss: 7.9082e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 7.9618e-04 - val_loss: 9.8766e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8858e-04 - val_loss: 1.7624e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 5.9490e-04 - val_loss: 1.1080e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 5.6829e-04 - val_loss: 4.3730e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.5547e-04 - val_loss: 2.1441e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8477e-04 - val_loss: 1.1465e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 5.7686e-04 - val_loss: 1.2914e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 6.9778e-04 - val_loss: 1.3110e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.7557e-04 - val_loss: 1.2607e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 8.1211e-04 - val_loss: 1.0304e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.5866e-04 - val_loss: 1.2515e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.5606e-04 - val_loss: 1.3000e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.3841e-04 - val_loss: 1.0545e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.0184e-04 - val_loss: 1.0252e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.3476e-04 - val_loss: 1.0741e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.1999e-04 - val_loss: 1.0670e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.9057e-04 - val_loss: 1.4992e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.4458e-04 - val_loss: 3.4080e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.4861e-04 - val_loss: 1.3079e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6861e-04 - val_loss: 1.2220e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6543e-04 - val_loss: 3.9367e-04\n",
      "9/9 [==============================] - 3s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 50.19392084907332\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 26s 50ms/step - loss: 0.0047 - val_loss: 2.7243e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 10s - loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0015 - val_loss: 3.2715e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0013 - val_loss: 1.5026e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 9.7752e-04 - val_loss: 3.4783e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.9519e-04 - val_loss: 1.2129e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0011 - val_loss: 2.3572e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.2187e-04 - val_loss: 1.4980e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.7440e-04 - val_loss: 8.8111e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.8115e-04 - val_loss: 1.2133e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.1340e-04 - val_loss: 1.5392e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.4220e-04 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0011 - val_loss: 1.1206e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 7.1460e-04 - val_loss: 1.1882e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.6412e-04 - val_loss: 4.6774e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0010 - val_loss: 3.7560e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.2432e-04 - val_loss: 3.7632e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 8.1484e-04 - val_loss: 1.0712e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.7694e-04 - val_loss: 2.5674e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.2551e-04 - val_loss: 1.3739e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 6.3698e-04 - val_loss: 1.4333e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.9148e-04 - val_loss: 1.3809e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.9517e-04 - val_loss: 2.0176e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.5867e-04 - val_loss: 1.1814e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.8431e-04 - val_loss: 1.4050e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.1445e-04 - val_loss: 1.3773e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.0529e-04 - val_loss: 1.1847e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.4532e-04 - val_loss: 1.4187e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.6040e-04 - val_loss: 1.8017e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.1713e-04 - val_loss: 8.3074e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.3557e-04 - val_loss: 1.0954e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.4613e-04 - val_loss: 1.2371e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.0524e-04 - val_loss: 1.1045e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.7264e-04 - val_loss: 2.9428e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.4360e-04 - val_loss: 1.0702e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.6036e-04 - val_loss: 1.8174e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.0817e-04 - val_loss: 1.6946e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.1919e-04 - val_loss: 4.1923e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.1017e-04 - val_loss: 3.0381e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.7525e-04 - val_loss: 2.9114e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.8118e-04 - val_loss: 2.4160e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.2625e-04 - val_loss: 2.7753e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.1061e-04 - val_loss: 1.8399e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.8274e-04 - val_loss: 2.8939e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.1513e-04 - val_loss: 1.3632e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.3175e-04 - val_loss: 1.0754e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.1138e-04 - val_loss: 1.4407e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.7870e-04 - val_loss: 9.9991e-05\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 5.9595e-04 - val_loss: 1.0920e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.3431e-04 - val_loss: 2.2848e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.3058e-04 - val_loss: 1.0676e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.3050e-04 - val_loss: 4.8553e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.4248e-04 - val_loss: 3.7534e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.4590e-04 - val_loss: 5.2459e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6751e-04 - val_loss: 5.7740e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.3021e-04 - val_loss: 1.0687e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.8933e-04 - val_loss: 3.6826e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.2345e-04 - val_loss: 1.2884e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 5.8597e-04 - val_loss: 1.3091e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.9264e-04 - val_loss: 2.3275e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 5.8927e-04 - val_loss: 1.2654e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6396e-04 - val_loss: 1.8047e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.9165e-04 - val_loss: 2.2998e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.1606e-04 - val_loss: 2.4919e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6585e-04 - val_loss: 1.0462e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.8842e-04 - val_loss: 1.2240e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.2744e-04 - val_loss: 1.4964e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8696e-04 - val_loss: 2.4067e-04\n",
      "9/9 [==============================] - 3s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 48.21089018708109\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 21s 46ms/step - loss: 0.0046 - val_loss: 5.0381e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 9s - loss: 5.3727e-04 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0012 - val_loss: 7.7268e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0012 - val_loss: 2.2169e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 9.7845e-04 - val_loss: 1.0628e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.4373e-04 - val_loss: 2.2895e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0012 - val_loss: 5.2765e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.3923e-04 - val_loss: 1.4919e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.6590e-04 - val_loss: 8.3590e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.6299e-04 - val_loss: 1.2302e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.6183e-04 - val_loss: 3.7494e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.1435e-04 - val_loss: 3.1646e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.5211e-04 - val_loss: 1.6532e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0011 - val_loss: 1.0543e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.7709e-04 - val_loss: 1.3478e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 8.8247e-04 - val_loss: 1.0459e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.9192e-04 - val_loss: 1.0969e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.3697e-04 - val_loss: 1.0586e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.3804e-04 - val_loss: 1.1881e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.3703e-04 - val_loss: 1.2519e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.2397e-04 - val_loss: 6.6380e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.5474e-04 - val_loss: 2.0831e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 8.1279e-04 - val_loss: 1.4634e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.6388e-04 - val_loss: 1.3493e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.0361e-04 - val_loss: 1.9352e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.9268e-04 - val_loss: 1.2280e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.9603e-04 - val_loss: 1.9730e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 6.9886e-04 - val_loss: 2.2000e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 6.2542e-04 - val_loss: 1.0205e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 7.2201e-04 - val_loss: 1.1162e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 6.8862e-04 - val_loss: 9.9082e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.0480e-04 - val_loss: 1.8226e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 7.4187e-04 - val_loss: 1.4532e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 6.0340e-04 - val_loss: 1.7382e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 7.1521e-04 - val_loss: 1.1778e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.5037e-04 - val_loss: 1.4903e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.6781e-04 - val_loss: 1.9734e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.0274e-04 - val_loss: 2.3370e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 6.4862e-04 - val_loss: 4.1973e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.8543e-04 - val_loss: 3.5598e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.5271e-04 - val_loss: 1.4571e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 6.4324e-04 - val_loss: 3.3785e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.2559e-04 - val_loss: 1.0225e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 7.1602e-04 - val_loss: 1.0020e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.2428e-04 - val_loss: 1.2375e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.3655e-04 - val_loss: 1.3006e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.5595e-04 - val_loss: 1.0743e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 6.6482e-04 - val_loss: 1.7585e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 6.1812e-04 - val_loss: 1.1534e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 6.3504e-04 - val_loss: 1.5429e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 6.5688e-04 - val_loss: 1.0142e-04\n",
      "9/9 [==============================] - 4s 31ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.671125557419856\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 44s 92ms/step - loss: 0.0047 - val_loss: 5.4755e-04\n",
      "Epoch 2/100\n",
      "  2/268 [..............................] - ETA: 13s - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 14s 53ms/step - loss: 0.0020 - val_loss: 2.3953e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 15s 54ms/step - loss: 0.0012 - val_loss: 5.2089e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.0010 - val_loss: 2.2196e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 0.0011 - val_loss: 2.5828e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 8.7348e-04 - val_loss: 2.9086e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 9.3851e-04 - val_loss: 2.0513e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 9.4780e-04 - val_loss: 1.2661e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 0.0012 - val_loss: 2.0302e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 6.7356e-04 - val_loss: 3.2108e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 8.6729e-04 - val_loss: 4.5075e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 7.0492e-04 - val_loss: 4.9079e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.0010 - val_loss: 4.7431e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.1451e-04 - val_loss: 3.2684e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 7.9269e-04 - val_loss: 1.0040e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.0010 - val_loss: 2.7735e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 7.8759e-04 - val_loss: 1.0722e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 8.9074e-04 - val_loss: 1.7526e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.7413e-04 - val_loss: 2.9395e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 12s 47ms/step - loss: 8.7609e-04 - val_loss: 1.9136e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.2839e-04 - val_loss: 1.1697e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 6.1760e-04 - val_loss: 1.5758e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 8.1061e-04 - val_loss: 1.2573e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.4136e-04 - val_loss: 1.0662e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.8363e-04 - val_loss: 1.2274e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.0835e-04 - val_loss: 2.1141e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 7.9628e-04 - val_loss: 1.1748e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 8.4241e-04 - val_loss: 2.2072e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 12s 47ms/step - loss: 7.1964e-04 - val_loss: 1.1302e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.5480e-04 - val_loss: 2.3922e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.2551e-04 - val_loss: 1.1340e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.2396e-04 - val_loss: 1.0788e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.4337e-04 - val_loss: 2.0241e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.1973e-04 - val_loss: 1.3193e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.4392e-04 - val_loss: 2.0422e-04\n",
      "9/9 [==============================] - 3s 32ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 48.83101165467385\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 15s 29ms/step - loss: 0.0034 - val_loss: 2.5903e-04\n",
      "Epoch 2/100\n",
      "  4/268 [..............................] - ETA: 5s - loss: 4.3867e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0011 - val_loss: 2.7689e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 9.6178e-04 - val_loss: 2.0365e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 8.3327e-04 - val_loss: 1.1090e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.9261e-04 - val_loss: 2.7061e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.7403e-04 - val_loss: 1.0986e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 8.4160e-04 - val_loss: 1.2669e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 8.1396e-04 - val_loss: 3.7792e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0010 - val_loss: 5.5329e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.8371e-04 - val_loss: 1.2727e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 7.4026e-04 - val_loss: 1.8355e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.9858e-04 - val_loss: 1.4888e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.9399e-04 - val_loss: 1.0855e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.7170e-04 - val_loss: 1.5731e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.2469e-04 - val_loss: 1.6114e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.6569e-04 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.0608e-04 - val_loss: 1.0628e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 8.4766e-04 - val_loss: 4.1952e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.8083e-04 - val_loss: 2.6397e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.5737e-04 - val_loss: 1.0086e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.4791e-04 - val_loss: 1.6032e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 8.1671e-04 - val_loss: 1.3679e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.9480e-04 - val_loss: 2.8873e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.6029e-04 - val_loss: 1.1630e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 6.0879e-04 - val_loss: 3.0295e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 6.5609e-04 - val_loss: 1.4395e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 7.0438e-04 - val_loss: 1.0182e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.3463e-04 - val_loss: 1.3743e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.8374e-04 - val_loss: 1.5079e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.1343e-04 - val_loss: 1.3948e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.3651e-04 - val_loss: 1.0522e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.1026e-04 - val_loss: 3.2309e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.3915e-04 - val_loss: 1.0461e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.2623e-04 - val_loss: 3.8664e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.7164e-04 - val_loss: 2.9972e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 6.7629e-04 - val_loss: 1.4972e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 5.9418e-04 - val_loss: 1.3423e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.8660e-04 - val_loss: 9.9472e-05\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.1071e-04 - val_loss: 1.6251e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 5.7962e-04 - val_loss: 2.5802e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.1358e-04 - val_loss: 1.0942e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.3175e-04 - val_loss: 1.0704e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.0724e-04 - val_loss: 3.6332e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.1513e-04 - val_loss: 2.9776e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 5.9023e-04 - val_loss: 2.4332e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 6.6657e-04 - val_loss: 1.5524e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.0829e-04 - val_loss: 1.8187e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 7.0314e-04 - val_loss: 4.9338e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.3740e-04 - val_loss: 4.2355e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.3189e-04 - val_loss: 1.7762e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.5329e-04 - val_loss: 3.4705e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.7147e-04 - val_loss: 2.0867e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.9456e-04 - val_loss: 1.1090e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.0891e-04 - val_loss: 1.3805e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 6.8115e-04 - val_loss: 5.7184e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 6.5382e-04 - val_loss: 1.1128e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 6.2710e-04 - val_loss: 1.3700e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 5.9369e-04 - val_loss: 3.4743e-04\n",
      "9/9 [==============================] - 2s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.02926976548513\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 24s 44ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0015 - val_loss: 6.1963e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0011 - val_loss: 3.9558e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0010 - val_loss: 5.6266e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0012 - val_loss: 9.2720e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0010 - val_loss: 2.7311e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.6147e-04 - val_loss: 1.3867e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.9530e-04 - val_loss: 2.2512e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.4208e-04 - val_loss: 5.0546e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0010 - val_loss: 2.2444e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.4968e-04 - val_loss: 1.6954e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.0441e-04 - val_loss: 4.2331e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.5349e-04 - val_loss: 4.0831e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.9440e-04 - val_loss: 1.0455e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.6806e-04 - val_loss: 4.8361e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.9563e-04 - val_loss: 3.5027e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.4556e-04 - val_loss: 1.0550e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.1135e-04 - val_loss: 2.2506e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 8.4554e-04 - val_loss: 2.1884e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.8064e-04 - val_loss: 2.0530e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.1835e-04 - val_loss: 3.9298e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.5020e-04 - val_loss: 1.2431e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.7117e-04 - val_loss: 1.4977e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.9056e-04 - val_loss: 2.1728e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.9874e-04 - val_loss: 1.1664e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.8874e-04 - val_loss: 1.0307e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 6.9748e-04 - val_loss: 1.0185e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.9553e-04 - val_loss: 1.8657e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 8.6538e-04 - val_loss: 7.7902e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.0737e-04 - val_loss: 1.7739e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.4738e-04 - val_loss: 1.2631e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.3912e-04 - val_loss: 2.6248e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.1745e-04 - val_loss: 1.6052e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.0192e-04 - val_loss: 1.3923e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.2778e-04 - val_loss: 1.2808e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 6.5131e-04 - val_loss: 1.9985e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.1741e-04 - val_loss: 1.8845e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.4503e-04 - val_loss: 1.6335e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.8391e-04 - val_loss: 1.2812e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.6676e-04 - val_loss: 2.2053e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.2344e-04 - val_loss: 3.3226e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.0248e-04 - val_loss: 1.0131e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 6.7342e-04 - val_loss: 1.3832e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.3025e-04 - val_loss: 3.5697e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.2795e-04 - val_loss: 1.0475e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6065e-04 - val_loss: 1.2414e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.3846e-04 - val_loss: 1.2556e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.5227e-04 - val_loss: 1.7370e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.9544e-04 - val_loss: 2.6580e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.5536e-04 - val_loss: 1.2942e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 6.0811e-04 - val_loss: 2.0685e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.2380e-04 - val_loss: 1.0655e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.2118e-04 - val_loss: 1.3253e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.9948e-04 - val_loss: 1.2190e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.4497e-04 - val_loss: 1.5532e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.0072e-04 - val_loss: 1.1700e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.2844e-04 - val_loss: 1.0568e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6763e-04 - val_loss: 4.3181e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 5.9679e-04 - val_loss: 3.7776e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.3880e-04 - val_loss: 7.1483e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 5.9698e-04 - val_loss: 3.8619e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.3948e-04 - val_loss: 2.2674e-04\n",
      "9/9 [==============================] - 3s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.259058428487094\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 22s 46ms/step - loss: 0.0046 - val_loss: 6.6015e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 6.6380e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0013 - val_loss: 1.9057e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.8965e-04 - val_loss: 2.6840e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.5178e-04 - val_loss: 3.7928e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0012 - val_loss: 3.4722e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.8928e-04 - val_loss: 1.1610e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 8.9456e-04 - val_loss: 9.8982e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 7.9755e-04 - val_loss: 2.1134e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 9.6229e-04 - val_loss: 2.3565e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.1432e-04 - val_loss: 1.2637e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.8942e-04 - val_loss: 2.3955e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.0754e-04 - val_loss: 1.2686e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.9806e-04 - val_loss: 1.7739e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.6874e-04 - val_loss: 6.5651e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.2628e-04 - val_loss: 1.3320e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.6307e-04 - val_loss: 3.0629e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0011 - val_loss: 1.3040e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.7375e-04 - val_loss: 1.2465e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.8480e-04 - val_loss: 1.8133e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.5152e-04 - val_loss: 1.1538e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.7272e-04 - val_loss: 2.6951e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.9711e-04 - val_loss: 1.2876e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.3182e-04 - val_loss: 1.1330e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.8335e-04 - val_loss: 1.1874e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 6.9471e-04 - val_loss: 1.8311e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 6.5256e-04 - val_loss: 1.1426e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 6.7826e-04 - val_loss: 1.2282e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.8565e-04 - val_loss: 1.0271e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 7.3005e-04 - val_loss: 1.1804e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 8.3265e-04 - val_loss: 1.3829e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.5773e-04 - val_loss: 1.0492e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 16s 62ms/step - loss: 6.4248e-04 - val_loss: 1.3353e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.6835e-04 - val_loss: 1.0026e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 6.7672e-04 - val_loss: 1.3279e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.9657e-04 - val_loss: 1.6591e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 6.0412e-04 - val_loss: 9.7475e-05\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 6.3158e-04 - val_loss: 1.4887e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.0486e-04 - val_loss: 2.1829e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 5.9764e-04 - val_loss: 1.0052e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.1742e-04 - val_loss: 1.2475e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 6.6235e-04 - val_loss: 1.5428e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.7918e-04 - val_loss: 4.1128e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.4795e-04 - val_loss: 1.0518e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 6.1771e-04 - val_loss: 1.1287e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.2852e-04 - val_loss: 1.1046e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 6.6605e-04 - val_loss: 1.3671e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.2064e-04 - val_loss: 2.0985e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.1498e-04 - val_loss: 3.0792e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.9828e-04 - val_loss: 1.4173e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.2337e-04 - val_loss: 1.1609e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.2330e-04 - val_loss: 4.8253e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.3268e-04 - val_loss: 1.8753e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 6.8152e-04 - val_loss: 3.1251e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.2251e-04 - val_loss: 2.2868e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.1038e-04 - val_loss: 1.2600e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8669e-04 - val_loss: 1.0533e-04\n",
      "9/9 [==============================] - 3s 28ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.02101516576364\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 31s 63ms/step - loss: 0.0046 - val_loss: 8.2907e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 13s - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0016 - val_loss: 7.4358e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0012 - val_loss: 4.4819e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0011 - val_loss: 8.8761e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.1432e-04 - val_loss: 0.0035\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 7.5998e-04 - val_loss: 1.2964e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.8775e-04 - val_loss: 2.0956e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 8.5262e-04 - val_loss: 1.5664e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 9.9806e-04 - val_loss: 2.7978e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 9.7591e-04 - val_loss: 1.1683e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 9.2778e-04 - val_loss: 1.8533e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.6748e-04 - val_loss: 1.0265e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 7.1241e-04 - val_loss: 9.8251e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.5939e-04 - val_loss: 3.9032e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.9318e-04 - val_loss: 2.3943e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 7.0251e-04 - val_loss: 3.9094e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.3845e-04 - val_loss: 2.6874e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 9.2493e-04 - val_loss: 1.2427e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.0981e-04 - val_loss: 4.0343e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.5239e-04 - val_loss: 1.4788e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.0834e-04 - val_loss: 9.9118e-05\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 8.3327e-04 - val_loss: 5.7105e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.3672e-04 - val_loss: 2.2342e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.1263e-04 - val_loss: 2.7595e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.3226e-04 - val_loss: 1.2521e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.9787e-04 - val_loss: 1.0233e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 6.2360e-04 - val_loss: 1.1311e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.2282e-04 - val_loss: 2.4992e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.6533e-04 - val_loss: 1.2948e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.4844e-04 - val_loss: 1.2448e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 6.8645e-04 - val_loss: 1.5990e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.6689e-04 - val_loss: 1.0030e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.6621e-04 - val_loss: 1.9885e-04\n",
      "9/9 [==============================] - 3s 26ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.32034734079032\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 47ms/step - loss: 0.0072 - val_loss: 3.0843e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 9.2329e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0012 - val_loss: 2.2965e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0011 - val_loss: 1.9917e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 9.6679e-04 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0011 - val_loss: 6.9904e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.0355e-04 - val_loss: 1.4488e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.1168e-04 - val_loss: 2.7367e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.4276e-04 - val_loss: 1.7918e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.8709e-04 - val_loss: 5.6448e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.3548e-04 - val_loss: 2.8056e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.7411e-04 - val_loss: 3.7086e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.1080e-04 - val_loss: 1.7248e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.5090e-04 - val_loss: 2.0479e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.7694e-04 - val_loss: 1.0465e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.5223e-04 - val_loss: 1.1695e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.6515e-04 - val_loss: 1.5052e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.7796e-04 - val_loss: 1.1496e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3108e-04 - val_loss: 5.8450e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.1034e-04 - val_loss: 1.3530e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8659e-04 - val_loss: 1.1044e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 8.2823e-04 - val_loss: 0.0010\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.6781e-04 - val_loss: 1.7438e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.3532e-04 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3383e-04 - val_loss: 2.3289e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.5790e-04 - val_loss: 1.1268e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.1299e-04 - val_loss: 4.3589e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.3288e-04 - val_loss: 3.3705e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.4233e-04 - val_loss: 2.2893e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.7661e-04 - val_loss: 2.6311e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.5906e-04 - val_loss: 1.0540e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.5141e-04 - val_loss: 1.2579e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.2220e-04 - val_loss: 1.1095e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.1803e-04 - val_loss: 2.1926e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.1905e-04 - val_loss: 1.0758e-04\n",
      "9/9 [==============================] - 2s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.6878185495295\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 56ms/step - loss: 0.0077 - val_loss: 3.3989e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 5s - loss: 0.0028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0018 - val_loss: 2.8350e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0011 - val_loss: 2.0399e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.7337e-04 - val_loss: 2.6676e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.3259e-04 - val_loss: 1.7771e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.7057e-04 - val_loss: 3.9704e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.2804e-04 - val_loss: 2.9456e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.3106e-04 - val_loss: 1.1971e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.6707e-04 - val_loss: 1.2543e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.3589e-04 - val_loss: 3.1718e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.7430e-04 - val_loss: 0.0017\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.0186e-04 - val_loss: 7.1942e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.7630e-04 - val_loss: 1.3629e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.4742e-04 - val_loss: 1.5939e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.0772e-04 - val_loss: 1.4162e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.2601e-04 - val_loss: 1.1818e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.8551e-04 - val_loss: 1.4881e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.1700e-04 - val_loss: 1.4743e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.5978e-04 - val_loss: 1.1104e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.3671e-04 - val_loss: 1.2175e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.9338e-04 - val_loss: 1.8201e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 6.1936e-04 - val_loss: 1.3238e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.0687e-04 - val_loss: 3.5395e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.1308e-04 - val_loss: 1.0987e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.5304e-04 - val_loss: 2.0765e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0055e-04 - val_loss: 8.1304e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.4715e-04 - val_loss: 4.4509e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.9803e-04 - val_loss: 2.3556e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.8229e-04 - val_loss: 1.2013e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.8258e-04 - val_loss: 2.9501e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.3805e-04 - val_loss: 2.4180e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.8536e-04 - val_loss: 1.7040e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.7877e-04 - val_loss: 1.3143e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.9282e-04 - val_loss: 2.6853e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.5126e-04 - val_loss: 1.0694e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.7602e-04 - val_loss: 1.2587e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.8602e-04 - val_loss: 4.2161e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.6578e-04 - val_loss: 0.0017\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.1493e-04 - val_loss: 2.3375e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.5355e-04 - val_loss: 1.8316e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.5136e-04 - val_loss: 6.4690e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8417e-04 - val_loss: 1.1263e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.1708e-04 - val_loss: 1.1247e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.3042e-04 - val_loss: 1.5218e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.1884e-04 - val_loss: 1.8458e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.9571e-04 - val_loss: 3.4937e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.2138e-04 - val_loss: 1.4796e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.9092e-04 - val_loss: 1.7189e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.0371e-04 - val_loss: 1.3144e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.2491e-04 - val_loss: 1.8181e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.5849e-04 - val_loss: 1.3976e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.4567e-04 - val_loss: 2.0177e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.2100e-04 - val_loss: 1.1991e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.4765e-04 - val_loss: 1.2153e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.9678e-04 - val_loss: 1.0800e-04\n",
      "9/9 [==============================] - 4s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.970845736582135\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 61ms/step - loss: 0.0061 - val_loss: 3.7768e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 5s - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0012 - val_loss: 2.3623e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0011 - val_loss: 1.6245e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0013 - val_loss: 1.3156e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.3089e-04 - val_loss: 2.3165e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.7357e-04 - val_loss: 1.7316e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 7.0904e-04 - val_loss: 1.6455e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.4555e-04 - val_loss: 2.2918e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.8802e-04 - val_loss: 1.0543e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.7554e-04 - val_loss: 2.2076e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.4839e-04 - val_loss: 2.2653e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.9369e-04 - val_loss: 4.3933e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 5.8714e-04 - val_loss: 2.4055e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.2034e-04 - val_loss: 2.3404e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.3198e-04 - val_loss: 1.2398e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.4834e-04 - val_loss: 1.9749e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.1015e-04 - val_loss: 3.4302e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.3679e-04 - val_loss: 2.0239e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.4800e-04 - val_loss: 1.1063e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 7.2516e-04 - val_loss: 1.8138e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.3520e-04 - val_loss: 1.4855e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.1561e-04 - val_loss: 1.0555e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 7.4741e-04 - val_loss: 4.7218e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 8.5384e-04 - val_loss: 6.1921e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.8024e-04 - val_loss: 1.1208e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.4660e-04 - val_loss: 2.2697e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.6786e-04 - val_loss: 3.1198e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.6640e-04 - val_loss: 4.4271e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.2785e-04 - val_loss: 7.0429e-04\n",
      "9/9 [==============================] - 2s 26ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.041589083187446\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 20s 72ms/step - loss: 0.0072 - val_loss: 2.9610e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 6s - loss: 0.0022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0014 - val_loss: 2.3003e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 9.0774e-04 - val_loss: 2.5169e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.5729e-04 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 9.1243e-04 - val_loss: 2.1771e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.6657e-04 - val_loss: 2.1835e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.6784e-04 - val_loss: 1.8845e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 8.4225e-04 - val_loss: 1.1939e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 9.4342e-04 - val_loss: 1.5250e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.8336e-04 - val_loss: 1.2054e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.8398e-04 - val_loss: 6.3925e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.5310e-04 - val_loss: 1.2087e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0011 - val_loss: 4.9692e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.9102e-04 - val_loss: 1.6085e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 7.9182e-04 - val_loss: 1.5347e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 7.2163e-04 - val_loss: 1.2414e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 8.3074e-04 - val_loss: 2.5871e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 8.7656e-04 - val_loss: 1.0965e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.7266e-04 - val_loss: 2.2512e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.7689e-04 - val_loss: 1.0406e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.0494e-04 - val_loss: 2.0303e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.5010e-04 - val_loss: 1.3341e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 6.7698e-04 - val_loss: 4.5951e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 7.5018e-04 - val_loss: 1.2667e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.4727e-04 - val_loss: 1.3905e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.8728e-04 - val_loss: 1.4457e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.6526e-04 - val_loss: 4.4422e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 8.7411e-04 - val_loss: 2.3925e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.8729e-04 - val_loss: 1.0638e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 8.0033e-04 - val_loss: 8.2824e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 0.0011 - val_loss: 4.0354e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.2737e-04 - val_loss: 1.0284e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.0386e-04 - val_loss: 1.2230e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0011 - val_loss: 2.5084e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.2647e-04 - val_loss: 1.0081e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.8556e-04 - val_loss: 3.9812e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 5.7908e-04 - val_loss: 1.2047e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.8953e-04 - val_loss: 1.7217e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.4710e-04 - val_loss: 1.0790e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 6.8145e-04 - val_loss: 1.0845e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 5.9119e-04 - val_loss: 1.3080e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.3647e-04 - val_loss: 1.3412e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.6692e-04 - val_loss: 3.4525e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.1755e-04 - val_loss: 2.2810e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.1093e-04 - val_loss: 1.1966e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 6.9297e-04 - val_loss: 1.0363e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.8897e-04 - val_loss: 1.1537e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.0567e-04 - val_loss: 9.8905e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.7816e-04 - val_loss: 1.3302e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.1224e-04 - val_loss: 2.9170e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.4031e-04 - val_loss: 4.5989e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.4767e-04 - val_loss: 1.1977e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.2267e-04 - val_loss: 1.1823e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.7797e-04 - val_loss: 1.3846e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.3129e-04 - val_loss: 1.0580e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 6.9153e-04 - val_loss: 1.0241e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.1941e-04 - val_loss: 1.1587e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.2146e-04 - val_loss: 1.5332e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 7.1771e-04 - val_loss: 1.2827e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.1997e-04 - val_loss: 1.5699e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.0348e-04 - val_loss: 1.1286e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 7.1391e-04 - val_loss: 1.1294e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 6.5175e-04 - val_loss: 1.2098e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.9095e-04 - val_loss: 1.2961e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 6.4131e-04 - val_loss: 1.5069e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.1538e-04 - val_loss: 1.7659e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 6.2287e-04 - val_loss: 1.6298e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 6.2862e-04 - val_loss: 1.2083e-04\n",
      "9/9 [==============================] - 3s 30ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.268870487046044\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 15s 42ms/step - loss: 0.0064 - val_loss: 2.9445e-04\n",
      "Epoch 2/100\n",
      "  4/134 [..............................] - ETA: 2s - loss: 0.0012    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0011 - val_loss: 5.5519e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0010 - val_loss: 5.3607e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 9.3283e-04 - val_loss: 2.0337e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.5412e-04 - val_loss: 5.9348e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.2547e-04 - val_loss: 1.6891e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.1614e-04 - val_loss: 1.1831e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.9488e-04 - val_loss: 1.9672e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4510e-04 - val_loss: 1.5546e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.0916e-04 - val_loss: 5.2968e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.2700e-04 - val_loss: 2.6860e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.1893e-04 - val_loss: 3.6983e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.1500e-04 - val_loss: 4.4967e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 9.3901e-04 - val_loss: 1.1717e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.5909e-04 - val_loss: 2.5149e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.6391e-04 - val_loss: 1.2329e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.5361e-04 - val_loss: 7.2132e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.2336e-04 - val_loss: 1.4798e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1210e-04 - val_loss: 6.5022e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.4727e-04 - val_loss: 1.6973e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2981e-04 - val_loss: 1.6533e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.6322e-04 - val_loss: 2.6850e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.0825e-04 - val_loss: 1.2096e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.2376e-04 - val_loss: 5.3310e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.1925e-04 - val_loss: 1.2700e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.9181e-04 - val_loss: 1.6098e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.0867e-04 - val_loss: 3.5913e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.8165e-04 - val_loss: 1.0431e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.5818e-04 - val_loss: 1.9009e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.8240e-04 - val_loss: 1.1193e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.8451e-04 - val_loss: 1.0561e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.8276e-04 - val_loss: 1.0548e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1756e-04 - val_loss: 1.1777e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.0676e-04 - val_loss: 1.4862e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.8505e-04 - val_loss: 1.9785e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.6694e-04 - val_loss: 1.2293e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.7469e-04 - val_loss: 9.9517e-05\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 5.4788e-04 - val_loss: 1.0619e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 5.9828e-04 - val_loss: 1.2957e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.1566e-04 - val_loss: 1.2444e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.1962e-04 - val_loss: 1.0658e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.5725e-04 - val_loss: 6.8606e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 6.5742e-04 - val_loss: 2.8959e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.3922e-04 - val_loss: 1.7316e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.3618e-04 - val_loss: 3.7444e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 6.5410e-04 - val_loss: 1.4857e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.3649e-04 - val_loss: 1.9537e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.4196e-04 - val_loss: 1.4216e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.5602e-04 - val_loss: 9.8940e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.5892e-04 - val_loss: 9.9372e-05\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.0019e-04 - val_loss: 1.4259e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2717e-04 - val_loss: 1.0329e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.7283e-04 - val_loss: 1.2571e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.5418e-04 - val_loss: 1.2500e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.7610e-04 - val_loss: 1.0226e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.0242e-04 - val_loss: 1.4238e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 5.7681e-04 - val_loss: 1.0499e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.1144e-04 - val_loss: 1.8958e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.5507e-04 - val_loss: 1.4585e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.3678e-04 - val_loss: 2.2592e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.6411e-04 - val_loss: 1.0587e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.6971e-04 - val_loss: 1.2864e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1040e-04 - val_loss: 0.0015\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.9233e-04 - val_loss: 1.3596e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.7162e-04 - val_loss: 1.6983e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.5432e-04 - val_loss: 1.2753e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.1795e-04 - val_loss: 1.0461e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.7226e-04 - val_loss: 1.1600e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4143e-04 - val_loss: 9.2921e-04\n",
      "9/9 [==============================] - 2s 14ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 46.763455646659274\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 49ms/step - loss: 0.0067 - val_loss: 4.4378e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0017 - val_loss: 6.9342e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0011 - val_loss: 3.7314e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.7154e-04 - val_loss: 1.3990e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.9803e-04 - val_loss: 1.2981e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.8234e-04 - val_loss: 0.0019\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7507e-04 - val_loss: 4.0731e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.7491e-04 - val_loss: 3.6969e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.8373e-04 - val_loss: 2.9429e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.9859e-04 - val_loss: 1.2211e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.6123e-04 - val_loss: 3.3613e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8323e-04 - val_loss: 1.2224e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.6622e-04 - val_loss: 1.6702e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.9331e-04 - val_loss: 1.2720e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.1214e-04 - val_loss: 2.2658e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.6392e-04 - val_loss: 1.2305e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.9507e-04 - val_loss: 5.4103e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.0283e-04 - val_loss: 1.1155e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.5617e-04 - val_loss: 2.2365e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 8.9086e-04 - val_loss: 1.4222e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.4849e-04 - val_loss: 3.8000e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.8464e-04 - val_loss: 8.5276e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 9.4237e-04 - val_loss: 1.2204e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.3363e-04 - val_loss: 3.8813e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.7323e-04 - val_loss: 1.1598e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 7.9948e-04 - val_loss: 1.9498e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.7075e-04 - val_loss: 2.3928e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 6.5685e-04 - val_loss: 1.2422e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 6.8735e-04 - val_loss: 2.3983e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.1830e-04 - val_loss: 2.1583e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.2792e-04 - val_loss: 1.4945e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.0418e-04 - val_loss: 4.9450e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.3765e-04 - val_loss: 1.1914e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 6.6352e-04 - val_loss: 2.8954e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.7685e-04 - val_loss: 1.0642e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1954e-04 - val_loss: 1.2305e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.7345e-04 - val_loss: 1.8038e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.7433e-04 - val_loss: 1.9648e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.9573e-04 - val_loss: 1.0212e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.0984e-04 - val_loss: 2.9215e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.4911e-04 - val_loss: 3.2431e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.0951e-04 - val_loss: 1.1175e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.5827e-04 - val_loss: 1.0393e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 6.1682e-04 - val_loss: 1.6009e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.3427e-04 - val_loss: 1.0933e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.5375e-04 - val_loss: 1.1318e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.5564e-04 - val_loss: 1.3230e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 6.0379e-04 - val_loss: 1.1834e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 5.8690e-04 - val_loss: 1.2054e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.8122e-04 - val_loss: 2.4857e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.1253e-04 - val_loss: 1.3386e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.5491e-04 - val_loss: 2.5078e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.1529e-04 - val_loss: 3.2093e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.3219e-04 - val_loss: 2.4577e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.7445e-04 - val_loss: 2.2298e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.1836e-04 - val_loss: 1.4782e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.6018e-04 - val_loss: 9.8262e-05\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.3711e-04 - val_loss: 9.8025e-05\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 5.7061e-04 - val_loss: 9.7495e-05\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9584e-04 - val_loss: 2.4896e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.1345e-04 - val_loss: 1.6620e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.9106e-04 - val_loss: 1.9405e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.2148e-04 - val_loss: 2.2267e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.5865e-04 - val_loss: 1.9010e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.4471e-04 - val_loss: 9.8855e-05\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.3378e-04 - val_loss: 1.0035e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 7.5006e-04 - val_loss: 1.1722e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.9794e-04 - val_loss: 1.2928e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.2536e-04 - val_loss: 2.2261e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.5369e-04 - val_loss: 1.0461e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.6118e-04 - val_loss: 1.2287e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.1439e-04 - val_loss: 1.1738e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.7589e-04 - val_loss: 1.0788e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.8563e-04 - val_loss: 1.1676e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.5201e-04 - val_loss: 1.2001e-04\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.0191e-04 - val_loss: 9.8095e-05\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 5.6877e-04 - val_loss: 1.4130e-04\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.0575e-04 - val_loss: 1.0991e-04\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.9185e-04 - val_loss: 1.8179e-04\n",
      "9/9 [==============================] - 3s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 47.06222330545111\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 13s 41ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 2/100\n",
      "  5/134 [>.............................] - ETA: 3s - loss: 0.0027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0014 - val_loss: 4.0186e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0011 - val_loss: 2.4670e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.8718e-04 - val_loss: 1.8148e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.1776e-04 - val_loss: 1.9607e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.1790e-04 - val_loss: 9.4602e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.1247e-04 - val_loss: 2.9218e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.6175e-04 - val_loss: 5.9302e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2575e-04 - val_loss: 1.1114e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.9719e-04 - val_loss: 1.1558e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.0824e-04 - val_loss: 2.7718e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.5408e-04 - val_loss: 2.0213e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.0685e-04 - val_loss: 1.0544e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.5496e-04 - val_loss: 4.0194e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.2258e-04 - val_loss: 1.2322e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.5969e-04 - val_loss: 1.5970e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.6705e-04 - val_loss: 1.5104e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.0113e-04 - val_loss: 1.8475e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.8597e-04 - val_loss: 1.2763e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.3115e-04 - val_loss: 1.5496e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.2820e-04 - val_loss: 2.9403e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.0767e-04 - val_loss: 1.2713e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.4601e-04 - val_loss: 2.1986e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.7274e-04 - val_loss: 1.2578e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.7601e-04 - val_loss: 2.1195e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.5482e-04 - val_loss: 1.5214e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.9023e-04 - val_loss: 1.1199e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.5454e-04 - val_loss: 4.1309e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.4335e-04 - val_loss: 1.2222e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.5186e-04 - val_loss: 1.3319e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.2482e-04 - val_loss: 1.0379e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.2704e-04 - val_loss: 1.0349e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.3359e-04 - val_loss: 1.1738e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.6049e-04 - val_loss: 1.7397e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.8142e-04 - val_loss: 4.5592e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.2341e-04 - val_loss: 1.6185e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.2773e-04 - val_loss: 2.3199e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.5852e-04 - val_loss: 1.2245e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.7512e-04 - val_loss: 1.3712e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.4767e-04 - val_loss: 1.5089e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.1623e-04 - val_loss: 1.4020e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.0455e-04 - val_loss: 2.1511e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9125e-04 - val_loss: 1.7809e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.6662e-04 - val_loss: 1.2712e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.6361e-04 - val_loss: 1.1979e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9432e-04 - val_loss: 1.4518e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.1124e-04 - val_loss: 6.6921e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.8587e-04 - val_loss: 1.7058e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.3200e-04 - val_loss: 1.0893e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.2909e-04 - val_loss: 1.0542e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.1495e-04 - val_loss: 9.9367e-05\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.1326e-04 - val_loss: 9.9394e-05\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.2111e-04 - val_loss: 1.0759e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.4836e-04 - val_loss: 1.0119e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9942e-04 - val_loss: 4.2101e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.3182e-04 - val_loss: 1.7287e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.9262e-04 - val_loss: 1.4417e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.8015e-04 - val_loss: 2.1898e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.1209e-04 - val_loss: 1.0053e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.4253e-04 - val_loss: 1.1030e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.2980e-04 - val_loss: 1.2050e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.5793e-04 - val_loss: 1.0788e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.3563e-04 - val_loss: 1.5000e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.7822e-04 - val_loss: 1.8830e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.0773e-04 - val_loss: 1.9128e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.2736e-04 - val_loss: 9.9838e-05\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.5011e-04 - val_loss: 1.4001e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.7484e-04 - val_loss: 2.1928e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.9778e-04 - val_loss: 1.4120e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 5.8940e-04 - val_loss: 1.8669e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.0034e-04 - val_loss: 1.0592e-04\n",
      "9/9 [==============================] - 2s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 46.74387605643885\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 53ms/step - loss: 0.0067 - val_loss: 4.7680e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0013 - val_loss: 5.6035e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0014 - val_loss: 1.9568e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0010 - val_loss: 9.5550e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 2.0656e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 9.6747e-04 - val_loss: 1.2361e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.0826e-04 - val_loss: 2.3036e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0010 - val_loss: 1.3407e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.1736e-04 - val_loss: 3.5187e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.3751e-04 - val_loss: 0.0020\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.1121e-04 - val_loss: 1.1374e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.6528e-04 - val_loss: 4.9199e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.1927e-04 - val_loss: 0.0014\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0012 - val_loss: 3.3854e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.3800e-04 - val_loss: 1.1266e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.9056e-04 - val_loss: 1.7401e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.8055e-04 - val_loss: 1.1498e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.9179e-04 - val_loss: 2.7646e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.5123e-04 - val_loss: 8.3641e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.9085e-04 - val_loss: 1.2525e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8210e-04 - val_loss: 1.2296e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.5663e-04 - val_loss: 4.7584e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.9683e-04 - val_loss: 1.4275e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.9929e-04 - val_loss: 1.2367e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.4560e-04 - val_loss: 1.0187e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0013 - val_loss: 2.1416e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.0815e-04 - val_loss: 1.0156e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 6.1124e-04 - val_loss: 1.1445e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.7327e-04 - val_loss: 1.1718e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.2819e-04 - val_loss: 4.0427e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0457e-04 - val_loss: 3.8744e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.6480e-04 - val_loss: 9.8207e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.2864e-04 - val_loss: 1.0921e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.4966e-04 - val_loss: 2.7008e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.6464e-04 - val_loss: 1.4081e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.4750e-04 - val_loss: 1.2050e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.8486e-04 - val_loss: 1.2649e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.9563e-04 - val_loss: 1.8857e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.2957e-04 - val_loss: 1.1360e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.8818e-04 - val_loss: 1.0836e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.3366e-04 - val_loss: 1.3105e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.3694e-04 - val_loss: 1.2093e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.6655e-04 - val_loss: 1.3798e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.2341e-04 - val_loss: 1.2864e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.6350e-04 - val_loss: 2.0749e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.6538e-04 - val_loss: 3.6438e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.5663e-04 - val_loss: 1.0868e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.5688e-04 - val_loss: 1.3910e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0914e-04 - val_loss: 1.2478e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 6.7458e-04 - val_loss: 1.0547e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 6.0289e-04 - val_loss: 1.6357e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 5.6632e-04 - val_loss: 2.2954e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 46.68350101296531\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_gru_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e12d1fd-830d-49c2-a171-a4c0ae04bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 50.19392084907332}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 48.21089018708109}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 47.671125557419856}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 48.83101165467385}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 47.02926976548513}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 47.259058428487094}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 47.02101516576364}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 47.32034734079032}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 47.6878185495295}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 47.970845736582135}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 47.041589083187446}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 47.268870487046044}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 46.763455646659274}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 47.06222330545111}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 46.74387605643885}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 46.68350101296531}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
