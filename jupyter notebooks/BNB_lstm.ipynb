{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1513031-ea8b-416e-8991-ae54888cefad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8fee62-f307-423a-adf7-04175f5a25a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72a7703-597c-4e0e-a42d-cf929fe8d3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c5fb4e-b49b-4722-b3c7-3d761cee2df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd68d936-c86b-4bcc-8f68-4eaf2cbbf6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3764b4-3282-401f-af66-2f10d96b6deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95be5620-3835-43b0-b2fc-11ffc1d8b4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    lstm_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"BNB_model_lstm.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(lstm_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'Plot_actualvspredicted/BNB_actual_vs_predicted.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'loss_curve/BNB_loss_curve.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196001a2-93ef-43d4-9741-8796a8995df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'BNB-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7554989d-a49d-4511-9afb-ebeb00fb4947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdfa6a4-5c93-4219-b2ab-a444efae1a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d059896-c15a-4a61-8980-97b8443fabdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e7c3cf3-8dce-4092-b5e2-48c90e8a6ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 15s 29ms/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  4/268 [..............................] - ETA: 5s - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0022 - val_loss: 3.5518e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0020 - val_loss: 9.7024e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0014 - val_loss: 2.5751e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0013 - val_loss: 2.6496e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0010 - val_loss: 1.7913e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 9.7400e-04 - val_loss: 7.2293e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0010 - val_loss: 1.4686e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0011 - val_loss: 2.4788e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.0011 - val_loss: 1.9532e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 9.3622e-04 - val_loss: 1.4916e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0010 - val_loss: 2.7081e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.8166e-04 - val_loss: 1.3726e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0011 - val_loss: 3.9797e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.8553e-04 - val_loss: 2.0726e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 9.2300e-04 - val_loss: 1.6842e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 9.1356e-04 - val_loss: 1.2958e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.5388e-04 - val_loss: 4.8239e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.6955e-04 - val_loss: 1.7297e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 9.2995e-04 - val_loss: 4.6233e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 9.0996e-04 - val_loss: 4.4211e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.5159e-04 - val_loss: 1.5976e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.8738e-04 - val_loss: 5.8778e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 0.0010 - val_loss: 2.0304e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 9.0667e-04 - val_loss: 7.4392e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.7137e-04 - val_loss: 2.1913e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 8.5003e-04 - val_loss: 6.9315e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.4729e-04 - val_loss: 2.3560e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 8.2595e-04 - val_loss: 2.1315e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.5026e-04 - val_loss: 1.8020e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.7132e-04 - val_loss: 1.4930e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.1127e-04 - val_loss: 1.5456e-04\n",
      "9/9 [==============================] - 2s 13ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.949736407763667\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 21s 41ms/step - loss: 0.0101 - val_loss: 9.4964e-04\n",
      "Epoch 2/100\n",
      "  5/268 [..............................] - ETA: 7s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0038 - val_loss: 4.3085e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0024 - val_loss: 3.9449e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0023 - val_loss: 4.0208e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0016 - val_loss: 2.8111e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0012 - val_loss: 1.8186e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0010 - val_loss: 1.6522e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.6947e-04 - val_loss: 0.0022\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0010 - val_loss: 5.3431e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.4506e-04 - val_loss: 1.4230e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0011 - val_loss: 2.3696e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0010 - val_loss: 1.4332e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.9352e-04 - val_loss: 5.8278e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.8694e-04 - val_loss: 1.6659e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.6184e-04 - val_loss: 2.8816e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.0107e-04 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0011 - val_loss: 1.3506e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0010 - val_loss: 1.2651e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.6392e-04 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 9.9395e-04 - val_loss: 1.4298e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.0400e-04 - val_loss: 0.0020\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 9.5581e-04 - val_loss: 4.8835e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.3468e-04 - val_loss: 1.3949e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.6013e-04 - val_loss: 3.7739e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 8.3082e-04 - val_loss: 3.4712e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.3380e-04 - val_loss: 1.4798e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.0285e-04 - val_loss: 1.2760e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.2441e-04 - val_loss: 1.7630e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 8.0157e-04 - val_loss: 3.5193e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 4.7977e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.4604e-04 - val_loss: 1.3498e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.1416e-04 - val_loss: 3.1121e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 9.0479e-04 - val_loss: 1.3102e-04\n",
      "9/9 [==============================] - 3s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.025592495879779\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 22s 49ms/step - loss: 0.0074 - val_loss: 6.3100e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 12s - loss: 6.5352e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0027 - val_loss: 3.1492e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0014 - val_loss: 1.6736e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 0.0011 - val_loss: 5.9847e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 0.0012 - val_loss: 2.0052e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 0.0012 - val_loss: 6.2723e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 9.2865e-04 - val_loss: 3.9566e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.0011 - val_loss: 2.0608e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 8.8853e-04 - val_loss: 9.8004e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 9.2724e-04 - val_loss: 5.2675e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 9.5513e-04 - val_loss: 3.4446e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 9.0547e-04 - val_loss: 1.7840e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 9.5373e-04 - val_loss: 1.6341e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 9.9893e-04 - val_loss: 1.4792e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 9.1031e-04 - val_loss: 2.4292e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.2975e-04 - val_loss: 1.6635e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 9.2727e-04 - val_loss: 1.4133e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 1.8647e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.9849e-04 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 0.0010 - val_loss: 1.3346e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 9.4367e-04 - val_loss: 1.3669e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.4411e-04 - val_loss: 1.4477e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.9784e-04 - val_loss: 4.3246e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.5143e-04 - val_loss: 1.6200e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.8841e-04 - val_loss: 1.3148e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 9.0675e-04 - val_loss: 9.6563e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 8.7424e-04 - val_loss: 1.5427e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 7.8258e-04 - val_loss: 7.9593e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 8.5080e-04 - val_loss: 1.5103e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.6964e-04 - val_loss: 4.4360e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 7.3423e-04 - val_loss: 1.7791e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.4846e-04 - val_loss: 1.3614e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 8.7133e-04 - val_loss: 9.7349e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 8.8532e-04 - val_loss: 0.0026\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 9.4733e-04 - val_loss: 1.3718e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.0894e-04 - val_loss: 2.0754e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 9.6970e-04 - val_loss: 2.4867e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 7.6677e-04 - val_loss: 1.4335e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.7456e-04 - val_loss: 2.1712e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 7.6269e-04 - val_loss: 8.1658e-04\n",
      "9/9 [==============================] - 3s 34ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.049033785884647\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 31s 65ms/step - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 12s - loss: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 49ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 0.0023 - val_loss: 2.7235e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 0.0022 - val_loss: 2.9031e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.0015 - val_loss: 2.1103e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.0014 - val_loss: 8.2221e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 0.0013 - val_loss: 1.6673e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 16s 62ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.0010 - val_loss: 1.3502e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0011 - val_loss: 3.7222e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0011 - val_loss: 1.9499e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 0.0010 - val_loss: 1.8711e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.0012 - val_loss: 1.5650e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.0011 - val_loss: 8.7192e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 0.0011 - val_loss: 1.2875e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 18s 69ms/step - loss: 0.0011 - val_loss: 2.6531e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 9.4515e-04 - val_loss: 1.3372e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 19s 70ms/step - loss: 0.0010 - val_loss: 2.1734e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 18s 65ms/step - loss: 9.0117e-04 - val_loss: 4.4448e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 9.2649e-04 - val_loss: 1.8812e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 9.5056e-04 - val_loss: 3.0646e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 8.5410e-04 - val_loss: 1.9995e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.6201e-04 - val_loss: 2.3009e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 8.9749e-04 - val_loss: 1.9876e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0011 - val_loss: 2.4641e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 9.6985e-04 - val_loss: 1.8332e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 8.5878e-04 - val_loss: 1.4932e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 9.1852e-04 - val_loss: 4.1497e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 0.0010 - val_loss: 2.3051e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 9.8236e-04 - val_loss: 3.4405e-04\n",
      "9/9 [==============================] - 3s 36ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.528476597601788\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 37s 90ms/step - loss: 0.0081 - val_loss: 7.8604e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 20s - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 19s 71ms/step - loss: 0.0030 - val_loss: 3.0832e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.0016 - val_loss: 2.9806e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.0013 - val_loss: 3.3854e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 0.0010 - val_loss: 1.9579e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 0.0011 - val_loss: 3.4482e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 0.0010 - val_loss: 1.4304e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 8.3445e-04 - val_loss: 1.3444e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 8.3466e-04 - val_loss: 2.4054e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 9.7300e-04 - val_loss: 2.6965e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 8.6782e-04 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 8.4950e-04 - val_loss: 1.3448e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 9.3869e-04 - val_loss: 5.1593e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 0.0011 - val_loss: 1.4361e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 8.5248e-04 - val_loss: 1.8180e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 7.9373e-04 - val_loss: 9.1034e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.0010 - val_loss: 1.9411e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 8.7436e-04 - val_loss: 6.9050e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 9.8828e-04 - val_loss: 8.8094e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 8.7275e-04 - val_loss: 1.3004e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.7776e-04 - val_loss: 2.7042e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 9.4547e-04 - val_loss: 1.7928e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 0.0010 - val_loss: 1.7876e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 8.2109e-04 - val_loss: 3.2459e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 7.6749e-04 - val_loss: 1.6734e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 7.4103e-04 - val_loss: 7.1506e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 8.5548e-04 - val_loss: 2.5373e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.3696e-04 - val_loss: 2.1121e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 8.5197e-04 - val_loss: 1.4100e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 7.3901e-04 - val_loss: 1.3198e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 8.8122e-04 - val_loss: 5.8046e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.6764e-04 - val_loss: 4.1078e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.0345e-04 - val_loss: 2.6709e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 8.4543e-04 - val_loss: 1.4381e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.5461e-04 - val_loss: 5.3861e-04\n",
      "8/8 [==============================] - 3s 39ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.22992612544076\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 64s 148ms/step - loss: 0.0087 - val_loss: 5.9866e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 32s 120ms/step - loss: 0.0038 - val_loss: 7.9444e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0033 - val_loss: 7.4130e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0022 - val_loss: 3.3265e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0015 - val_loss: 2.1297e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0016 - val_loss: 3.5077e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 0.0012 - val_loss: 4.3651e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0011 - val_loss: 7.3504e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0011 - val_loss: 6.6750e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 9.8149e-04 - val_loss: 2.4814e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0010 - val_loss: 4.8564e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 0.0010 - val_loss: 1.3565e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 0.0010 - val_loss: 5.8237e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 9.7497e-04 - val_loss: 2.4585e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 9.1157e-04 - val_loss: 2.3652e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 9.7851e-04 - val_loss: 6.2214e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 9.7708e-04 - val_loss: 2.6651e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 9.4555e-04 - val_loss: 3.2456e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 0.0010 - val_loss: 3.4361e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 0.0010 - val_loss: 1.6665e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 8.5368e-04 - val_loss: 1.6891e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 7.9245e-04 - val_loss: 3.5627e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 9.1126e-04 - val_loss: 2.1292e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 9.1653e-04 - val_loss: 1.4095e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 8.1298e-04 - val_loss: 3.1593e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 8.8559e-04 - val_loss: 3.6817e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 26s 97ms/step - loss: 7.9819e-04 - val_loss: 1.9368e-04\n",
      "8/8 [==============================] - 6s 58ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 10.624284810150742\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 45s 117ms/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 27s 102ms/step - loss: 0.0029 - val_loss: 3.2112e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.0020 - val_loss: 2.1116e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0016 - val_loss: 2.0861e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0014 - val_loss: 1.8144e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 0.0011 - val_loss: 6.3013e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 29s 106ms/step - loss: 9.0531e-04 - val_loss: 1.8534e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 9.7096e-04 - val_loss: 1.6706e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 8.8684e-04 - val_loss: 1.4750e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 8.3053e-04 - val_loss: 5.5433e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 9.8577e-04 - val_loss: 8.8526e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 9.2691e-04 - val_loss: 1.2628e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 8.8434e-04 - val_loss: 3.5430e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 26s 97ms/step - loss: 0.0011 - val_loss: 5.2065e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 9.5961e-04 - val_loss: 1.3539e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 9.5476e-04 - val_loss: 3.2855e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 0.0011 - val_loss: 4.8895e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 9.3199e-04 - val_loss: 2.6055e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 8.1494e-04 - val_loss: 8.5306e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 8.7326e-04 - val_loss: 1.5005e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 28s 104ms/step - loss: 8.9694e-04 - val_loss: 2.1193e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 28s 104ms/step - loss: 9.4165e-04 - val_loss: 2.0666e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 8.2478e-04 - val_loss: 1.8797e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 28s 105ms/step - loss: 9.9999e-04 - val_loss: 1.6394e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 9.6217e-04 - val_loss: 1.3045e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 9.2096e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 8.6362e-04 - val_loss: 3.7568e-04\n",
      "8/8 [==============================] - 5s 79ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.364121099381788\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 62s 155ms/step - loss: 0.0121 - val_loss: 0.0026\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 37s 137ms/step - loss: 0.0038 - val_loss: 7.4064e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 36s 134ms/step - loss: 0.0032 - val_loss: 7.4181e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 0.0025 - val_loss: 2.4711e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.0020 - val_loss: 5.6652e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.0020 - val_loss: 3.3555e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 0.0015 - val_loss: 1.7134e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 36s 134ms/step - loss: 0.0012 - val_loss: 3.7731e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.0011 - val_loss: 2.7051e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 0.0010 - val_loss: 2.6234e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 9.7691e-04 - val_loss: 4.1728e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 0.0012 - val_loss: 1.3244e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 9.4114e-04 - val_loss: 1.6802e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 9.7816e-04 - val_loss: 1.9276e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 0.0011 - val_loss: 7.1317e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 38s 143ms/step - loss: 0.0011 - val_loss: 7.6047e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 9.4151e-04 - val_loss: 3.6262e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.0011 - val_loss: 2.1313e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.0010 - val_loss: 1.6266e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 29s 107ms/step - loss: 0.0010 - val_loss: 1.6217e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 36s 136ms/step - loss: 9.3239e-04 - val_loss: 2.9873e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 37s 136ms/step - loss: 9.5012e-04 - val_loss: 3.1848e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 38s 143ms/step - loss: 9.7076e-04 - val_loss: 2.4074e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 40s 149ms/step - loss: 9.9364e-04 - val_loss: 8.9626e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 39s 144ms/step - loss: 8.7373e-04 - val_loss: 1.5998e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 39s 145ms/step - loss: 0.0010 - val_loss: 3.4956e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 39s 147ms/step - loss: 8.6017e-04 - val_loss: 5.9939e-04\n",
      "8/8 [==============================] - 7s 97ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.983796500444765\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 32s 74ms/step - loss: 0.0109 - val_loss: 0.0018\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0034 - val_loss: 7.9594e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0029 - val_loss: 6.0749e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0022 - val_loss: 5.0307e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0020 - val_loss: 3.7640e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0019 - val_loss: 4.1345e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0015 - val_loss: 5.4483e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0011 - val_loss: 2.6249e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0012 - val_loss: 2.6735e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.8678e-04 - val_loss: 7.9006e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0012 - val_loss: 1.6436e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 8.5809e-04 - val_loss: 4.9147e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.6134e-04 - val_loss: 3.3733e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.9469e-04 - val_loss: 2.2264e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0010 - val_loss: 2.2047e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.8827e-04 - val_loss: 1.4736e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.9614e-04 - val_loss: 1.7439e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.3237e-04 - val_loss: 1.4736e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.9702e-04 - val_loss: 2.6679e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 9.4910e-04 - val_loss: 8.4316e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.0700e-04 - val_loss: 2.3810e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.5678e-04 - val_loss: 1.3927e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.8984e-04 - val_loss: 1.5817e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.7457e-04 - val_loss: 5.8420e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 8.1596e-04 - val_loss: 1.4221e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.9639e-04 - val_loss: 1.5319e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.4278e-04 - val_loss: 1.8176e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.6654e-04 - val_loss: 3.2500e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 8.6834e-04 - val_loss: 2.6383e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.5195e-04 - val_loss: 6.6131e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 8.6705e-04 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 9.5801e-04 - val_loss: 1.8783e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 9.0516e-04 - val_loss: 4.3942e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.0792e-04 - val_loss: 1.6855e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.3114e-04 - val_loss: 5.2168e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 8.6488e-04 - val_loss: 5.8185e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.4979e-04 - val_loss: 1.6686e-04\n",
      "9/9 [==============================] - 5s 25ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.956974097047279\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 39s 103ms/step - loss: 0.0114 - val_loss: 0.0015\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0058 - val_loss: 6.5510e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0038 - val_loss: 9.5449e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 0.0033 - val_loss: 7.1681e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0026 - val_loss: 5.6130e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0018 - val_loss: 4.4548e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0019 - val_loss: 2.7244e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0017 - val_loss: 5.0753e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0010 - val_loss: 3.0172e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.5419e-04 - val_loss: 2.2982e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0014 - val_loss: 2.2894e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 9.8555e-04 - val_loss: 6.9465e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 9.2395e-04 - val_loss: 4.8794e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0010 - val_loss: 4.6760e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 9.2568e-04 - val_loss: 2.1276e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0010 - val_loss: 2.0859e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0011 - val_loss: 1.9197e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 8.4889e-04 - val_loss: 1.5044e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 9.3923e-04 - val_loss: 1.6985e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 9.2527e-04 - val_loss: 2.2890e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.4650e-04 - val_loss: 2.9162e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 9.1170e-04 - val_loss: 1.4730e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 9.2501e-04 - val_loss: 1.8640e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.5383e-04 - val_loss: 1.8933e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.9035e-04 - val_loss: 8.6654e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.7926e-04 - val_loss: 2.8867e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 9.6532e-04 - val_loss: 3.7018e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.6761e-04 - val_loss: 4.2267e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 9.6847e-04 - val_loss: 2.5807e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.9272e-04 - val_loss: 1.5548e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 9.6627e-04 - val_loss: 1.7961e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 8.2045e-04 - val_loss: 1.8078e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 8.8119e-04 - val_loss: 3.0646e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.6177e-04 - val_loss: 3.3862e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 8.1339e-04 - val_loss: 2.7633e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.8485e-04 - val_loss: 1.9711e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.5778e-04 - val_loss: 1.4822e-04\n",
      "9/9 [==============================] - 8s 31ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.681233403143206\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 40s 120ms/step - loss: 0.0096 - val_loss: 0.0022\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0039 - val_loss: 5.8778e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 0.0024 - val_loss: 7.8242e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 0.0017 - val_loss: 2.2488e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 0.0016 - val_loss: 2.8918e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 0.0013 - val_loss: 4.3056e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0012 - val_loss: 1.6339e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 9.3344e-04 - val_loss: 1.6969e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 9.6293e-04 - val_loss: 2.5798e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 9.8574e-04 - val_loss: 1.4957e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 9.1005e-04 - val_loss: 1.4127e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 9.5782e-04 - val_loss: 1.5736e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.8538e-04 - val_loss: 1.4478e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0012 - val_loss: 9.3867e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 8.1113e-04 - val_loss: 2.2570e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.5518e-04 - val_loss: 1.6197e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 9.0964e-04 - val_loss: 1.6641e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 8.3457e-04 - val_loss: 1.7143e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 9.0573e-04 - val_loss: 4.3234e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.0222e-04 - val_loss: 1.4380e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.9540e-04 - val_loss: 2.1454e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 9.8762e-04 - val_loss: 3.3523e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.8291e-04 - val_loss: 3.3229e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 8.8355e-04 - val_loss: 3.1778e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.7672e-04 - val_loss: 1.5649e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 7.7319e-04 - val_loss: 1.7266e-04\n",
      "9/9 [==============================] - 10s 42ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.8171382566044585\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 58s 146ms/step - loss: 0.0121 - val_loss: 0.0015\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 11s 83ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 0.0036 - val_loss: 4.7900e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 0.0022 - val_loss: 3.4484e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 0.0024 - val_loss: 5.4253e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 12s 89ms/step - loss: 0.0020 - val_loss: 3.0379e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.0014 - val_loss: 2.1906e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 0.0015 - val_loss: 4.0263e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 9.8417e-04 - val_loss: 1.6333e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 11s 78ms/step - loss: 0.0013 - val_loss: 2.4961e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 9.0692e-04 - val_loss: 1.8213e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0010 - val_loss: 3.5747e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 8.4421e-04 - val_loss: 5.0651e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 0.0011 - val_loss: 4.2265e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 9.9984e-04 - val_loss: 4.0293e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 8.1848e-04 - val_loss: 8.5129e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 9.3554e-04 - val_loss: 2.1302e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 0.0012 - val_loss: 2.3693e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 9.6329e-04 - val_loss: 2.4092e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 8.4355e-04 - val_loss: 1.4514e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 8.8799e-04 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 8.7159e-04 - val_loss: 4.3016e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 9.5166e-04 - val_loss: 3.4994e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 9.9703e-04 - val_loss: 1.3736e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.4121e-04 - val_loss: 8.7908e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 0.0012 - val_loss: 1.7134e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 8.4048e-04 - val_loss: 1.2937e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.7903e-04 - val_loss: 1.5969e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.0670e-04 - val_loss: 2.4822e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.3863e-04 - val_loss: 2.6714e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 7.6782e-04 - val_loss: 1.4173e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 8.5767e-04 - val_loss: 5.0207e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 9.5683e-04 - val_loss: 4.7657e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 8.5723e-04 - val_loss: 2.2306e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 8.7014e-04 - val_loss: 1.3538e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 0.0011 - val_loss: 4.2020e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.9570e-04 - val_loss: 1.3878e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.1421e-04 - val_loss: 2.2466e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 8.3037e-04 - val_loss: 1.9627e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.8275e-04 - val_loss: 2.6681e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.4456e-04 - val_loss: 1.6920e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.5993e-04 - val_loss: 2.5269e-04\n",
      "9/9 [==============================] - 7s 40ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.228332185133109\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 31s 109ms/step - loss: 0.0098 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 9s - loss: 0.0084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0026 - val_loss: 6.1246e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0016 - val_loss: 4.4926e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0017 - val_loss: 8.6765e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 0.0015 - val_loss: 2.4526e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0016 - val_loss: 1.7545e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0011 - val_loss: 9.7877e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0012 - val_loss: 1.4783e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.2612e-04 - val_loss: 1.5746e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 9.0133e-04 - val_loss: 1.5120e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.5002e-04 - val_loss: 3.3753e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 9.4916e-04 - val_loss: 2.0933e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 9.5490e-04 - val_loss: 2.0296e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 8.4247e-04 - val_loss: 1.4529e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 11s 78ms/step - loss: 9.4221e-04 - val_loss: 3.0994e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.3032e-04 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.3079e-04 - val_loss: 2.1754e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.3060e-04 - val_loss: 3.3440e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.8992e-04 - val_loss: 1.6141e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 9.8187e-04 - val_loss: 4.6851e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.0376e-04 - val_loss: 3.1107e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0010 - val_loss: 8.5331e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 8.1026e-04 - val_loss: 1.4420e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 8.3265e-04 - val_loss: 1.3039e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 8.2254e-04 - val_loss: 5.7353e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.3158e-04 - val_loss: 1.4706e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 7.5547e-04 - val_loss: 5.8692e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 8.5518e-04 - val_loss: 4.3821e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 7.8352e-04 - val_loss: 2.0591e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.7748e-04 - val_loss: 2.4561e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 8.2802e-04 - val_loss: 1.4029e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.0010 - val_loss: 2.4391e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 8.5456e-04 - val_loss: 5.4966e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.8554e-04 - val_loss: 2.2211e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.8479e-04 - val_loss: 1.4607e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 7.9177e-04 - val_loss: 1.8664e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 8.2188e-04 - val_loss: 1.3649e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 7.2722e-04 - val_loss: 3.9029e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 7.3182e-04 - val_loss: 1.7089e-04\n",
      "8/8 [==============================] - 4s 41ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.309168986268094\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 34s 125ms/step - loss: 0.0150 - val_loss: 8.9432e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 12s 93ms/step - loss: 0.0044 - val_loss: 5.1095e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 0.0038 - val_loss: 7.3633e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 0.0028 - val_loss: 3.9131e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 0.0018 - val_loss: 2.3802e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 0.0015 - val_loss: 2.2154e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 0.0014 - val_loss: 3.3961e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 0.0012 - val_loss: 1.7473e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 0.0015 - val_loss: 1.6828e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 0.0011 - val_loss: 2.0135e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0011 - val_loss: 2.0970e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 9.2949e-04 - val_loss: 1.5946e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.0011 - val_loss: 5.3760e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 9.5625e-04 - val_loss: 1.3980e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 8.3666e-04 - val_loss: 2.0408e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 8.8020e-04 - val_loss: 2.4581e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 9.9750e-04 - val_loss: 1.5251e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 8.4975e-04 - val_loss: 5.8573e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 9.0034e-04 - val_loss: 5.9807e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 9.9391e-04 - val_loss: 2.1820e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.2657e-04 - val_loss: 1.3459e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 8.1199e-04 - val_loss: 1.9395e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 8.4344e-04 - val_loss: 8.3649e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.5887e-04 - val_loss: 2.0703e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 0.0010 - val_loss: 1.2958e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.4231e-04 - val_loss: 1.4999e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 7.9730e-04 - val_loss: 1.3429e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 8.0476e-04 - val_loss: 1.3323e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.9103e-04 - val_loss: 1.3942e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.1849e-04 - val_loss: 1.4769e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.9309e-04 - val_loss: 1.3285e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 7.4919e-04 - val_loss: 2.3925e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.7962e-04 - val_loss: 7.5151e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 8.2147e-04 - val_loss: 5.6028e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 13s 99ms/step - loss: 7.6693e-04 - val_loss: 1.7360e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 7.1873e-04 - val_loss: 3.0824e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 13s 97ms/step - loss: 9.8057e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 7.1516e-04 - val_loss: 3.2475e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 8.9405e-04 - val_loss: 7.3941e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 13s 99ms/step - loss: 8.1784e-04 - val_loss: 1.3902e-04\n",
      "8/8 [==============================] - 6s 54ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.814027285854598\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 39s 150ms/step - loss: 0.0081 - val_loss: 9.1453e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 17s 128ms/step - loss: 0.0029 - val_loss: 5.3956e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 17s 124ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 16s 116ms/step - loss: 0.0019 - val_loss: 2.6766e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 16s 118ms/step - loss: 0.0014 - val_loss: 7.2981e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 16s 120ms/step - loss: 0.0013 - val_loss: 3.0530e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 16s 119ms/step - loss: 0.0012 - val_loss: 1.7358e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 9.9309e-04 - val_loss: 1.5260e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 9.3914e-04 - val_loss: 7.1240e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 0.0011 - val_loss: 5.6762e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 8.7156e-04 - val_loss: 1.3201e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 14s 106ms/step - loss: 8.8490e-04 - val_loss: 1.3975e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 16s 117ms/step - loss: 9.2792e-04 - val_loss: 4.0310e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 16s 120ms/step - loss: 8.2562e-04 - val_loss: 1.4056e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 0.0011 - val_loss: 1.4254e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 0.0011 - val_loss: 3.8273e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 8.9087e-04 - val_loss: 3.0184e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 16s 118ms/step - loss: 0.0012 - val_loss: 1.2664e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 8.7657e-04 - val_loss: 4.7792e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 16s 121ms/step - loss: 8.5725e-04 - val_loss: 5.5268e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 17s 129ms/step - loss: 9.9684e-04 - val_loss: 3.5981e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 18s 137ms/step - loss: 7.0498e-04 - val_loss: 3.0122e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 18s 132ms/step - loss: 7.7364e-04 - val_loss: 1.3242e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 17s 130ms/step - loss: 8.3949e-04 - val_loss: 0.0023\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 16s 119ms/step - loss: 9.3007e-04 - val_loss: 2.8866e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 7.9260e-04 - val_loss: 3.8599e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 17s 128ms/step - loss: 7.6416e-04 - val_loss: 1.6632e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 17s 126ms/step - loss: 8.7263e-04 - val_loss: 4.7176e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 16s 117ms/step - loss: 8.4054e-04 - val_loss: 1.7706e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 7.7226e-04 - val_loss: 1.3490e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 8.5216e-04 - val_loss: 1.4493e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 16s 116ms/step - loss: 9.1665e-04 - val_loss: 1.4758e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 16s 116ms/step - loss: 7.3668e-04 - val_loss: 2.3076e-04\n",
      "8/8 [==============================] - 5s 72ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.827474581500474\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 35s 146ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 15s - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 16s 121ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 0.0027 - val_loss: 5.7337e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 0.0024 - val_loss: 2.9685e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 17s 124ms/step - loss: 0.0020 - val_loss: 3.1535e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 17s 125ms/step - loss: 0.0016 - val_loss: 1.8298e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 17s 126ms/step - loss: 0.0012 - val_loss: 6.5310e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 17s 123ms/step - loss: 0.0011 - val_loss: 3.3447e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 20s 148ms/step - loss: 9.9000e-04 - val_loss: 1.6823e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 0.0011 - val_loss: 3.4198e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 9.1132e-04 - val_loss: 3.3806e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 18s 137ms/step - loss: 9.3595e-04 - val_loss: 0.0014\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 0.0011 - val_loss: 1.5829e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 8.6883e-04 - val_loss: 6.7320e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 0.0011 - val_loss: 1.9445e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 9.0462e-04 - val_loss: 3.8382e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 7.6369e-04 - val_loss: 1.6582e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 8.2516e-04 - val_loss: 1.8273e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 18s 137ms/step - loss: 8.6386e-04 - val_loss: 1.6749e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 19s 138ms/step - loss: 9.7299e-04 - val_loss: 2.1196e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 18s 138ms/step - loss: 8.4004e-04 - val_loss: 1.7237e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 19s 139ms/step - loss: 9.1838e-04 - val_loss: 1.2941e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 9.4520e-04 - val_loss: 1.3580e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 18s 132ms/step - loss: 7.9279e-04 - val_loss: 1.4430e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 18s 132ms/step - loss: 0.0010 - val_loss: 3.2177e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 0.0011 - val_loss: 5.8179e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 8.7249e-04 - val_loss: 6.7563e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 8.6261e-04 - val_loss: 4.1151e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 8.9123e-04 - val_loss: 3.7811e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 7.5609e-04 - val_loss: 3.5655e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 17s 129ms/step - loss: 8.8799e-04 - val_loss: 7.5933e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 8.1222e-04 - val_loss: 1.3242e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 8.6315e-04 - val_loss: 3.4989e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 7.9266e-04 - val_loss: 2.4539e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 19s 139ms/step - loss: 7.8856e-04 - val_loss: 2.6714e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 7.7828e-04 - val_loss: 1.3412e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "8/8 [==============================] - 5s 81ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.242742537900384\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fc4e52-b991-4c9f-b9bd-596a05a38b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 6.949736407763667}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 7.025592495879779}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 6.049033785884647}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 7.528476597601788}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 6.22992612544076}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 10.624284810150742}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 6.364121099381788}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 6.983796500444765}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 6.956974097047279}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 7.681233403143206}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 6.8171382566044585}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 6.228332185133109}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 6.309168986268094}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 6.814027285854598}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 6.827474581500474}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 6.242742537900384}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88199911-bd4b-41f4-8de8-0dd783b18b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = joblib.load(\"BNB_model_lstm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20f27749-6d4c-4086-9b4a-9faacddf1625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df1 = yf.download(\"BNB-USD\",\"2024-01-01\",\"2024-01-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d092bf74-5e88-416c-9ef7-e0a6440efe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "255b13f2-f006-4a69-80c5-1ac81edb77cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df1.filter(['Close']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ed1abb6-7bde-45ad-bb1d-73cfadc7d264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_scaled = scaler1.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1518fb54-22da-478e-a278-9626f23cd298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_25_days = df1_scaled[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3a18f07-8603-4387-910b-74ea6b606c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "future_prices = []\n",
    "for _ in range(30):\n",
    "    X_future = np.array([last_25_days])\n",
    "    lstm_predicted_price = model.predict(X_future)\n",
    "    last_25_days_lstm = np.append(last_25_days, lstm_predicted_price, axis=0)[1:]\n",
    "    future_prices.append(lstm_predicted_price[0, 0])\n",
    "    last_25_days = last_25_days_lstm.copy()  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60208773-f6da-4e5d-8cef-d08280cb79e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "future_prices = np.array(future_prices)\n",
    "future_prices = future_prices.reshape(1,-1)\n",
    "future_prices = scaler1.inverse_transform(future_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df2ede9e-bd8a-4275-ae7b-5ebbbf58740f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-02-01    300.175903\n",
       "2024-02-02    301.154968\n",
       "2024-02-03    299.736725\n",
       "2024-02-04    304.734161\n",
       "2024-02-05    300.854034\n",
       "2024-02-06    302.710144\n",
       "2024-02-07    307.634583\n",
       "2024-02-08    318.871887\n",
       "2024-02-09    323.842285\n",
       "2024-02-10    323.133881\n",
       "2024-02-11    320.787537\n",
       "2024-02-12    327.944611\n",
       "2024-02-13    324.868225\n",
       "2024-02-14    334.245972\n",
       "2024-02-15    354.710815\n",
       "2024-02-16    360.890381\n",
       "2024-02-17    352.908112\n",
       "2024-02-18    349.679962\n",
       "2024-02-19    351.807098\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.download(\"BNB-USD\", \"2024-02-1\", \"2024-02-20\")['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc97cbac-0a68-43f2-b05e-31814f515733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[306.7083 , 305.83725, 305.4069 , 305.48727, 305.92413, 306.45868,\n",
       "        306.86816, 307.05743, 307.0495 , 306.9252 , 306.76953, 306.6432 ,\n",
       "        306.57288, 306.55484, 306.56732, 306.58487, 306.5893 , 306.5739 ,\n",
       "        306.5417 , 306.5006 , 306.45905, 306.4226 , 306.39334, 306.37012,\n",
       "        306.35037, 306.33145, 306.3117 , 306.29056, 306.2684 , 306.24612]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b31772-53cf-49f0-a8aa-194f6e4aeb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
