{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ebecab-51a9-4571-8616-0f6b5e062529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0c4e8b-03e8-4a5f-9432-78111e8eb877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7484e2-ab6c-4e57-81c3-bf2718fab584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59510eda-2f8e-49f3-a4bd-f618255501b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81aba24e-2aa4-416d-87c1-c433cd78d62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c3be9fa-7b9f-4798-84cc-f9560b3f7271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'LSTMmodel_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    gru_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    gru_predictions = model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, gru_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"LSTM_model_gru.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(gru_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BTC_actual_vs_predicted_LSTM.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BTC_loss_curve_LSTM.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2438bf43-82ca-437c-ba0e-5c73f963fe6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'BTC-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'\n",
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49761f53-97d0-4915-90bc-083fd60ce1db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b48d21-849f-4b8b-9237-d9b268121438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 17s 31ms/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "  4/268 [..............................] - ETA: 6s - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0029 - val_loss: 4.8882e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0015 - val_loss: 3.6143e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0012 - val_loss: 3.8366e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 0.0012 - val_loss: 2.4269e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 9.8900e-04 - val_loss: 7.1535e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.7431e-04 - val_loss: 2.4515e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.4708e-04 - val_loss: 2.3296e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.5741e-04 - val_loss: 2.8744e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.2691e-04 - val_loss: 5.8263e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.9459e-04 - val_loss: 4.5508e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.6946e-04 - val_loss: 4.7459e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.9437e-04 - val_loss: 3.1941e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 7.8634e-04 - val_loss: 3.0016e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 6.1832e-04 - val_loss: 6.5229e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.2147e-04 - val_loss: 1.5157e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.0011e-04 - val_loss: 2.1978e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.0239e-04 - val_loss: 2.9569e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.4892e-04 - val_loss: 2.2180e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.2228e-04 - val_loss: 2.4729e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.2915e-04 - val_loss: 4.3846e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.1983e-04 - val_loss: 1.6266e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 6.4664e-04 - val_loss: 2.3701e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.3366e-04 - val_loss: 2.1758e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.8589e-04 - val_loss: 4.2071e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 7.0131e-04 - val_loss: 1.5271e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 5.8246e-04 - val_loss: 1.2703e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 5.7969e-04 - val_loss: 1.3334e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.8036e-04 - val_loss: 6.7744e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 5.8281e-04 - val_loss: 1.2827e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4128e-04 - val_loss: 1.3897e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.1728e-04 - val_loss: 1.9208e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.2358e-04 - val_loss: 1.4159e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.0827e-04 - val_loss: 2.3517e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.3082e-04 - val_loss: 1.4504e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4482e-04 - val_loss: 1.6459e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.5786e-04 - val_loss: 1.5564e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.5341e-04 - val_loss: 1.3632e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.9372e-04 - val_loss: 1.8648e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 5.5650e-04 - val_loss: 1.2422e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.0961e-04 - val_loss: 1.1692e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.4194e-04 - val_loss: 1.9767e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.5855e-04 - val_loss: 1.6042e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.7379e-04 - val_loss: 1.9818e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 6.5912e-04 - val_loss: 5.0645e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 6.2020e-04 - val_loss: 1.2185e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 5.2555e-04 - val_loss: 1.8185e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 5.2101e-04 - val_loss: 1.3439e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.3771e-04 - val_loss: 3.0683e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.0744e-04 - val_loss: 2.9616e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.7773e-04 - val_loss: 1.3825e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.3793e-04 - val_loss: 1.1346e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.3589e-04 - val_loss: 1.6685e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 6.1590e-04 - val_loss: 1.6250e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.6779e-04 - val_loss: 1.5121e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.4124e-04 - val_loss: 1.3029e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 5.4596e-04 - val_loss: 1.3240e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4893e-04 - val_loss: 1.5785e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.5125e-04 - val_loss: 1.2612e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4933e-04 - val_loss: 2.1191e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 5.2720e-04 - val_loss: 1.4290e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.8784e-04 - val_loss: 1.1402e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.4245e-04 - val_loss: 1.1858e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4018e-04 - val_loss: 2.4899e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.9451e-04 - val_loss: 1.1874e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.0983e-04 - val_loss: 1.2919e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.0747e-04 - val_loss: 1.3523e-04\n",
      "Epoch 69/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 5.2848e-04 - val_loss: 1.3286e-04\n",
      "Epoch 70/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 6.2022e-04 - val_loss: 4.1878e-04\n",
      "Epoch 71/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 5.2374e-04 - val_loss: 1.1067e-04\n",
      "Epoch 72/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.4735e-04 - val_loss: 1.8153e-04\n",
      "Epoch 73/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 5.4730e-04 - val_loss: 1.8218e-04\n",
      "Epoch 74/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.6936e-04 - val_loss: 1.7653e-04\n",
      "Epoch 75/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.4509e-04 - val_loss: 2.4435e-04\n",
      "Epoch 76/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4794e-04 - val_loss: 1.5792e-04\n",
      "Epoch 77/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.1999e-04 - val_loss: 1.2373e-04\n",
      "Epoch 78/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.4017e-04 - val_loss: 1.4392e-04\n",
      "Epoch 79/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 5.1220e-04 - val_loss: 2.1059e-04\n",
      "Epoch 80/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.2518e-04 - val_loss: 2.1071e-04\n",
      "Epoch 81/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 5.3673e-04 - val_loss: 1.2564e-04\n",
      "Epoch 82/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.1755e-04 - val_loss: 1.3685e-04\n",
      "Epoch 83/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.1624e-04 - val_loss: 1.6638e-04\n",
      "Epoch 84/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.4073e-04 - val_loss: 1.1170e-04\n",
      "Epoch 85/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.4373e-04 - val_loss: 1.6518e-04\n",
      "Epoch 86/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.7873e-04 - val_loss: 2.3593e-04\n",
      "Epoch 87/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.0251e-04 - val_loss: 1.4168e-04\n",
      "Epoch 88/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.1177e-04 - val_loss: 2.3037e-04\n",
      "Epoch 89/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.1735e-04 - val_loss: 1.5951e-04\n",
      "Epoch 90/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.0244e-04 - val_loss: 1.1185e-04\n",
      "Epoch 91/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.0834e-04 - val_loss: 1.4896e-04\n",
      "9/9 [==============================] - 3s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 878.3645536309717\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 29s 52ms/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 10s - loss: 4.4557e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0039 - val_loss: 8.2013e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0030 - val_loss: 7.0827e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0021 - val_loss: 5.9119e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0016 - val_loss: 6.3342e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0013 - val_loss: 3.6508e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0014 - val_loss: 3.0551e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.5321e-04 - val_loss: 5.4217e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.7836e-04 - val_loss: 2.1585e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.1669e-04 - val_loss: 2.2791e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.8822e-04 - val_loss: 2.6372e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 9.0193e-04 - val_loss: 5.8057e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.0281e-04 - val_loss: 3.0031e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.7457e-04 - val_loss: 1.6034e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.0636e-04 - val_loss: 1.7501e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4635e-04 - val_loss: 1.7478e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.9137e-04 - val_loss: 3.2146e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 7.2634e-04 - val_loss: 1.5053e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.9202e-04 - val_loss: 2.1614e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.8102e-04 - val_loss: 1.3713e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.3131e-04 - val_loss: 1.4793e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.8281e-04 - val_loss: 1.7612e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4057e-04 - val_loss: 1.6758e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.7940e-04 - val_loss: 1.2532e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.6017e-04 - val_loss: 1.7641e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.2227e-04 - val_loss: 1.5745e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.7740e-04 - val_loss: 1.6711e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.5887e-04 - val_loss: 1.1392e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.1688e-04 - val_loss: 1.4648e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4371e-04 - val_loss: 2.1598e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.7710e-04 - val_loss: 2.8415e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.0395e-04 - val_loss: 1.6419e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.3195e-04 - val_loss: 1.3541e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.4883e-04 - val_loss: 1.4799e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.2487e-04 - val_loss: 3.4344e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.0437e-04 - val_loss: 1.9331e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 5.9000e-04 - val_loss: 1.2858e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.3564e-04 - val_loss: 2.7239e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 5.5407e-04 - val_loss: 1.8794e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.2349e-04 - val_loss: 1.3063e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.1535e-04 - val_loss: 1.2304e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 6.8013e-04 - val_loss: 1.3370e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.4426e-04 - val_loss: 3.7821e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.2046e-04 - val_loss: 1.9186e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 6.0657e-04 - val_loss: 1.4375e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 5.9202e-04 - val_loss: 1.4297e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.2004e-04 - val_loss: 1.5539e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 5.8273e-04 - val_loss: 1.1917e-04\n",
      "9/9 [==============================] - 5s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 823.2489429520285\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 27s 52ms/step - loss: 0.0057 - val_loss: 5.6555e-04\n",
      "Epoch 2/100\n",
      "  2/268 [..............................] - ETA: 13s - loss: 4.8471e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0018 - val_loss: 2.9078e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0013 - val_loss: 6.8110e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 3.8771e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.7890e-04 - val_loss: 1.8880e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.1195e-04 - val_loss: 2.2540e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.3323e-04 - val_loss: 7.5324e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.5604e-04 - val_loss: 3.3686e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.2500e-04 - val_loss: 5.2382e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.4159e-04 - val_loss: 1.3025e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.9051e-04 - val_loss: 4.1603e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.5061e-04 - val_loss: 1.7629e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.0936e-04 - val_loss: 1.9591e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.1931e-04 - val_loss: 3.1617e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8860e-04 - val_loss: 5.2725e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.9794e-04 - val_loss: 2.4166e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.3326e-04 - val_loss: 1.4255e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.1472e-04 - val_loss: 2.9047e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.3589e-04 - val_loss: 2.9752e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8950e-04 - val_loss: 1.4254e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.7781e-04 - val_loss: 1.2852e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.7473e-04 - val_loss: 1.5888e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.6605e-04 - val_loss: 2.0468e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.3403e-04 - val_loss: 1.2889e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.9348e-04 - val_loss: 2.3105e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.2095e-04 - val_loss: 2.3797e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.6663e-04 - val_loss: 1.3565e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.8800e-04 - val_loss: 3.7100e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7313e-04 - val_loss: 1.7554e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0763e-04 - val_loss: 1.3338e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.2650e-04 - val_loss: 1.1508e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.1277e-04 - val_loss: 2.1892e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0376e-04 - val_loss: 1.0979e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.5555e-04 - val_loss: 3.1753e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.6940e-04 - val_loss: 1.1488e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.4748e-04 - val_loss: 1.2899e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.9007e-04 - val_loss: 1.1253e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.2978e-04 - val_loss: 2.6211e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.8979e-04 - val_loss: 2.2650e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.1566e-04 - val_loss: 1.6275e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.9137e-04 - val_loss: 2.0408e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.1332e-04 - val_loss: 1.3171e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.2143e-04 - val_loss: 1.2417e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.4773e-04 - val_loss: 2.4444e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.0332e-04 - val_loss: 1.9885e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.6450e-04 - val_loss: 1.1521e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.3526e-04 - val_loss: 1.3524e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.2549e-04 - val_loss: 3.4835e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.2375e-04 - val_loss: 1.9749e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.6370e-04 - val_loss: 4.8995e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 5.6881e-04 - val_loss: 1.4103e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.8624e-04 - val_loss: 2.9379e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 5.6714e-04 - val_loss: 1.8101e-04\n",
      "9/9 [==============================] - 3s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 796.8780221479607\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 28s 49ms/step - loss: 0.0092 - val_loss: 9.2791e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 11s - loss: 9.3721e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0036 - val_loss: 6.3521e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.0024 - val_loss: 4.4653e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0016 - val_loss: 6.0607e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0014 - val_loss: 5.7232e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0012 - val_loss: 3.5277e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.9711e-04 - val_loss: 2.0531e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.6679e-04 - val_loss: 3.7112e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 9.8514e-04 - val_loss: 1.3636e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.7700e-04 - val_loss: 1.8226e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 9.2074e-04 - val_loss: 2.9683e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.5652e-04 - val_loss: 2.4126e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.6976e-04 - val_loss: 2.6732e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.2964e-04 - val_loss: 1.4847e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.3291e-04 - val_loss: 2.0856e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.7642e-04 - val_loss: 2.3179e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.4923e-04 - val_loss: 2.4647e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 9.0193e-04 - val_loss: 1.2003e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.9840e-04 - val_loss: 2.6988e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.5850e-04 - val_loss: 4.0483e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 14s 50ms/step - loss: 5.9530e-04 - val_loss: 2.2306e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.7041e-04 - val_loss: 2.6779e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.8562e-04 - val_loss: 1.3233e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.8085e-04 - val_loss: 1.9564e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.0131e-04 - val_loss: 1.8149e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.2281e-04 - val_loss: 2.7621e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.6343e-04 - val_loss: 1.6936e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.5002e-04 - val_loss: 1.2342e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.7896e-04 - val_loss: 1.9003e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.2437e-04 - val_loss: 1.2901e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.4533e-04 - val_loss: 2.6332e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.7334e-04 - val_loss: 1.5927e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.4153e-04 - val_loss: 2.0362e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.1373e-04 - val_loss: 1.6070e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.7645e-04 - val_loss: 1.2398e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.4671e-04 - val_loss: 1.9960e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.6977e-04 - val_loss: 1.2426e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 14s 50ms/step - loss: 6.4240e-04 - val_loss: 2.8659e-04\n",
      "9/9 [==============================] - 5s 36ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 745.5401012429093\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 34s 78ms/step - loss: 0.0087 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 16s - loss: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0034 - val_loss: 5.4172e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0022 - val_loss: 6.1389e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0016 - val_loss: 4.7234e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0014 - val_loss: 4.1210e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0013 - val_loss: 4.7235e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 0.0011 - val_loss: 3.1430e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 0.0011 - val_loss: 2.3426e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 7.5161e-04 - val_loss: 1.9876e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 8.9705e-04 - val_loss: 2.0366e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 8.5759e-04 - val_loss: 1.6903e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 8.6156e-04 - val_loss: 3.4212e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 8.3816e-04 - val_loss: 1.5230e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 7.0727e-04 - val_loss: 2.6444e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.2918e-04 - val_loss: 1.4042e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.7396e-04 - val_loss: 6.8817e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.5502e-04 - val_loss: 1.7543e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.9585e-04 - val_loss: 1.5450e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 8.0227e-04 - val_loss: 1.5925e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.2515e-04 - val_loss: 1.5637e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.0775e-04 - val_loss: 3.7284e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.0555e-04 - val_loss: 1.4325e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.7557e-04 - val_loss: 2.1482e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.3525e-04 - val_loss: 1.5845e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.7875e-04 - val_loss: 6.4977e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.2582e-04 - val_loss: 4.1219e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.7381e-04 - val_loss: 3.1484e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.6795e-04 - val_loss: 1.2744e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.3375e-04 - val_loss: 1.5312e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.9140e-04 - val_loss: 3.2516e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.2613e-04 - val_loss: 6.1113e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.0996e-04 - val_loss: 1.4960e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.8290e-04 - val_loss: 3.5359e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.3840e-04 - val_loss: 3.3369e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 6.3514e-04 - val_loss: 2.1681e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.9727e-04 - val_loss: 1.3488e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 5.7458e-04 - val_loss: 3.0150e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 6.1215e-04 - val_loss: 1.9529e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 5.6862e-04 - val_loss: 1.7344e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 6.2925e-04 - val_loss: 1.1595e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.4011e-04 - val_loss: 2.4635e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.3842e-04 - val_loss: 1.6237e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.5646e-04 - val_loss: 1.5030e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.4225e-04 - val_loss: 1.4132e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 6.0199e-04 - val_loss: 1.5568e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.3006e-04 - val_loss: 2.0050e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.3642e-04 - val_loss: 1.2130e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.2225e-04 - val_loss: 1.2951e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 6.1400e-04 - val_loss: 1.5024e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.3276e-04 - val_loss: 1.2625e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.4985e-04 - val_loss: 1.4851e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.5776e-04 - val_loss: 1.3050e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.0949e-04 - val_loss: 1.7360e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.4419e-04 - val_loss: 1.1616e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.4722e-04 - val_loss: 1.2252e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.5783e-04 - val_loss: 1.7999e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.6115e-04 - val_loss: 1.2885e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.4305e-04 - val_loss: 4.0991e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.8359e-04 - val_loss: 1.1370e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.4875e-04 - val_loss: 3.0536e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.3305e-04 - val_loss: 1.3584e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.5597e-04 - val_loss: 1.5494e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.6694e-04 - val_loss: 1.3191e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.5817e-04 - val_loss: 1.6761e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 5.5397e-04 - val_loss: 2.4741e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.2613e-04 - val_loss: 2.6287e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 6.0643e-04 - val_loss: 3.4732e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 5.4707e-04 - val_loss: 1.2601e-04\n",
      "Epoch 69/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 5.2895e-04 - val_loss: 2.0322e-04\n",
      "Epoch 70/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.8267e-04 - val_loss: 1.2863e-04\n",
      "Epoch 71/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.6131e-04 - val_loss: 1.2920e-04\n",
      "Epoch 72/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.7690e-04 - val_loss: 1.4804e-04\n",
      "Epoch 73/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.2517e-04 - val_loss: 1.1402e-04\n",
      "Epoch 74/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.6661e-04 - val_loss: 2.0713e-04\n",
      "Epoch 75/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.4616e-04 - val_loss: 1.6863e-04\n",
      "Epoch 76/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 5.5884e-04 - val_loss: 1.2167e-04\n",
      "Epoch 77/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.4021e-04 - val_loss: 1.2117e-04\n",
      "Epoch 78/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 6.1769e-04 - val_loss: 1.5594e-04\n",
      "Epoch 79/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 5.1233e-04 - val_loss: 1.3188e-04\n",
      "8/8 [==============================] - 4s 38ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 777.3400015036473\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 43s 98ms/step - loss: 0.0105 - val_loss: 8.3487e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 21s - loss: 0.0032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 21s 80ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 0.0019 - val_loss: 4.4872e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 0.0021 - val_loss: 5.0946e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 0.0012 - val_loss: 3.3582e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 0.0010 - val_loss: 2.6422e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 8.8147e-04 - val_loss: 6.2681e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 7.2811e-04 - val_loss: 1.9435e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 8.4080e-04 - val_loss: 1.9106e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 8.8194e-04 - val_loss: 2.0684e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 7.6050e-04 - val_loss: 1.8368e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 7.5407e-04 - val_loss: 1.9275e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 8.6384e-04 - val_loss: 3.4991e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.7166e-04 - val_loss: 1.5441e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 9.3013e-04 - val_loss: 1.7343e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.1029e-04 - val_loss: 2.8746e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.9148e-04 - val_loss: 4.3425e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 7.3635e-04 - val_loss: 1.6842e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 7.8036e-04 - val_loss: 1.3127e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0011 - val_loss: 6.0083e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.3714e-04 - val_loss: 5.2153e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 6.5118e-04 - val_loss: 1.3634e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 8.5411e-04 - val_loss: 2.2230e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.0705e-04 - val_loss: 5.2598e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.4846e-04 - val_loss: 1.3284e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.2597e-04 - val_loss: 1.4619e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 6.2911e-04 - val_loss: 2.8051e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 5.8125e-04 - val_loss: 2.9355e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.0476e-04 - val_loss: 3.8335e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.9898e-04 - val_loss: 1.2466e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 6.3192e-04 - val_loss: 2.3918e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.5160e-04 - val_loss: 1.3003e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.9116e-04 - val_loss: 1.4989e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 5.7327e-04 - val_loss: 1.2098e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 5.7104e-04 - val_loss: 1.4428e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 6.1568e-04 - val_loss: 1.6558e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 5.8439e-04 - val_loss: 5.3181e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.8440e-04 - val_loss: 3.1262e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.8350e-04 - val_loss: 1.2160e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 20s 76ms/step - loss: 5.8066e-04 - val_loss: 2.4968e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 6.1449e-04 - val_loss: 1.1874e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.3983e-04 - val_loss: 1.4332e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.4660e-04 - val_loss: 2.2455e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 19s 69ms/step - loss: 5.4550e-04 - val_loss: 1.2443e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 5.7727e-04 - val_loss: 1.2451e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.5709e-04 - val_loss: 1.5495e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.9138e-04 - val_loss: 1.3376e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 5.9971e-04 - val_loss: 1.2836e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.9028e-04 - val_loss: 1.3425e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 5.7215e-04 - val_loss: 2.9245e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 6.3458e-04 - val_loss: 2.3957e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 4.9656e-04 - val_loss: 1.2748e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.5084e-04 - val_loss: 1.3355e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.5646e-04 - val_loss: 1.4850e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.6805e-04 - val_loss: 2.3298e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 5.8800e-04 - val_loss: 1.4094e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.4826e-04 - val_loss: 1.1054e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 5.7722e-04 - val_loss: 1.4082e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.8508e-04 - val_loss: 1.7059e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 4.9874e-04 - val_loss: 1.7801e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 5.6246e-04 - val_loss: 1.2466e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 5.4896e-04 - val_loss: 3.1991e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.6668e-04 - val_loss: 1.2196e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 5.6644e-04 - val_loss: 1.8370e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 5.6496e-04 - val_loss: 1.1487e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 5.4169e-04 - val_loss: 1.4826e-04\n",
      "Epoch 69/100\n",
      "268/268 [==============================] - 25s 95ms/step - loss: 5.7417e-04 - val_loss: 5.4396e-04\n",
      "Epoch 70/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 5.5623e-04 - val_loss: 1.5243e-04\n",
      "Epoch 71/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 5.5073e-04 - val_loss: 1.9912e-04\n",
      "Epoch 72/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.4600e-04 - val_loss: 1.5049e-04\n",
      "Epoch 73/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.1935e-04 - val_loss: 2.0952e-04\n",
      "Epoch 74/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 5.6475e-04 - val_loss: 1.8851e-04\n",
      "Epoch 75/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 5.7717e-04 - val_loss: 2.0830e-04\n",
      "Epoch 76/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 5.5480e-04 - val_loss: 1.1265e-04\n",
      "Epoch 77/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 5.9134e-04 - val_loss: 1.1291e-04\n",
      "Epoch 78/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.5069e-04 - val_loss: 2.1290e-04\n",
      "Epoch 79/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 5.5073e-04 - val_loss: 1.1943e-04\n",
      "8/8 [==============================] - 5s 49ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 807.0470691547191\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 31s 88ms/step - loss: 0.0061 - val_loss: 7.1428e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 21s - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 23s 85ms/step - loss: 0.0027 - val_loss: 4.0684e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.0016 - val_loss: 4.4758e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 0.0014 - val_loss: 2.4940e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 0.0010 - val_loss: 5.4575e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 9.9291e-04 - val_loss: 1.6746e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 7.9564e-04 - val_loss: 2.7694e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 7.0465e-04 - val_loss: 5.4846e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 8.7206e-04 - val_loss: 1.7914e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 7.5955e-04 - val_loss: 1.3541e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.4714e-04 - val_loss: 1.8900e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 6.7847e-04 - val_loss: 2.1449e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 6.8603e-04 - val_loss: 1.2864e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 7.9831e-04 - val_loss: 1.4741e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 7.2599e-04 - val_loss: 1.2485e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 8.7857e-04 - val_loss: 1.4653e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 6.9227e-04 - val_loss: 1.2455e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 23s 88ms/step - loss: 5.8583e-04 - val_loss: 1.2354e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 6.2652e-04 - val_loss: 1.2733e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 6.3188e-04 - val_loss: 1.7525e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 7.0942e-04 - val_loss: 1.2490e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.8222e-04 - val_loss: 2.6902e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 6.6783e-04 - val_loss: 1.7458e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 26s 97ms/step - loss: 7.1510e-04 - val_loss: 2.7899e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 27s 99ms/step - loss: 6.3619e-04 - val_loss: 2.8382e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 27s 99ms/step - loss: 7.0068e-04 - val_loss: 1.9556e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 6.3464e-04 - val_loss: 2.2586e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 6.3356e-04 - val_loss: 3.8364e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 26s 96ms/step - loss: 5.9110e-04 - val_loss: 2.8964e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 6.4716e-04 - val_loss: 1.4914e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 20s 74ms/step - loss: 6.4713e-04 - val_loss: 1.2693e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.7523e-04 - val_loss: 1.1922e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 6.1708e-04 - val_loss: 1.9380e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 6.4032e-04 - val_loss: 2.9412e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 5.8173e-04 - val_loss: 1.2276e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.0871e-04 - val_loss: 1.1942e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 5.5299e-04 - val_loss: 1.4959e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 6.3106e-04 - val_loss: 1.2054e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.7975e-04 - val_loss: 1.1870e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 5.7272e-04 - val_loss: 1.3790e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 5.4099e-04 - val_loss: 2.6097e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 5.1105e-04 - val_loss: 1.6686e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 5.8433e-04 - val_loss: 3.9267e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.2609e-04 - val_loss: 1.5526e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 6.4152e-04 - val_loss: 2.9493e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 5.8820e-04 - val_loss: 2.4854e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 5.6058e-04 - val_loss: 1.3153e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 26s 97ms/step - loss: 6.4093e-04 - val_loss: 1.5838e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 6.0735e-04 - val_loss: 1.1210e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 5.4652e-04 - val_loss: 1.4042e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 5.5669e-04 - val_loss: 1.3215e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 5.8433e-04 - val_loss: 1.2520e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 5.6599e-04 - val_loss: 1.6233e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 5.7186e-04 - val_loss: 1.3287e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 24s 90ms/step - loss: 5.5772e-04 - val_loss: 3.4612e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 26s 98ms/step - loss: 5.6434e-04 - val_loss: 2.6391e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 20s 73ms/step - loss: 5.9701e-04 - val_loss: 1.3908e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 5.7327e-04 - val_loss: 1.2567e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 5.0767e-04 - val_loss: 1.5670e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.1999e-04 - val_loss: 1.5023e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 5.6582e-04 - val_loss: 1.2151e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 5.9347e-04 - val_loss: 1.2121e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 6.3883e-04 - val_loss: 4.2055e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 24s 88ms/step - loss: 5.5332e-04 - val_loss: 1.9615e-04\n",
      "Epoch 65/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 5.5005e-04 - val_loss: 1.5063e-04\n",
      "Epoch 66/100\n",
      "268/268 [==============================] - 26s 95ms/step - loss: 5.2023e-04 - val_loss: 2.1500e-04\n",
      "Epoch 67/100\n",
      "268/268 [==============================] - 25s 92ms/step - loss: 6.0555e-04 - val_loss: 1.9626e-04\n",
      "Epoch 68/100\n",
      "268/268 [==============================] - 25s 94ms/step - loss: 5.8964e-04 - val_loss: 2.6129e-04\n",
      "Epoch 69/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 4.9038e-04 - val_loss: 1.2498e-04\n",
      "8/8 [==============================] - 4s 67ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 793.4858556025573\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 54s 128ms/step - loss: 0.0072 - val_loss: 8.7603e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 30s 110ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 29s 110ms/step - loss: 0.0023 - val_loss: 4.0754e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 0.0017 - val_loss: 3.4241e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0014 - val_loss: 2.1629e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 0.0013 - val_loss: 2.1616e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 29s 109ms/step - loss: 0.0011 - val_loss: 3.2399e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 7.2175e-04 - val_loss: 2.1768e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 30s 111ms/step - loss: 7.8080e-04 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 32s 121ms/step - loss: 7.1743e-04 - val_loss: 1.4155e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 8.1266e-04 - val_loss: 1.4636e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 30s 110ms/step - loss: 7.4228e-04 - val_loss: 1.3910e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 7.2130e-04 - val_loss: 1.3140e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 7.7577e-04 - val_loss: 1.9462e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 9.1321e-04 - val_loss: 1.8736e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 6.4357e-04 - val_loss: 4.1324e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 30s 114ms/step - loss: 7.8499e-04 - val_loss: 1.3876e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 29s 108ms/step - loss: 7.8918e-04 - val_loss: 1.4259e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 6.5954e-04 - val_loss: 1.4992e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 7.4782e-04 - val_loss: 1.4963e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 8.8152e-04 - val_loss: 1.2487e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 9.7199e-04 - val_loss: 1.1640e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 7.1368e-04 - val_loss: 1.2529e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 7.5218e-04 - val_loss: 2.3776e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 5.8724e-04 - val_loss: 4.6175e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.3498e-04 - val_loss: 1.1299e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.0926e-04 - val_loss: 2.6991e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 5.9910e-04 - val_loss: 1.7158e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 7.9772e-04 - val_loss: 4.9899e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 6.0678e-04 - val_loss: 6.4576e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.2288e-04 - val_loss: 1.5320e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 5.9717e-04 - val_loss: 1.2572e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.1075e-04 - val_loss: 2.3853e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.3760e-04 - val_loss: 3.2713e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.0340e-04 - val_loss: 1.5915e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.6111e-04 - val_loss: 1.1301e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 5.7811e-04 - val_loss: 1.3172e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.8809e-04 - val_loss: 5.0051e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.2628e-04 - val_loss: 3.6470e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.1778e-04 - val_loss: 1.6750e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 6.1984e-04 - val_loss: 3.6895e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 6.8151e-04 - val_loss: 2.7422e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 7.1656e-04 - val_loss: 3.0536e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 23s 88ms/step - loss: 5.8148e-04 - val_loss: 1.1282e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 6.0422e-04 - val_loss: 1.2323e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 6.0963e-04 - val_loss: 1.5748e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.4370e-04 - val_loss: 2.4208e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 6.6810e-04 - val_loss: 2.2676e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 6.3153e-04 - val_loss: 1.3482e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 6.0550e-04 - val_loss: 1.9680e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 5.9507e-04 - val_loss: 2.8959e-04\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 21s 80ms/step - loss: 5.7807e-04 - val_loss: 1.6328e-04\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 22s 80ms/step - loss: 5.5314e-04 - val_loss: 2.0620e-04\n",
      "Epoch 54/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 6.1036e-04 - val_loss: 1.9661e-04\n",
      "Epoch 55/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.9895e-04 - val_loss: 1.1646e-04\n",
      "Epoch 56/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 5.8643e-04 - val_loss: 2.0890e-04\n",
      "Epoch 57/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.8492e-04 - val_loss: 1.9897e-04\n",
      "Epoch 58/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 5.7660e-04 - val_loss: 2.2927e-04\n",
      "Epoch 59/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 6.2167e-04 - val_loss: 5.0015e-04\n",
      "Epoch 60/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 5.8835e-04 - val_loss: 1.5140e-04\n",
      "Epoch 61/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 5.6844e-04 - val_loss: 1.1301e-04\n",
      "Epoch 62/100\n",
      "268/268 [==============================] - 25s 93ms/step - loss: 5.2799e-04 - val_loss: 1.5033e-04\n",
      "Epoch 63/100\n",
      "268/268 [==============================] - 24s 91ms/step - loss: 5.6180e-04 - val_loss: 1.3342e-04\n",
      "Epoch 64/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 6.4544e-04 - val_loss: 4.0026e-04\n",
      "8/8 [==============================] - 3s 63ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 843.2983439087086\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 45ms/step - loss: 0.0090 - val_loss: 8.2391e-04\n",
      "Epoch 2/100\n",
      "  4/134 [..............................] - ETA: 3s - loss: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0024 - val_loss: 8.9161e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0018 - val_loss: 9.0808e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0018 - val_loss: 5.3022e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0019 - val_loss: 4.1368e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0014 - val_loss: 6.0079e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 0.0012 - val_loss: 3.4401e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 0.0011 - val_loss: 2.5191e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.4827e-04 - val_loss: 2.5235e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.9709e-04 - val_loss: 3.7416e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.8743e-04 - val_loss: 2.1097e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.4914e-04 - val_loss: 2.2975e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.5302e-04 - val_loss: 4.3709e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.1693e-04 - val_loss: 5.4168e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.3096e-04 - val_loss: 2.2653e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.3080e-04 - val_loss: 1.5564e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.6109e-04 - val_loss: 1.8531e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.5976e-04 - val_loss: 7.3787e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 8.5519e-04 - val_loss: 3.1443e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2414e-04 - val_loss: 1.6550e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 6.8999e-04 - val_loss: 2.8492e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.0723e-04 - val_loss: 1.6081e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.3551e-04 - val_loss: 1.9359e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.3878e-04 - val_loss: 1.6130e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.8991e-04 - val_loss: 2.0937e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.6950e-04 - val_loss: 1.7511e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.6041e-04 - val_loss: 3.6187e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.9028e-04 - val_loss: 2.5644e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 5.9268e-04 - val_loss: 2.1744e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.9530e-04 - val_loss: 2.0860e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 5.4705e-04 - val_loss: 3.5562e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 5.4471e-04 - val_loss: 1.8620e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.8233e-04 - val_loss: 1.6809e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.8122e-04 - val_loss: 1.6558e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 5.2007e-04 - val_loss: 1.8164e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.7587e-04 - val_loss: 3.4117e-04\n",
      "9/9 [==============================] - 3s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 852.4653786327683\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 19s 54ms/step - loss: 0.0113 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0020 - val_loss: 6.7244e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0017 - val_loss: 4.7659e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0014 - val_loss: 4.9813e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0013 - val_loss: 8.7918e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 0.0012 - val_loss: 3.3126e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.0589e-04 - val_loss: 5.0711e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 9.1212e-04 - val_loss: 8.2328e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.8158e-04 - val_loss: 3.3944e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.7551e-04 - val_loss: 3.5833e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.0551e-04 - val_loss: 4.5584e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.3279e-04 - val_loss: 1.8958e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.0369e-04 - val_loss: 2.2250e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 6.3346e-04 - val_loss: 2.2437e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.6245e-04 - val_loss: 1.8481e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.9176e-04 - val_loss: 5.4122e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.9198e-04 - val_loss: 2.5955e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.3256e-04 - val_loss: 2.4490e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.0429e-04 - val_loss: 1.6599e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.4715e-04 - val_loss: 2.3951e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.9766e-04 - val_loss: 1.7965e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.4443e-04 - val_loss: 5.5433e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.1681e-04 - val_loss: 2.2115e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.8726e-04 - val_loss: 5.4884e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.4290e-04 - val_loss: 1.7948e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.1267e-04 - val_loss: 1.8393e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.5089e-04 - val_loss: 1.6692e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.8433e-04 - val_loss: 1.8170e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.0468e-04 - val_loss: 2.0583e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.7786e-04 - val_loss: 1.4525e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.7953e-04 - val_loss: 1.3142e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.8025e-04 - val_loss: 1.2944e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.8379e-04 - val_loss: 2.1135e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.4954e-04 - val_loss: 1.4096e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.9328e-04 - val_loss: 1.3643e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.6288e-04 - val_loss: 2.2704e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.6008e-04 - val_loss: 2.4623e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.1774e-04 - val_loss: 1.8711e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.5823e-04 - val_loss: 2.9711e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.8042e-04 - val_loss: 1.7942e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.3883e-04 - val_loss: 2.3151e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 5.7285e-04 - val_loss: 1.5895e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.4321e-04 - val_loss: 1.8912e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.1020e-04 - val_loss: 3.3287e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.5745e-04 - val_loss: 1.4705e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.9908e-04 - val_loss: 1.6896e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.2921e-04 - val_loss: 3.2739e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.5891e-04 - val_loss: 1.2897e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.0407e-04 - val_loss: 1.1904e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.6334e-04 - val_loss: 1.7341e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 5.9153e-04 - val_loss: 1.4643e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.7557e-04 - val_loss: 1.3274e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.7865e-04 - val_loss: 1.4671e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.8045e-04 - val_loss: 1.4853e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.3369e-04 - val_loss: 2.8272e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.4171e-04 - val_loss: 1.7600e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.5354e-04 - val_loss: 1.7807e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.0342e-04 - val_loss: 1.4609e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 4.7812e-04 - val_loss: 1.2977e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.3243e-04 - val_loss: 1.2699e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.4905e-04 - val_loss: 2.4574e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.4451e-04 - val_loss: 2.3311e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.2919e-04 - val_loss: 1.3746e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.3916e-04 - val_loss: 1.6839e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.1591e-04 - val_loss: 1.8367e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.2945e-04 - val_loss: 1.5440e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.7817e-04 - val_loss: 1.4689e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.3922e-04 - val_loss: 1.2846e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.0109e-04 - val_loss: 1.1964e-04\n",
      "9/9 [==============================] - 3s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 759.1787180014396\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 51ms/step - loss: 0.0081 - val_loss: 7.9640e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0026 - val_loss: 5.6394e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0017 - val_loss: 3.8112e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0015 - val_loss: 3.6350e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0014 - val_loss: 4.1662e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.3261e-04 - val_loss: 2.5552e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.5288e-04 - val_loss: 5.7854e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.7452e-04 - val_loss: 2.5655e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.6971e-04 - val_loss: 1.6644e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.0812e-04 - val_loss: 1.9314e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 6.7861e-04 - val_loss: 1.7331e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8841e-04 - val_loss: 3.3145e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 5.8054e-04 - val_loss: 2.0025e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.4916e-04 - val_loss: 4.8814e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.0562e-04 - val_loss: 4.7182e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.5348e-04 - val_loss: 2.7165e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.2233e-04 - val_loss: 1.4719e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.4252e-04 - val_loss: 1.9567e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.0774e-04 - val_loss: 1.2546e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 5.8054e-04 - val_loss: 4.2352e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.5610e-04 - val_loss: 3.1199e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.8107e-04 - val_loss: 2.0550e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.6074e-04 - val_loss: 1.4457e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.3410e-04 - val_loss: 1.6513e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.8286e-04 - val_loss: 1.3742e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.2700e-04 - val_loss: 1.1617e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.2039e-04 - val_loss: 3.3776e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.7085e-04 - val_loss: 5.6102e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.3042e-04 - val_loss: 1.6537e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.5365e-04 - val_loss: 1.3114e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.9159e-04 - val_loss: 2.2652e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 5.5495e-04 - val_loss: 1.3210e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.4671e-04 - val_loss: 2.6282e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 4.8965e-04 - val_loss: 1.8221e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.9049e-04 - val_loss: 1.2838e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.2351e-04 - val_loss: 1.5107e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.1818e-04 - val_loss: 1.2428e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 5.6429e-04 - val_loss: 5.0800e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.1961e-04 - val_loss: 2.8211e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.1655e-04 - val_loss: 3.4191e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.4293e-04 - val_loss: 3.4819e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.5586e-04 - val_loss: 2.0355e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.3825e-04 - val_loss: 1.2855e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 34ms/step - loss: 5.1038e-04 - val_loss: 1.7387e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 5.8096e-04 - val_loss: 1.4691e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.7361e-04 - val_loss: 1.3060e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 744.506480823787\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 18s 60ms/step - loss: 0.0144 - val_loss: 0.0016\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 6s - loss: 0.0155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0035 - val_loss: 7.6794e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0023 - val_loss: 5.4422e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0015 - val_loss: 4.6857e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0017 - val_loss: 3.5960e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0013 - val_loss: 4.0872e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0011 - val_loss: 3.3330e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.3527e-04 - val_loss: 2.5078e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.9279e-04 - val_loss: 2.1321e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.9139e-04 - val_loss: 2.1153e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.8800e-04 - val_loss: 1.6843e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.9927e-04 - val_loss: 7.0502e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.9624e-04 - val_loss: 5.1193e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.0886e-04 - val_loss: 1.8590e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.9000e-04 - val_loss: 1.6401e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.6062e-04 - val_loss: 1.6914e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 8.3763e-04 - val_loss: 1.8540e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.4130e-04 - val_loss: 1.7354e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.7480e-04 - val_loss: 1.3897e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.6974e-04 - val_loss: 2.6746e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.1804e-04 - val_loss: 2.5986e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.0282e-04 - val_loss: 1.3586e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.0352e-04 - val_loss: 1.7773e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.2569e-04 - val_loss: 1.8927e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.7275e-04 - val_loss: 1.7409e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.0802e-04 - val_loss: 1.2891e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.6015e-04 - val_loss: 1.7270e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.5864e-04 - val_loss: 2.3640e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.4019e-04 - val_loss: 2.0449e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.2649e-04 - val_loss: 1.8028e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.2479e-04 - val_loss: 2.5155e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.8357e-04 - val_loss: 1.4108e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.9076e-04 - val_loss: 1.1740e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.4489e-04 - val_loss: 1.1961e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.3984e-04 - val_loss: 2.0396e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 5.6130e-04 - val_loss: 2.4408e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 6.6249e-04 - val_loss: 2.0462e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.3720e-04 - val_loss: 1.2720e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 5.1298e-04 - val_loss: 1.3183e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.4384e-04 - val_loss: 1.6705e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.9695e-04 - val_loss: 1.7527e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.4937e-04 - val_loss: 1.5540e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.7123e-04 - val_loss: 1.6595e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.6734e-04 - val_loss: 1.6018e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 5.9499e-04 - val_loss: 1.7288e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.7290e-04 - val_loss: 2.7272e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 8.0976e-04 - val_loss: 3.8927e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.1162e-04 - val_loss: 2.8184e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.8687e-04 - val_loss: 3.2970e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.9457e-04 - val_loss: 2.8345e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 6.6548e-04 - val_loss: 1.7398e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.0385e-04 - val_loss: 1.2998e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 5.2727e-04 - val_loss: 1.2002e-04\n",
      "9/9 [==============================] - 3s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 848.0456029141642\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 66ms/step - loss: 0.0094 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 6s - loss: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0038 - val_loss: 8.5817e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0024 - val_loss: 5.9544e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0016 - val_loss: 5.3496e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0014 - val_loss: 7.1218e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0013 - val_loss: 7.3852e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0011 - val_loss: 8.3157e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0011 - val_loss: 3.0239e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.2827e-04 - val_loss: 4.6552e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.0944e-04 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.9479e-04 - val_loss: 3.8641e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.8120e-04 - val_loss: 2.1503e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.3210e-04 - val_loss: 2.7316e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.9675e-04 - val_loss: 1.5661e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.5564e-04 - val_loss: 5.8106e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.4960e-04 - val_loss: 2.2844e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.8885e-04 - val_loss: 1.6540e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.9088e-04 - val_loss: 5.3619e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.9145e-04 - val_loss: 1.8714e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.2578e-04 - val_loss: 7.8275e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.8848e-04 - val_loss: 3.0817e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.6092e-04 - val_loss: 1.9266e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 6.8868e-04 - val_loss: 3.1254e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.3872e-04 - val_loss: 2.7657e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.7468e-04 - val_loss: 1.8581e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.0169e-04 - val_loss: 9.0933e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.1602e-04 - val_loss: 4.6785e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.3418e-04 - val_loss: 3.5054e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.4047e-04 - val_loss: 1.8703e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 6.1439e-04 - val_loss: 5.7229e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 6.2227e-04 - val_loss: 1.3985e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.0702e-04 - val_loss: 1.7308e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.3602e-04 - val_loss: 1.6714e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.4568e-04 - val_loss: 2.5912e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.8706e-04 - val_loss: 2.1905e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.7937e-04 - val_loss: 1.8331e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.0767e-04 - val_loss: 2.1941e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.9651e-04 - val_loss: 1.7495e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.1965e-04 - val_loss: 1.6789e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.4980e-04 - val_loss: 1.3068e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.2484e-04 - val_loss: 1.2606e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.9256e-04 - val_loss: 1.4284e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.3439e-04 - val_loss: 3.4926e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.7696e-04 - val_loss: 4.9230e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.7388e-04 - val_loss: 1.4517e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.8663e-04 - val_loss: 1.4493e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.2590e-04 - val_loss: 4.9839e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.3670e-04 - val_loss: 1.4628e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.6427e-04 - val_loss: 2.2719e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.2396e-04 - val_loss: 2.8090e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.6985e-04 - val_loss: 1.7479e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.3592e-04 - val_loss: 3.0409e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.9833e-04 - val_loss: 1.2007e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.9317e-04 - val_loss: 1.8054e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.4864e-04 - val_loss: 1.2351e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.5505e-04 - val_loss: 2.0826e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.0515e-04 - val_loss: 2.6890e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 6.1539e-04 - val_loss: 1.1836e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 5.1958e-04 - val_loss: 2.1570e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 5.6353e-04 - val_loss: 1.9111e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.4504e-04 - val_loss: 1.1922e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 6.3556e-04 - val_loss: 2.6031e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 5.5850e-04 - val_loss: 1.1845e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 5.4337e-04 - val_loss: 3.4434e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 4.6643e-04 - val_loss: 1.1583e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.0983e-04 - val_loss: 6.8748e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.3098e-04 - val_loss: 2.1803e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.8524e-04 - val_loss: 3.6305e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.8747e-04 - val_loss: 1.1588e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.1774e-04 - val_loss: 1.2283e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.7463e-04 - val_loss: 1.2333e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.2262e-04 - val_loss: 3.8362e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.9433e-04 - val_loss: 1.6509e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.7833e-04 - val_loss: 1.7054e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.4508e-04 - val_loss: 2.0451e-04\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 5.0652e-04 - val_loss: 1.8345e-04\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.0634e-04 - val_loss: 1.2346e-04\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 4.7837e-04 - val_loss: 1.1175e-04\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.4276e-04 - val_loss: 1.3896e-04\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.2814e-04 - val_loss: 2.6984e-04\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.3291e-04 - val_loss: 1.3588e-04\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 5.2335e-04 - val_loss: 6.7362e-04\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.8462e-04 - val_loss: 1.7744e-04\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 4.8189e-04 - val_loss: 2.4259e-04\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.2298e-04 - val_loss: 1.8751e-04\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.8333e-04 - val_loss: 1.4296e-04\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.4754e-04 - val_loss: 1.6129e-04\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.8263e-04 - val_loss: 1.7319e-04\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.3171e-04 - val_loss: 1.2700e-04\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.9502e-04 - val_loss: 1.1827e-04\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.1043e-04 - val_loss: 1.5187e-04\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.4032e-04 - val_loss: 2.8948e-04\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.3976e-04 - val_loss: 2.0678e-04\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.3836e-04 - val_loss: 2.3471e-04\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 5.2855e-04 - val_loss: 1.2372e-04\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.6380e-04 - val_loss: 2.1057e-04\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 4.8948e-04 - val_loss: 1.4269e-04\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.8668e-04 - val_loss: 1.1828e-04\n",
      "8/8 [==============================] - 2s 33ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 788.1936700630375\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 24s 98ms/step - loss: 0.0093 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 9s - loss: 0.0022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 10s 75ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0029 - val_loss: 7.1703e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0018 - val_loss: 4.5752e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0015 - val_loss: 7.1960e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0014 - val_loss: 3.3642e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 9.3945e-04 - val_loss: 5.0203e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 8.9535e-04 - val_loss: 5.2632e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 0.0010 - val_loss: 2.5496e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.6204e-04 - val_loss: 2.1857e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 8.4824e-04 - val_loss: 3.2684e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 7.4084e-04 - val_loss: 1.8182e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.0648e-04 - val_loss: 1.9829e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.5357e-04 - val_loss: 2.8470e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.2004e-04 - val_loss: 2.7653e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.4187e-04 - val_loss: 2.2579e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 9.5306e-04 - val_loss: 7.2303e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.0064e-04 - val_loss: 1.8144e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.1909e-04 - val_loss: 1.6546e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 7.0715e-04 - val_loss: 2.3379e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 5.8037e-04 - val_loss: 1.5312e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.0599e-04 - val_loss: 2.5543e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 6.2084e-04 - val_loss: 1.7497e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 5.9261e-04 - val_loss: 1.5928e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 5.7255e-04 - val_loss: 2.1428e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 5.5551e-04 - val_loss: 4.2648e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.3646e-04 - val_loss: 2.9416e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.2662e-04 - val_loss: 7.0497e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.9628e-04 - val_loss: 1.4325e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.2267e-04 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.1980e-04 - val_loss: 2.4621e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.7709e-04 - val_loss: 2.0189e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.5078e-04 - val_loss: 1.3904e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 5.3707e-04 - val_loss: 1.4396e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 6.9198e-04 - val_loss: 1.3694e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 6.2994e-04 - val_loss: 4.1795e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 5.5382e-04 - val_loss: 1.6898e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 6.7798e-04 - val_loss: 2.3851e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 5.5335e-04 - val_loss: 1.4012e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.5215e-04 - val_loss: 2.2706e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.8947e-04 - val_loss: 2.4939e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.0766e-04 - val_loss: 1.2589e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 5.4525e-04 - val_loss: 3.0699e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.1579e-04 - val_loss: 1.4598e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 7.0569e-04 - val_loss: 3.4959e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 5.6563e-04 - val_loss: 1.2995e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 6.0230e-04 - val_loss: 7.0555e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 13s 101ms/step - loss: 6.4282e-04 - val_loss: 1.4070e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 5.2914e-04 - val_loss: 2.2211e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 12s 89ms/step - loss: 5.2316e-04 - val_loss: 1.1567e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 6.0059e-04 - val_loss: 1.9077e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 12s 88ms/step - loss: 5.1023e-04 - val_loss: 1.1768e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 5.2806e-04 - val_loss: 1.1925e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 5.0803e-04 - val_loss: 1.8426e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 6.4320e-04 - val_loss: 1.2443e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 6.0221e-04 - val_loss: 2.5970e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 13s 93ms/step - loss: 5.3384e-04 - val_loss: 1.3263e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 14s 104ms/step - loss: 5.8152e-04 - val_loss: 2.4322e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 5.7587e-04 - val_loss: 1.2501e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 13s 95ms/step - loss: 5.5896e-04 - val_loss: 3.6752e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 5.5299e-04 - val_loss: 1.7844e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 12s 88ms/step - loss: 5.1193e-04 - val_loss: 1.1969e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.1025e-04 - val_loss: 3.5602e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 16s 123ms/step - loss: 6.9566e-04 - val_loss: 1.7248e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 6.1923e-04 - val_loss: 1.2676e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 15s 113ms/step - loss: 6.0121e-04 - val_loss: 2.6251e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.6475e-04 - val_loss: 1.4888e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 17s 126ms/step - loss: 5.1648e-04 - val_loss: 1.3438e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 4.9047e-04 - val_loss: 1.1445e-04\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 5.5420e-04 - val_loss: 2.1930e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 19s 142ms/step - loss: 5.1354e-04 - val_loss: 1.2890e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 19s 144ms/step - loss: 5.1896e-04 - val_loss: 5.6331e-04\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 19s 140ms/step - loss: 6.0798e-04 - val_loss: 1.3009e-04\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 4.9435e-04 - val_loss: 1.4868e-04\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 5.2494e-04 - val_loss: 1.4667e-04\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 5.3024e-04 - val_loss: 1.5225e-04\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 14s 105ms/step - loss: 5.5642e-04 - val_loss: 1.4359e-04\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 20s 147ms/step - loss: 5.2519e-04 - val_loss: 1.2220e-04\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 19s 145ms/step - loss: 5.3839e-04 - val_loss: 2.2849e-04\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 6.0413e-04 - val_loss: 1.1438e-04\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 5.8412e-04 - val_loss: 1.4021e-04\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 5.1470e-04 - val_loss: 1.7820e-04\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 6.3508e-04 - val_loss: 1.1905e-04\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 5.5928e-04 - val_loss: 1.5044e-04\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 5.5480e-04 - val_loss: 2.9808e-04\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 13s 96ms/step - loss: 6.0949e-04 - val_loss: 1.4992e-04\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 13s 96ms/step - loss: 5.3073e-04 - val_loss: 1.2962e-04\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 5.0982e-04 - val_loss: 1.4874e-04\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 5.1679e-04 - val_loss: 1.2376e-04\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 4.9115e-04 - val_loss: 1.1871e-04\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 5.3196e-04 - val_loss: 1.2022e-04\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 5.2180e-04 - val_loss: 1.5919e-04\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 14s 104ms/step - loss: 4.7640e-04 - val_loss: 1.2326e-04\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 13s 99ms/step - loss: 5.2661e-04 - val_loss: 1.7574e-04\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 14s 106ms/step - loss: 5.2124e-04 - val_loss: 2.9068e-04\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 5.5574e-04 - val_loss: 1.6277e-04\n",
      "8/8 [==============================] - 4s 58ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 817.6719256827366\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 30s 150ms/step - loss: 0.0111 - val_loss: 6.7780e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 12s - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 15s 111ms/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 0.0026 - val_loss: 6.7751e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 0.0021 - val_loss: 8.5901e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 15s 113ms/step - loss: 0.0016 - val_loss: 3.6165e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 0.0012 - val_loss: 5.3545e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 0.0013 - val_loss: 3.2050e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 8.2005e-04 - val_loss: 2.8042e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 8.7787e-04 - val_loss: 2.7763e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 9.0028e-04 - val_loss: 2.0777e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 16s 117ms/step - loss: 8.3596e-04 - val_loss: 1.8103e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 15s 113ms/step - loss: 6.1901e-04 - val_loss: 2.8257e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 6.5714e-04 - val_loss: 1.5424e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 16s 116ms/step - loss: 6.8294e-04 - val_loss: 1.9011e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 7.1532e-04 - val_loss: 2.1261e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 18s 135ms/step - loss: 6.2551e-04 - val_loss: 1.4199e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 7.9865e-04 - val_loss: 1.5063e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 15s 111ms/step - loss: 6.8562e-04 - val_loss: 1.7256e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 6.4764e-04 - val_loss: 1.9422e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 6.5815e-04 - val_loss: 2.3810e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 7.0609e-04 - val_loss: 1.3070e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 14s 107ms/step - loss: 6.7155e-04 - val_loss: 3.0053e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.4160e-04 - val_loss: 2.3506e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 15s 113ms/step - loss: 7.0920e-04 - val_loss: 1.4872e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 6.3206e-04 - val_loss: 1.7202e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 5.8089e-04 - val_loss: 1.8548e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 15s 116ms/step - loss: 6.7821e-04 - val_loss: 2.4556e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 6.1648e-04 - val_loss: 1.6166e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 15s 111ms/step - loss: 6.6889e-04 - val_loss: 3.4207e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.8851e-04 - val_loss: 1.7800e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.1129e-04 - val_loss: 1.3345e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 6.3014e-04 - val_loss: 1.5133e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 5.6855e-04 - val_loss: 1.2231e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 15s 114ms/step - loss: 6.0123e-04 - val_loss: 2.9034e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 5.6678e-04 - val_loss: 1.2555e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 15s 111ms/step - loss: 5.1755e-04 - val_loss: 1.2511e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 5.7419e-04 - val_loss: 1.4407e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 5.3099e-04 - val_loss: 1.5581e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 14s 103ms/step - loss: 5.0672e-04 - val_loss: 1.7539e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 15s 110ms/step - loss: 5.3884e-04 - val_loss: 1.2733e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 16s 121ms/step - loss: 5.5206e-04 - val_loss: 1.2556e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.7375e-04"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d7ae8-0c52-4e55-97ae-5cac6e1aa714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
