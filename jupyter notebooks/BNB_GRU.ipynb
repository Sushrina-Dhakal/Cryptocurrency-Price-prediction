{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847153b4-d4af-41a4-992b-b9a5bf35210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09cf3a6-af8d-4283-8ea6-6097de7a8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d77eebe-b055-46d9-b90c-c46ad9dc2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02c85f3-4356-4564-b497-5f75c98edb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8eee78-6d1f-4147-9676-97cb22e77dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(GRU(units, return_sequences=True))\n",
    "    model.add(GRU(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3d5711-1704-4f19-b1b8-2dcf75ae3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    gru_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    gru_predictions = model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, gru_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"BNB_model_gru.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(gru_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BNB_actual_vs_predicted_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'BNB_loss_curve_GRU.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19aeb2ff-cc11-4447-9edb-13e79e510935",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'BNB-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70870bf8-c413-4cb1-a503-fc6ed13ea1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,20]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecfab0a-8ee1-4ac1-8bb4-5fed2c4046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b52e73e-2dd8-496a-912a-c41ed65ca9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f90938b-a84e-40a4-b60d-6c48dd629f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 17s 35ms/step - loss: 0.0038 - val_loss: 3.6017e-04\n",
      "Epoch 2/100\n",
      "  6/268 [..............................] - ETA: 6s - loss: 0.0035   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0016 - val_loss: 4.7028e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0012 - val_loss: 1.4630e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 9.2461e-04 - val_loss: 2.3030e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 9.4262e-04 - val_loss: 1.3232e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.3660e-04 - val_loss: 1.3049e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.9636e-04 - val_loss: 2.7634e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 9.4325e-04 - val_loss: 1.2878e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.4140e-04 - val_loss: 1.4792e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.9746e-04 - val_loss: 1.8659e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 8.2617e-04 - val_loss: 1.5089e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.0010 - val_loss: 1.5241e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.9453e-04 - val_loss: 3.9944e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.2298e-04 - val_loss: 2.6165e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 9.3974e-04 - val_loss: 1.8570e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.1502e-04 - val_loss: 2.7037e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 8.5179e-04 - val_loss: 4.9680e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 24ms/step - loss: 8.9728e-04 - val_loss: 1.4404e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.6842e-04 - val_loss: 2.6719e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.9970e-04 - val_loss: 0.0011\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.9431e-04 - val_loss: 3.3105e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.0063e-04 - val_loss: 1.6230e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 7.9028e-04 - val_loss: 1.3509e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.0371e-04 - val_loss: 1.4326e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 8.9488e-04 - val_loss: 3.1157e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 7.6288e-04 - val_loss: 4.8507e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.0902e-04 - val_loss: 6.4556e-04\n",
      "9/9 [==============================] - 2s 15ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.4744073402672475\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 22s 45ms/step - loss: 0.0051 - val_loss: 2.8286e-04\n",
      "Epoch 2/100\n",
      "  5/268 [..............................] - ETA: 8s - loss: 0.0010    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0018 - val_loss: 2.5409e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0014 - val_loss: 5.8839e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0011 - val_loss: 1.9830e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 7.4571e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 4.7009e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0014 - val_loss: 5.5458e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 9.9509e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.9676e-04 - val_loss: 1.4958e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.7364e-04 - val_loss: 6.4984e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.9396e-04 - val_loss: 3.1660e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.8612e-04 - val_loss: 5.1934e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0011 - val_loss: 2.0065e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 5.5432e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.4425e-04 - val_loss: 6.3679e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0011 - val_loss: 3.5516e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.6391e-04 - val_loss: 1.5601e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.9769e-04 - val_loss: 3.4112e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0011 - val_loss: 1.8914e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.8859e-04 - val_loss: 5.9599e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0010 - val_loss: 2.2036e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 9.2163e-04 - val_loss: 1.2792e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.2426e-04 - val_loss: 2.1451e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.0313e-04 - val_loss: 5.9978e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4550e-04 - val_loss: 2.7533e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.1443e-04 - val_loss: 4.9484e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.2086e-04 - val_loss: 1.4085e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.5799e-04 - val_loss: 2.1125e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.4762e-04 - val_loss: 3.2701e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.8768e-04 - val_loss: 1.8035e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.0909e-04 - val_loss: 2.6934e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.8555e-04 - val_loss: 3.7428e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.3139e-04 - val_loss: 1.3293e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.9003e-04 - val_loss: 2.1386e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4284e-04 - val_loss: 3.2130e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.6749e-04 - val_loss: 2.5217e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.1536e-04 - val_loss: 2.0835e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.3305e-04 - val_loss: 1.3126e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 9.4794e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.2855e-04 - val_loss: 1.3757e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4643e-04 - val_loss: 1.3817e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.7089e-04 - val_loss: 4.3559e-04\n",
      "9/9 [==============================] - 2s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.645016313614708\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 17s 39ms/step - loss: 0.0046 - val_loss: 2.3866e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 0.0012    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0014 - val_loss: 8.0142e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.8787e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 0.0013 - val_loss: 2.2716e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 0.0011 - val_loss: 4.4947e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 3.9312e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0011 - val_loss: 2.0676e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.2333e-04 - val_loss: 0.0021\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 3.3918e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 19s 73ms/step - loss: 9.9178e-04 - val_loss: 1.7738e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 8.9486e-04 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.6299e-04 - val_loss: 1.3009e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.8957e-04 - val_loss: 2.9509e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 9.1774e-04 - val_loss: 2.0794e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.9575e-04 - val_loss: 9.0470e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.1749e-04 - val_loss: 1.2051e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.5403e-04 - val_loss: 1.3764e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.9300e-04 - val_loss: 1.3347e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.7592e-04 - val_loss: 1.4039e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.0168e-04 - val_loss: 1.3070e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 9.3731e-04 - val_loss: 2.1533e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.9332e-04 - val_loss: 2.5717e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.1818e-04 - val_loss: 0.0017\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 8.7102e-04 - val_loss: 2.1005e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 8.5832e-04 - val_loss: 3.5822e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 7.8092e-04 - val_loss: 2.4645e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.2671e-04 - val_loss: 1.4161e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.7902e-04 - val_loss: 2.4721e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.1931e-04 - val_loss: 2.3865e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.5976e-04 - val_loss: 3.7872e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 9.7983e-04 - val_loss: 2.1103e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 7.4796e-04 - val_loss: 1.6441e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.3623e-04 - val_loss: 2.7593e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.1372e-04 - val_loss: 2.8179e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 9.2262e-04 - val_loss: 1.2614e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 19s 70ms/step - loss: 8.3164e-04 - val_loss: 3.7825e-04\n",
      "9/9 [==============================] - 4s 44ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 9.275660089588598\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 27s 53ms/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 12s - loss: 7.6347e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0017 - val_loss: 2.5745e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0016 - val_loss: 5.2293e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.3018e-04 - val_loss: 1.2563e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 8.5606e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 7.8625e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 9.5183e-04 - val_loss: 2.4904e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0012 - val_loss: 3.1714e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 9.6978e-04 - val_loss: 1.4178e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0011 - val_loss: 4.3464e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0013 - val_loss: 2.0593e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 0.0011 - val_loss: 1.5306e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 9.8868e-04 - val_loss: 1.6881e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.8673e-04 - val_loss: 1.4844e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.8502e-04 - val_loss: 3.1992e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 9.2513e-04 - val_loss: 2.6917e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 0.0010 - val_loss: 1.8913e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.8939e-04 - val_loss: 1.3533e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.9807e-04 - val_loss: 9.9510e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.2388e-04 - val_loss: 3.8429e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.0011 - val_loss: 4.0052e-04\n",
      "9/9 [==============================] - 3s 30ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.523011106924789\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 15s 28ms/step - loss: 0.0051 - val_loss: 2.9271e-04\n",
      "Epoch 2/100\n",
      "  7/268 [..............................] - ETA: 5s - loss: 3.8797e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0014 - val_loss: 3.8009e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.3791e-04 - val_loss: 2.5248e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.9152e-04 - val_loss: 3.3893e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.3634e-04 - val_loss: 1.9521e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0010 - val_loss: 5.7411e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.7662e-04 - val_loss: 1.3267e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.4173e-04 - val_loss: 6.3453e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.4986e-04 - val_loss: 2.9155e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 0.0010 - val_loss: 2.7197e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.6474e-04 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.1835e-04 - val_loss: 1.2661e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.1740e-04 - val_loss: 1.5685e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.5077e-04 - val_loss: 4.5509e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.9729e-04 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.2899e-04 - val_loss: 5.0629e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.8517e-04 - val_loss: 2.4993e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.8818e-04 - val_loss: 3.4882e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.8292e-04 - val_loss: 1.5854e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.8035e-04 - val_loss: 1.4257e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.5137e-04 - val_loss: 1.2196e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.5122e-04 - val_loss: 6.2008e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.1932e-04 - val_loss: 1.4883e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0010 - val_loss: 2.6851e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 5s 21ms/step - loss: 9.0535e-04 - val_loss: 2.1065e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.3491e-04 - val_loss: 1.3112e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.1032e-04 - val_loss: 4.5404e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.3846e-04 - val_loss: 1.7126e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0010 - val_loss: 2.5165e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.6002e-04 - val_loss: 1.3653e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 7.7774e-04 - val_loss: 2.1230e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 7.9201e-04 - val_loss: 1.3372e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.3458e-04 - val_loss: 1.6441e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.5108e-04 - val_loss: 2.9185e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 9.7540e-04 - val_loss: 1.8180e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 6s 20ms/step - loss: 7.9006e-04 - val_loss: 4.0925e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 7.9140e-04 - val_loss: 1.7987e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 8.2719e-04 - val_loss: 2.9291e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.2862e-04 - val_loss: 1.7271e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.3136e-04 - val_loss: 2.6743e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.6644e-04 - val_loss: 6.7990e-04\n",
      "9/9 [==============================] - 2s 13ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.334712399295536\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 19s 35ms/step - loss: 0.0053 - val_loss: 2.2266e-04\n",
      "Epoch 2/100\n",
      "  5/268 [..............................] - ETA: 6s - loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0016 - val_loss: 1.8400e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0012 - val_loss: 1.9332e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0012 - val_loss: 1.2980e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0012 - val_loss: 6.7390e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0011 - val_loss: 1.4718e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.8917e-04 - val_loss: 4.8066e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.7650e-04 - val_loss: 1.3980e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.4640e-04 - val_loss: 7.8980e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.8481e-04 - val_loss: 2.5663e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 9.7799e-04 - val_loss: 1.4116e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.5042e-04 - val_loss: 1.9324e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 9.4266e-04 - val_loss: 5.0743e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0010 - val_loss: 3.9375e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0011 - val_loss: 3.2227e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.4707e-04 - val_loss: 3.0620e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.6602e-04 - val_loss: 1.2145e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0010 - val_loss: 2.9376e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 9.3573e-04 - val_loss: 5.5185e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 9.6286e-04 - val_loss: 1.2587e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.6084e-04 - val_loss: 1.2393e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.0799e-04 - val_loss: 2.4282e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 7.8342e-04 - val_loss: 1.6550e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.8601e-04 - val_loss: 1.2506e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.9137e-04 - val_loss: 3.4624e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0010 - val_loss: 1.4854e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.7996e-04 - val_loss: 2.6609e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.3443e-04 - val_loss: 1.5207e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.1360e-04 - val_loss: 1.6703e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.1233e-04 - val_loss: 1.3167e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 8.9624e-04 - val_loss: 3.4976e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.1376e-04 - val_loss: 3.0473e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.1911e-04 - val_loss: 1.2951e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.8737e-04 - val_loss: 1.9048e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.8175e-04 - val_loss: 5.6881e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 7.9242e-04 - val_loss: 9.5703e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 7.7995e-04 - val_loss: 4.2365e-04\n",
      "9/9 [==============================] - 3s 16ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.895659893580752\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 17s 35ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 9.9989e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0018 - val_loss: 3.2714e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0011 - val_loss: 1.3873e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.0013 - val_loss: 1.7523e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0014 - val_loss: 1.6463e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.0010 - val_loss: 5.4830e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 9.8580e-04 - val_loss: 1.3848e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.5180e-04 - val_loss: 3.7377e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0010 - val_loss: 1.4165e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.0618e-04 - val_loss: 1.3172e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.6005e-04 - val_loss: 4.1603e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 9.0996e-04 - val_loss: 1.2107e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.2540e-04 - val_loss: 1.4435e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.0011 - val_loss: 6.2636e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.0011 - val_loss: 1.2622e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 9.5967e-04 - val_loss: 2.1901e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.7671e-04 - val_loss: 5.3053e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0012 - val_loss: 1.7898e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.9296e-04 - val_loss: 1.3175e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 8.7542e-04 - val_loss: 1.6492e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.6289e-04 - val_loss: 9.0188e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 9.5836e-04 - val_loss: 8.7019e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 9.0305e-04 - val_loss: 1.5387e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.7458e-04 - val_loss: 2.7060e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.4598e-04 - val_loss: 2.2961e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.9321e-04 - val_loss: 4.1939e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 7.9368e-04 - val_loss: 2.2186e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 9.1790e-04 - val_loss: 2.9026e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.8813e-04 - val_loss: 1.9243e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 8.3927e-04 - val_loss: 2.2413e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.3710e-04 - val_loss: 1.4809e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 8.9293e-04 - val_loss: 1.5738e-04\n",
      "9/9 [==============================] - 2s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.635506340097518\n",
      "Training model with epochs=100, batch_size=4, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 21s 43ms/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 3.6592e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 1.3610e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0011 - val_loss: 1.8871e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.8083e-04 - val_loss: 1.6466e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0012 - val_loss: 1.5668e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0011 - val_loss: 2.8367e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0013 - val_loss: 1.5403e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0012 - val_loss: 1.4273e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0014 - val_loss: 5.5195e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.0911e-04 - val_loss: 1.2804e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0012 - val_loss: 2.2945e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0011 - val_loss: 5.3654e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.8194e-04 - val_loss: 1.4620e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0012 - val_loss: 2.0996e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 9.3912e-04 - val_loss: 2.3501e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 7.1300e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.2481e-04 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.4328e-04 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 3.7819e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.8778e-04 - val_loss: 1.3090e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 5.1407e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.8004e-04 - val_loss: 5.8918e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0010 - val_loss: 2.2702e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.9916e-04 - val_loss: 1.8397e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 8.9242e-04 - val_loss: 1.4870e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0011 - val_loss: 1.3612e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.6394e-04 - val_loss: 3.6178e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.9325e-04 - val_loss: 1.7528e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.4052e-04 - val_loss: 1.2633e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 9.3455e-04 - val_loss: 5.3225e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.6919e-04 - val_loss: 1.2715e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.8503e-04 - val_loss: 2.2062e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.3862e-04 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.7864e-04 - val_loss: 1.3637e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.0955e-04 - val_loss: 2.2167e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 7.8950e-04 - val_loss: 1.6080e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.1169e-04 - val_loss: 2.8941e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 9.3079e-04 - val_loss: 1.7104e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.9483e-04 - val_loss: 1.5390e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.3376e-04 - val_loss: 2.0189e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.3768e-04 - val_loss: 6.7665e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 9.0822e-04 - val_loss: 1.3884e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 8.0081e-04 - val_loss: 2.7855e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 8.4403e-04 - val_loss: 2.9477e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.0830e-04 - val_loss: 2.0400e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 9.5443e-04 - val_loss: 2.4844e-04\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.4743e-04 - val_loss: 4.2599e-04\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.7963e-04 - val_loss: 4.1991e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.4130e-04 - val_loss: 3.0002e-04\n",
      "9/9 [==============================] - 3s 26ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.142855402174031\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 13s 40ms/step - loss: 0.0091 - val_loss: 3.7308e-04\n",
      "Epoch 2/100\n",
      "  5/134 [>.............................] - ETA: 3s - loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0013 - val_loss: 4.6108e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 0.0011 - val_loss: 7.8638e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 0.0011 - val_loss: 1.5318e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.8918e-04 - val_loss: 2.1546e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.1852e-04 - val_loss: 2.0648e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 9.4114e-04 - val_loss: 6.4027e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 8.3338e-04 - val_loss: 5.7369e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.9121e-04 - val_loss: 0.0017\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.5615e-04 - val_loss: 2.9824e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.9433e-04 - val_loss: 4.3989e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.1610e-04 - val_loss: 7.0519e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.8430e-04 - val_loss: 4.2731e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 0.0011 - val_loss: 1.9055e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.9486e-04 - val_loss: 4.2399e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0010 - val_loss: 4.4117e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.6155e-04 - val_loss: 1.2898e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.4341e-04 - val_loss: 1.3317e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.7303e-04 - val_loss: 1.4740e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.8964e-04 - val_loss: 1.4434e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.0638e-04 - val_loss: 2.4574e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.2957e-04 - val_loss: 3.2165e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.4220e-04 - val_loss: 4.7711e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.3583e-04 - val_loss: 2.6687e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.6300e-04 - val_loss: 1.5301e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.7551e-04 - val_loss: 1.3585e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0010 - val_loss: 1.9943e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.3781e-04 - val_loss: 1.5721e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.6240e-04 - val_loss: 1.8692e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.0297e-04 - val_loss: 3.9856e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.5976e-04 - val_loss: 1.3580e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 9.0832e-04 - val_loss: 1.7333e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.1582e-04 - val_loss: 4.5300e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.8326e-04 - val_loss: 2.0414e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.0470e-04 - val_loss: 1.3544e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.1914e-04 - val_loss: 3.3459e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.7237e-04 - val_loss: 2.1930e-04\n",
      "9/9 [==============================] - 2s 15ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.202118365560203\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 52ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0017 - val_loss: 3.4664e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0014 - val_loss: 3.1111e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0010 - val_loss: 1.7731e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.0278e-04 - val_loss: 9.1945e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.7062e-04 - val_loss: 1.7665e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.8783e-04 - val_loss: 1.4729e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.3579e-04 - val_loss: 1.4243e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.3024e-04 - val_loss: 3.2580e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 1.5241e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.2523e-04 - val_loss: 2.5019e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.6789e-04 - val_loss: 0.0010\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0010 - val_loss: 1.8604e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.6817e-04 - val_loss: 1.3205e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 8.7575e-04 - val_loss: 1.9586e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.1543e-04 - val_loss: 1.4066e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 5.1730e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.8852e-04 - val_loss: 2.0531e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.3755e-04 - val_loss: 5.0583e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.5473e-04 - val_loss: 1.5235e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.9989e-04 - val_loss: 6.5622e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.8007e-04 - val_loss: 4.0192e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.5568e-04 - val_loss: 3.5604e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.6343e-04 - val_loss: 2.6380e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.3071e-04 - val_loss: 4.6943e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.8525e-04 - val_loss: 1.7311e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.4403e-04 - val_loss: 1.6647e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.6707e-04 - val_loss: 1.2937e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.1576e-04 - val_loss: 2.8953e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.1454e-04 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 8.1052e-04 - val_loss: 2.5666e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.8351e-04 - val_loss: 1.5020e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.6927e-04 - val_loss: 1.3284e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.0018e-04 - val_loss: 4.2024e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.4661e-04 - val_loss: 1.8622e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.7367e-04 - val_loss: 1.4789e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.0690e-04 - val_loss: 1.5033e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6310e-04 - val_loss: 1.3964e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.7289e-04 - val_loss: 1.4334e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.9549e-04 - val_loss: 7.4518e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.9430e-04 - val_loss: 1.5506e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.3544e-04 - val_loss: 4.6427e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.7003e-04 - val_loss: 1.8125e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.3400e-04 - val_loss: 1.3105e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.0013e-04 - val_loss: 1.4183e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.2560e-04 - val_loss: 2.4731e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.1035e-04 - val_loss: 1.8378e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.6317e-04 - val_loss: 2.5672e-04\n",
      "9/9 [==============================] - 2s 20ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.257839066993423\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 49ms/step - loss: 0.0074 - val_loss: 6.6664e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 7.0541e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0013 - val_loss: 3.6538e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0015 - val_loss: 1.5734e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0011 - val_loss: 1.4857e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 9.1612e-04 - val_loss: 2.3677e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.7424e-04 - val_loss: 1.3023e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.7152e-04 - val_loss: 5.1199e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.5833e-04 - val_loss: 1.3190e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.1201e-04 - val_loss: 1.7873e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0012 - val_loss: 1.4570e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.9866e-04 - val_loss: 5.7576e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.4156e-04 - val_loss: 1.7717e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.5732e-04 - val_loss: 2.0617e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.7368e-04 - val_loss: 1.4868e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0012 - val_loss: 1.4005e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.5421e-04 - val_loss: 1.3359e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.2377e-04 - val_loss: 2.0251e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.3804e-04 - val_loss: 2.4656e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0010 - val_loss: 4.0576e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0011 - val_loss: 4.5572e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0012 - val_loss: 6.6439e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.8409e-04 - val_loss: 1.2389e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.1207e-04 - val_loss: 1.3376e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.1521e-04 - val_loss: 2.0781e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.5594e-04 - val_loss: 1.4921e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.0092e-04 - val_loss: 1.8547e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0010 - val_loss: 1.4378e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.4481e-04 - val_loss: 1.4561e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.6667e-04 - val_loss: 1.2684e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.8980e-04 - val_loss: 3.7143e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.9531e-04 - val_loss: 1.2900e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.9599e-04 - val_loss: 1.5866e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.3875e-04 - val_loss: 1.2692e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.9217e-04 - val_loss: 1.4318e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.7927e-04 - val_loss: 4.8431e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.2943e-04 - val_loss: 1.3459e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.0411e-04 - val_loss: 3.1499e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.0766e-04 - val_loss: 1.4054e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.8640e-04 - val_loss: 2.3850e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.1079e-04 - val_loss: 2.4013e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.7126e-04 - val_loss: 5.5557e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.6645e-04 - val_loss: 1.4057e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.473630425353553\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 18s 62ms/step - loss: 0.0065 - val_loss: 5.5085e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 6s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0013 - val_loss: 6.4505e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0014 - val_loss: 9.3063e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0012 - val_loss: 1.7562e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.7025e-04 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 9.8593e-04 - val_loss: 1.6175e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 9.9682e-04 - val_loss: 9.9514e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0012 - val_loss: 1.9364e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 9.6761e-04 - val_loss: 2.5269e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.9305e-04 - val_loss: 0.0020\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0011 - val_loss: 7.1860e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0010 - val_loss: 1.3644e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 9.1762e-04 - val_loss: 1.3192e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 9.9265e-04 - val_loss: 2.5261e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.7688e-04 - val_loss: 7.2307e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.9526e-04 - val_loss: 2.7531e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.4364e-04 - val_loss: 2.5963e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 8.3008e-04 - val_loss: 1.3431e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 0.0010 - val_loss: 1.8567e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 8.0373e-04 - val_loss: 5.8461e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 8.2782e-04 - val_loss: 3.4948e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 7.5672e-04 - val_loss: 2.9957e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0010 - val_loss: 1.8076e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0011 - val_loss: 2.4797e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0010 - val_loss: 1.8889e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 7.5197e-04 - val_loss: 5.3939e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.8228e-04 - val_loss: 3.2542e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.6151e-04 - val_loss: 8.2361e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.9065e-04 - val_loss: 2.0308e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.4476e-04 - val_loss: 1.2661e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 8.6916e-04 - val_loss: 3.6847e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 9.3339e-04 - val_loss: 1.3354e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.6365e-04 - val_loss: 8.0202e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 7.8861e-04 - val_loss: 1.3873e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 8.6283e-04 - val_loss: 7.7723e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.9585e-04 - val_loss: 2.2422e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 9.1694e-04 - val_loss: 1.3902e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 7.4719e-04 - val_loss: 2.0013e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.0861e-04 - val_loss: 1.5531e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 9.6845e-04 - val_loss: 1.3561e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.7844e-04 - val_loss: 1.6435e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.4699e-04 - val_loss: 1.3148e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 8.9803e-04 - val_loss: 1.5068e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 8.2862e-04 - val_loss: 2.8935e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 9.6232e-04 - val_loss: 2.9571e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 7.7257e-04 - val_loss: 1.3807e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 8.5967e-04 - val_loss: 3.8692e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.0406e-04 - val_loss: 1.9018e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.3328e-04 - val_loss: 1.2532e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 9.0516e-04 - val_loss: 1.5057e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.7684e-04 - val_loss: 2.1866e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 8.5931e-04 - val_loss: 3.5353e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.1347e-04 - val_loss: 2.4331e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.9403e-04 - val_loss: 1.8027e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 8.1465e-04 - val_loss: 4.3957e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.1099e-04 - val_loss: 1.6563e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.7268e-04 - val_loss: 4.8668e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.6304e-04 - val_loss: 1.6717e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.8709e-04 - val_loss: 1.4037e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.3594e-04 - val_loss: 3.9525e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.0938e-04 - val_loss: 2.3703e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 7.7635e-04 - val_loss: 1.4294e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.3059e-04 - val_loss: 1.3712e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 7.7216e-04 - val_loss: 1.3994e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 7.8591e-04 - val_loss: 3.1720e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 8.3484e-04 - val_loss: 4.8850e-04\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 7.3929e-04 - val_loss: 1.6994e-04\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 7.0059e-04 - val_loss: 1.7652e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.3909e-04 - val_loss: 1.3841e-04\n",
      "9/9 [==============================] - 3s 36ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.504032678290311\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 12s 37ms/step - loss: 0.0068 - val_loss: 5.6881e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 6.7681e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 23ms/step - loss: 0.0015 - val_loss: 2.0113e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 0.0011 - val_loss: 4.3857e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 0.0011 - val_loss: 1.4587e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 0.0012 - val_loss: 1.9913e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 8.6435e-04 - val_loss: 8.5784e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 8.9595e-04 - val_loss: 1.2900e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 0.0012 - val_loss: 1.2405e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.3396e-04 - val_loss: 1.8512e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.9718e-04 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 9.1390e-04 - val_loss: 1.7889e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.9065e-04 - val_loss: 1.8066e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.1805e-04 - val_loss: 2.4072e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 9.2680e-04 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 8.1365e-04 - val_loss: 1.2110e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 8.3961e-04 - val_loss: 1.8387e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 9.2990e-04 - val_loss: 3.4495e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.4599e-04 - val_loss: 1.2570e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 9.1783e-04 - val_loss: 2.7030e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.9286e-04 - val_loss: 1.2127e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.0148e-04 - val_loss: 1.7964e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.5805e-04 - val_loss: 1.2294e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.0761e-04 - val_loss: 1.5712e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 9.1290e-04 - val_loss: 1.2620e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.6296e-04 - val_loss: 2.0947e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.8760e-04 - val_loss: 3.7019e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 8.7834e-04 - val_loss: 1.1953e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.6554e-04 - val_loss: 3.8850e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.5436e-04 - val_loss: 1.8737e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.5167e-04 - val_loss: 2.6474e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.8288e-04 - val_loss: 1.4523e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.1598e-04 - val_loss: 1.3035e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.4017e-04 - val_loss: 2.1172e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.3394e-04 - val_loss: 1.2445e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.6276e-04 - val_loss: 4.9248e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.9967e-04 - val_loss: 1.2971e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.2966e-04 - val_loss: 1.4210e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 8.6194e-04 - val_loss: 3.4206e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.3844e-04 - val_loss: 5.7678e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.5308e-04 - val_loss: 1.6559e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 6.9431e-04 - val_loss: 1.3090e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.0774e-04 - val_loss: 7.1160e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.5560e-04 - val_loss: 1.8883e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 8.6387e-04 - val_loss: 3.9985e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.9108e-04 - val_loss: 1.8149e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 3s 22ms/step - loss: 7.7931e-04 - val_loss: 1.2544e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 3s 21ms/step - loss: 7.6626e-04 - val_loss: 6.4051e-04\n",
      "9/9 [==============================] - 2s 12ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.545812360901388\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 47ms/step - loss: 0.0074 - val_loss: 3.9331e-04\n",
      "Epoch 2/100\n",
      "  5/134 [>.............................] - ETA: 3s - loss: 0.0022   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0020 - val_loss: 8.5620e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0013 - val_loss: 1.6086e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0011 - val_loss: 1.8483e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.8118e-04 - val_loss: 4.7755e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.7715e-04 - val_loss: 2.6440e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.9294e-04 - val_loss: 2.9380e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 9.0578e-04 - val_loss: 7.5084e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 8.5625e-04 - val_loss: 2.1881e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 9.0396e-04 - val_loss: 5.7472e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 9.0302e-04 - val_loss: 8.9375e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 9.9322e-04 - val_loss: 7.4638e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 9.1760e-04 - val_loss: 5.3653e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0010 - val_loss: 4.5941e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.5120e-04 - val_loss: 1.7784e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.5160e-04 - val_loss: 2.8232e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 9.8349e-04 - val_loss: 3.4979e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.7346e-04 - val_loss: 1.3353e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.5354e-04 - val_loss: 0.0031\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.4883e-04 - val_loss: 2.9567e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 9.4160e-04 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.6409e-04 - val_loss: 1.2397e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 9.6813e-04 - val_loss: 7.2692e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0011 - val_loss: 5.2106e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.6314e-04 - val_loss: 2.4542e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 9.4947e-04 - val_loss: 1.3259e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.1253e-04 - val_loss: 1.4115e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.4417e-04 - val_loss: 8.7840e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.1062e-04 - val_loss: 1.4976e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.0946e-04 - val_loss: 1.2802e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.8270e-04 - val_loss: 8.2624e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.2166e-04 - val_loss: 2.0889e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.0432e-04 - val_loss: 1.5856e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.5510e-04 - val_loss: 1.2403e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.7318e-04 - val_loss: 1.4101e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.9622e-04 - val_loss: 1.2740e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 8.1278e-04 - val_loss: 1.3190e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.1151e-04 - val_loss: 1.7551e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 7.9850e-04 - val_loss: 1.8985e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 8.0987e-04 - val_loss: 3.8754e-04\n",
      "9/9 [==============================] - 2s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 7.080257471283834\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 13s 44ms/step - loss: 0.0069 - val_loss: 2.1825e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0013 - val_loss: 3.1736e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0011 - val_loss: 5.4959e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.9466e-04 - val_loss: 2.2747e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.7391e-04 - val_loss: 0.0017\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.3548e-04 - val_loss: 5.3634e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.4388e-04 - val_loss: 5.4799e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0010 - val_loss: 3.3572e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.3613e-04 - val_loss: 1.8732e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 1.7590e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0011 - val_loss: 1.3161e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.6094e-04 - val_loss: 3.9979e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0010 - val_loss: 1.2472e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 8.8844e-04 - val_loss: 1.7778e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.2343e-04 - val_loss: 5.1433e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.9264e-04 - val_loss: 1.2839e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.8557e-04 - val_loss: 1.2519e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.3791e-04 - val_loss: 2.8155e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.8888e-04 - val_loss: 1.2951e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.1965e-04 - val_loss: 1.4395e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.2853e-04 - val_loss: 1.2436e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.7094e-04 - val_loss: 8.2326e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.6130e-04 - val_loss: 3.4127e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.4445e-04 - val_loss: 2.2808e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.8332e-04 - val_loss: 1.8272e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.8330e-04 - val_loss: 1.2380e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 7.3942e-04 - val_loss: 1.6894e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.8539e-04 - val_loss: 3.3556e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.5390e-04 - val_loss: 4.4469e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.5167e-04 - val_loss: 2.4570e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.8413e-04 - val_loss: 1.5041e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 8.9894e-04 - val_loss: 4.6060e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.1188e-04 - val_loss: 1.5887e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.3430e-04 - val_loss: 1.2568e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.5510e-04 - val_loss: 6.4574e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.9743e-04 - val_loss: 6.6416e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.5217e-04 - val_loss: 1.2704e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.6226e-04 - val_loss: 4.3253e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.1876e-04 - val_loss: 2.6043e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.5995e-04 - val_loss: 2.1066e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.1895e-04 - val_loss: 1.2484e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2890e-04 - val_loss: 1.2836e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.2941e-04 - val_loss: 4.0587e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2461e-04 - val_loss: 3.9310e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2353e-04 - val_loss: 3.1016e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.5650e-04 - val_loss: 1.2167e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.5533e-04 - val_loss: 1.2069e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.5476e-04 - val_loss: 5.2388e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.3271e-04 - val_loss: 4.7801e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 7.4408e-04 - val_loss: 1.5584e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.3052e-04 - val_loss: 1.6767e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.6790e-04 - val_loss: 6.9692e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.6368e-04 - val_loss: 1.5190e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.6975e-04 - val_loss: 1.7642e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.7681e-04 - val_loss: 1.5169e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 9.8507e-04 - val_loss: 3.3602e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.2036e-04 - val_loss: 1.6288e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.2387e-04 - val_loss: 1.3107e-04\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 7.8463e-04 - val_loss: 1.9109e-04\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 8.4741e-04 - val_loss: 1.3029e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 6.9473e-04 - val_loss: 3.5485e-04\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 8.1622e-04 - val_loss: 1.2456e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 8.0690e-04 - val_loss: 2.3147e-04\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.8577e-04 - val_loss: 2.2483e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.4804e-04 - val_loss: 2.4651e-04\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.0048e-04 - val_loss: 3.3407e-04\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 7.7942e-04 - val_loss: 3.2246e-04\n",
      "9/9 [==============================] - 2s 20ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.46664042642139\n",
      "Training model with epochs=100, batch_size=8, sequence_length=20, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 53ms/step - loss: 0.0078 - val_loss: 3.8516e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0018    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0016 - val_loss: 2.5576e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0013 - val_loss: 3.1039e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0011 - val_loss: 4.8803e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0011 - val_loss: 1.3552e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0015 - val_loss: 3.6869e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0010 - val_loss: 4.8808e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.0451e-04 - val_loss: 9.8023e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0010 - val_loss: 1.8492e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.1802e-04 - val_loss: 2.4524e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0012 - val_loss: 8.1048e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.3740e-04 - val_loss: 3.8626e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.3265e-04 - val_loss: 1.6014e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.1889e-04 - val_loss: 4.5407e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.6232e-04 - val_loss: 3.2899e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 9.6381e-04 - val_loss: 3.3862e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.6407e-04 - val_loss: 3.8499e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0010 - val_loss: 2.1999e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 8.8682e-04 - val_loss: 1.9081e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0010 - val_loss: 2.4045e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 9.1330e-04 - val_loss: 1.5055e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 7.6663e-04 - val_loss: 1.4137e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.2316e-04 - val_loss: 1.6827e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.6984e-04 - val_loss: 1.2615e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 8.1659e-04 - val_loss: 1.8738e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.6189e-04 - val_loss: 4.6566e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.7419e-04 - val_loss: 1.4998e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0011 - val_loss: 5.0346e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 9.3412e-04 - val_loss: 1.3100e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.5005e-04 - val_loss: 1.8061e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.8433e-04 - val_loss: 1.2447e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.4244e-04 - val_loss: 4.1285e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.3989e-04 - val_loss: 2.3286e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.9404e-04 - val_loss: 1.8599e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 9.6516e-04 - val_loss: 2.7407e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.5205e-04 - val_loss: 7.2197e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.7766e-04 - val_loss: 6.6514e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.4469e-04 - val_loss: 2.2507e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.9287e-04 - val_loss: 2.0017e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.0489e-04 - val_loss: 1.5060e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0011 - val_loss: 2.3857e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.3255e-04 - val_loss: 3.3733e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 7.8942e-04 - val_loss: 1.5448e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 7.5738e-04 - val_loss: 2.6967e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 8.0168e-04 - val_loss: 5.6730e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.3544e-04 - val_loss: 1.7699e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.9336e-04 - val_loss: 1.4373e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.9684e-04 - val_loss: 1.7231e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.8694e-04 - val_loss: 2.1200e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.7067e-04 - val_loss: 1.2519e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.6426e-04 - val_loss: 3.8665e-04\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 6.093506360976433\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_gru_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e12d1fd-830d-49c2-a171-a4c0ae04bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 6.4744073402672475}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 6.645016313614708}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 9.275660089588598}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 7.523011106924789}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 6.334712399295536}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 7.895659893580752}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 6.635506340097518}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 6.142855402174031}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 6.202118365560203}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 6.257839066993423}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 7.473630425353553}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 6.504032678290311}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 2, 'rmse': 6.545812360901388}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 50, 'layers': 3, 'rmse': 7.080257471283834}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 2, 'rmse': 6.46664042642139}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 20, 'units': 100, 'layers': 3, 'rmse': 6.093506360976433}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f2fbd-4960-46df-91fa-f1e7ce0b6f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
