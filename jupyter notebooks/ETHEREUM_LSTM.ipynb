{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4a897a-e386-409b-bb3a-d83bc77c3e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dfd89f-4b30-43e9-a703-e515907028a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384f2f6f-a7f6-4a2f-8ad4-43c5748fb110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d1a007-620e-4305-858d-d51de9eca530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55d3d86-4c92-4e61-b525-9a030e7a5268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    lstm_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    plt.plot(y_test, label='Actual')\n",
    "    plt.plot(lstm_predictions, label='Predicted')\n",
    "    plt.title('Actual vs Predicted Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Ethereum_Models/actual_vs_predicted_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "    plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Epoch Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Ethereum_Models/loss_curve_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e4f60a-e7d2-4da3-868e-f76f1f908e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'ETH-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679b7a1c-eff2-433e-bfdf-4bf4f5807cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a16e1bc-7395-4d88-a65d-95b822aa4820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_range = [50, 100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60,80]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809e7d35-e183-43fa-a126-85794043dfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857d5ae3-d3b4-44e1-b021-f2694308ef71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "263/263 [==============================] - 35s 67ms/step - loss: 0.0069 - val_loss: 3.6463e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 14s 53ms/step - loss: 0.0032 - val_loss: 2.8510e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0020 - val_loss: 2.3408e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0016 - val_loss: 1.9299e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.0014 - val_loss: 2.0785e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0013 - val_loss: 7.1698e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 0.0010 - val_loss: 1.3595e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 9.6669e-04 - val_loss: 1.2462e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 9.0353e-04 - val_loss: 1.1794e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 8.6542e-04 - val_loss: 6.9409e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 0.0011 - val_loss: 1.1384e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 7.5551e-04 - val_loss: 2.3116e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 8.0413e-04 - val_loss: 1.2319e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 9.6332e-04 - val_loss: 7.0913e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.0888e-04 - val_loss: 1.9770e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 16s 63ms/step - loss: 7.8158e-04 - val_loss: 1.0767e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 9.0888e-04 - val_loss: 3.8702e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.5297e-04 - val_loss: 1.2229e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.8917e-04 - val_loss: 1.2128e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.7855e-04 - val_loss: 3.5904e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.1234e-04 - val_loss: 1.0077e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.4908e-04 - val_loss: 2.8034e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.2079e-04 - val_loss: 1.9274e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.9185e-04 - val_loss: 9.1166e-05\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 6.8578e-04 - val_loss: 9.8377e-05\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 7.0610e-04 - val_loss: 3.0401e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 6.7889e-04 - val_loss: 1.1345e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 8.9886e-04 - val_loss: 1.4538e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 7.0481e-04 - val_loss: 1.5534e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 6.9721e-04 - val_loss: 9.7541e-05\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 6.0182e-04 - val_loss: 3.3535e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 7.3233e-04 - val_loss: 1.1449e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 5.9777e-04 - val_loss: 1.7863e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.7421e-04 - val_loss: 9.7674e-05\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 5.9796e-04 - val_loss: 8.7741e-05\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.3943e-04 - val_loss: 1.1219e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.0891e-04 - val_loss: 1.2713e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.5560e-04 - val_loss: 8.5137e-05\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.7111e-04 - val_loss: 1.3278e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 5.9291e-04 - val_loss: 9.0091e-05\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.9630e-04 - val_loss: 9.6200e-05\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 6.2610e-04 - val_loss: 8.5226e-05\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 5.8584e-04 - val_loss: 2.1313e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.3008e-04 - val_loss: 1.1328e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.1797e-04 - val_loss: 1.1597e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 6.5172e-04 - val_loss: 8.9245e-05\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.5101e-04 - val_loss: 1.7314e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 6.5344e-04 - val_loss: 1.1367e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.4208e-04 - val_loss: 1.2117e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4828e-04 - val_loss: 7.6147e-04\n",
      "9/9 [==============================] - 4s 20ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 127.08885006285385\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 46s 88ms/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 16s 62ms/step - loss: 0.0040 - val_loss: 7.3110e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 0.0030 - val_loss: 2.9659e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 0.0022 - val_loss: 7.7904e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 0.0018 - val_loss: 6.8288e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 0.0014 - val_loss: 4.3133e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 0.0012 - val_loss: 9.3215e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 0.0012 - val_loss: 1.5790e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 9.5666e-04 - val_loss: 1.2827e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 0.0013 - val_loss: 1.5606e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 9.2121e-04 - val_loss: 1.2808e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 7.6633e-04 - val_loss: 3.1171e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 9.1926e-04 - val_loss: 3.2598e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 7.8678e-04 - val_loss: 1.2733e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 9.0400e-04 - val_loss: 1.8095e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 8.3667e-04 - val_loss: 2.5060e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 8.4513e-04 - val_loss: 2.2085e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 8.4521e-04 - val_loss: 9.9860e-05\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 9.0433e-04 - val_loss: 1.3637e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 8.0343e-04 - val_loss: 1.0043e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 7.5302e-04 - val_loss: 5.5803e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 8.3089e-04 - val_loss: 2.2035e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 6.7172e-04 - val_loss: 1.1494e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 17s 64ms/step - loss: 8.4056e-04 - val_loss: 1.6096e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 16s 61ms/step - loss: 7.6051e-04 - val_loss: 1.3204e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 6.4561e-04 - val_loss: 9.3035e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.9095e-04 - val_loss: 1.8184e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 6.9804e-04 - val_loss: 1.2230e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 6.9685e-04 - val_loss: 3.2612e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 7.4803e-04 - val_loss: 8.7185e-05\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 17s 63ms/step - loss: 6.9155e-04 - val_loss: 2.4363e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 8.0295e-04 - val_loss: 9.3517e-05\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 6.2730e-04 - val_loss: 1.2331e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 37s 143ms/step - loss: 6.9055e-04 - val_loss: 3.2360e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 9.1209e-04 - val_loss: 1.3645e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 31s 117ms/step - loss: 6.4337e-04 - val_loss: 1.6888e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 6.8616e-04 - val_loss: 1.3073e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 21s 82ms/step - loss: 6.9497e-04 - val_loss: 2.1225e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 6.2997e-04 - val_loss: 9.8232e-05\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 7.2507e-04 - val_loss: 1.0111e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 7.0199e-04 - val_loss: 1.9728e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 21s 82ms/step - loss: 6.9547e-04 - val_loss: 1.1668e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 6.4853e-04 - val_loss: 2.1459e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 7.4489e-04 - val_loss: 1.9815e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 7.5380e-04 - val_loss: 9.9926e-05\n",
      "9/9 [==============================] - 8s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 45.149463312730155\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 72s 132ms/step - loss: 0.0049 - val_loss: 2.8037e-04\n",
      "Epoch 2/50\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 0.0022 - val_loss: 4.8560e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.0015 - val_loss: 2.3573e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.0017 - val_loss: 1.4620e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 0.0010 - val_loss: 5.0628e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.0014 - val_loss: 1.4282e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 9.4727e-04 - val_loss: 1.3462e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 9.9495e-04 - val_loss: 3.4726e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 8.8827e-04 - val_loss: 2.6976e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 23s 89ms/step - loss: 0.0010 - val_loss: 7.4715e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 6.7643e-04 - val_loss: 3.9863e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 8.1062e-04 - val_loss: 9.0839e-05\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 8.5315e-04 - val_loss: 2.4216e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 6.6347e-04 - val_loss: 1.2333e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 7.7470e-04 - val_loss: 1.8023e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 7.6048e-04 - val_loss: 8.8949e-05\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 6.3460e-04 - val_loss: 1.1507e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 8.7532e-04 - val_loss: 2.2101e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 23s 89ms/step - loss: 8.4247e-04 - val_loss: 1.3098e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 8.1423e-04 - val_loss: 1.4433e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 23s 88ms/step - loss: 7.1796e-04 - val_loss: 3.5458e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.4975e-04 - val_loss: 4.9244e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 7.3721e-04 - val_loss: 1.0416e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 7.0525e-04 - val_loss: 1.5056e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 27s 101ms/step - loss: 7.1156e-04 - val_loss: 1.1213e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 6.1098e-04 - val_loss: 1.6404e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 7.9432e-04 - val_loss: 1.0358e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.8864e-04 - val_loss: 1.2592e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 6.6101e-04 - val_loss: 1.0441e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 6.6569e-04 - val_loss: 1.6150e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 7.1921e-04 - val_loss: 8.8131e-05\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.3868e-04 - val_loss: 1.2726e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 7.2492e-04 - val_loss: 1.8612e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 6.3865e-04 - val_loss: 4.1533e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 7.7168e-04 - val_loss: 1.0228e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 6.8862e-04 - val_loss: 1.3384e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 6.5033e-04 - val_loss: 1.1148e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 6.7800e-04 - val_loss: 9.8702e-05\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 6.6237e-04 - val_loss: 2.3358e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 6.1296e-04 - val_loss: 2.7637e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 6.5491e-04 - val_loss: 9.2751e-05\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 7.0197e-04 - val_loss: 9.3467e-05\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 6.6683e-04 - val_loss: 2.1123e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 6.1638e-04 - val_loss: 9.3933e-05\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 6.1539e-04 - val_loss: 1.3827e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 6.8103e-04 - val_loss: 8.9625e-05\n",
      "9/9 [==============================] - 7s 38ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.78698928385512\n",
      "Training model with epochs=50, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 70s 113ms/step - loss: 0.0103 - val_loss: 5.5084e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 23s 87ms/step - loss: 0.0046 - val_loss: 7.8962e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.0028 - val_loss: 3.1307e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0017 - val_loss: 2.4298e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 24s 93ms/step - loss: 0.0013 - val_loss: 1.5328e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.0013 - val_loss: 1.9872e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 25s 93ms/step - loss: 0.0012 - val_loss: 1.2491e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.0010 - val_loss: 3.1914e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 24s 90ms/step - loss: 9.8594e-04 - val_loss: 1.2982e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 24s 93ms/step - loss: 7.7555e-04 - val_loss: 1.3976e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 24s 91ms/step - loss: 0.0010 - val_loss: 1.2636e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 24s 91ms/step - loss: 7.8649e-04 - val_loss: 1.4364e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 24s 90ms/step - loss: 9.1663e-04 - val_loss: 3.1433e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 7.6415e-04 - val_loss: 2.3887e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 23s 88ms/step - loss: 8.3824e-04 - val_loss: 8.9273e-05\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.5656e-04 - val_loss: 1.1526e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 9.2329e-04 - val_loss: 1.3170e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 7.7132e-04 - val_loss: 1.0174e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 8.9174e-04 - val_loss: 1.4569e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 24s 92ms/step - loss: 8.4087e-04 - val_loss: 3.2575e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 23s 89ms/step - loss: 0.0011 - val_loss: 2.5170e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 24s 91ms/step - loss: 7.2178e-04 - val_loss: 2.8332e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 24s 91ms/step - loss: 8.3148e-04 - val_loss: 3.1767e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 6.8048e-04 - val_loss: 1.4071e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 7.5709e-04 - val_loss: 9.0658e-05\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 9.8784e-04 - val_loss: 1.2183e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 18s 67ms/step - loss: 7.0533e-04 - val_loss: 9.7777e-05\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 16s 62ms/step - loss: 7.8724e-04 - val_loss: 1.1964e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 7.3015e-04 - val_loss: 2.4076e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 24s 93ms/step - loss: 7.0104e-04 - val_loss: 2.1465e-04\n",
      "9/9 [==============================] - 7s 45ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 46.17269548700949\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 65s 148ms/step - loss: 0.0076 - val_loss: 4.3629e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 31s 117ms/step - loss: 0.0032 - val_loss: 4.9817e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 0.0017 - val_loss: 5.3654e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 0.0014 - val_loss: 2.5187e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 0.0012 - val_loss: 1.9913e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 27s 101ms/step - loss: 0.0011 - val_loss: 2.2748e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 9.6588e-04 - val_loss: 1.8695e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 8.6128e-04 - val_loss: 1.3388e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 8.7644e-04 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 7.7546e-04 - val_loss: 2.1051e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 26s 101ms/step - loss: 7.7225e-04 - val_loss: 2.0931e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 26s 99ms/step - loss: 7.2659e-04 - val_loss: 1.8890e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 7.5189e-04 - val_loss: 1.2690e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 8.6596e-04 - val_loss: 1.4315e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 6.9626e-04 - val_loss: 1.4114e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 8.5842e-04 - val_loss: 3.8737e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 8.9243e-04 - val_loss: 2.2384e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 7.9082e-04 - val_loss: 1.7782e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 7.9783e-04 - val_loss: 1.2673e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 7.9745e-04 - val_loss: 7.9266e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 6.9297e-04 - val_loss: 1.4403e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 8.3873e-04 - val_loss: 3.0520e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 30s 116ms/step - loss: 7.1916e-04 - val_loss: 5.6763e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 7.5318e-04 - val_loss: 4.9148e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.6061e-04 - val_loss: 2.7944e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 31s 116ms/step - loss: 6.4449e-04 - val_loss: 1.1586e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.7206e-04 - val_loss: 1.9243e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 7.2521e-04 - val_loss: 1.7350e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 8.5228e-04 - val_loss: 1.2041e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 7.2321e-04 - val_loss: 6.1647e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 6.7267e-04 - val_loss: 1.6336e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 7.3473e-04 - val_loss: 1.6248e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 31s 116ms/step - loss: 6.5695e-04 - val_loss: 1.1879e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 5.9813e-04 - val_loss: 1.6058e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 6.6744e-04 - val_loss: 1.3790e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 6.6231e-04 - val_loss: 1.2206e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.5741e-04 - val_loss: 1.7650e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.1743e-04 - val_loss: 1.5196e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 6.3322e-04 - val_loss: 1.0876e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 31s 117ms/step - loss: 6.1248e-04 - val_loss: 1.3198e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 7.1459e-04 - val_loss: 1.7198e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 5.9993e-04 - val_loss: 1.2213e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.0086e-04 - val_loss: 1.6844e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.5746e-04 - val_loss: 2.8106e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 7.3171e-04 - val_loss: 1.2473e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 31s 116ms/step - loss: 6.4509e-04 - val_loss: 1.0878e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 6.1893e-04 - val_loss: 6.1460e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.1226e-04 - val_loss: 1.1609e-04\n",
      "8/8 [==============================] - 5s 55ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.61902077438216\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 83s 189ms/step - loss: 0.0078 - val_loss: 6.1292e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 41s 155ms/step - loss: 0.0032 - val_loss: 5.0534e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.0014 - val_loss: 6.2046e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 0.0014 - val_loss: 9.6763e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 0.0011 - val_loss: 3.1467e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 0.0012 - val_loss: 2.8844e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 8.4517e-04 - val_loss: 2.8994e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 0.0015 - val_loss: 4.2671e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 8.4469e-04 - val_loss: 3.2070e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.5832e-04 - val_loss: 5.2013e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 8.4182e-04 - val_loss: 1.2261e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.8246e-04 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 7.2697e-04 - val_loss: 1.2982e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 0.0011 - val_loss: 1.1941e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 7.6673e-04 - val_loss: 2.9320e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 8.9088e-04 - val_loss: 2.3195e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 7.2960e-04 - val_loss: 1.3222e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 7.7538e-04 - val_loss: 3.2177e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 9.5121e-04 - val_loss: 1.1680e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 8.6287e-04 - val_loss: 1.1621e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.0817e-04 - val_loss: 1.2942e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 7.1469e-04 - val_loss: 2.7877e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 35s 135ms/step - loss: 7.5043e-04 - val_loss: 2.5146e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 7.3431e-04 - val_loss: 2.6222e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 6.6809e-04 - val_loss: 1.0634e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.5197e-04 - val_loss: 2.1979e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 7.1468e-04 - val_loss: 1.1177e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 5.8250e-04 - val_loss: 2.8552e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 8.3253e-04 - val_loss: 2.2054e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 7.1089e-04 - val_loss: 1.1825e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 7.1830e-04 - val_loss: 1.3660e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 8.0211e-04 - val_loss: 2.3613e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.5450e-04 - val_loss: 1.0901e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 6.6741e-04 - val_loss: 2.0320e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 6.2302e-04 - val_loss: 1.1653e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 6.4673e-04 - val_loss: 1.0883e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.6904e-04 - val_loss: 1.1883e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 6.3882e-04 - val_loss: 1.4699e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 6.6695e-04 - val_loss: 1.4739e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 6.8502e-04 - val_loss: 1.2043e-04\n",
      "8/8 [==============================] - 6s 56ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 42.83370651158674\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 60s 156ms/step - loss: 0.0075 - val_loss: 0.0011\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 36s 137ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0016 - val_loss: 2.5064e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 0.0018 - val_loss: 3.4011e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 0.0014 - val_loss: 1.7557e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 0.0011 - val_loss: 3.9377e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 0.0010 - val_loss: 1.7257e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 8.4839e-04 - val_loss: 1.5061e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 8.9321e-04 - val_loss: 1.5265e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 41s 155ms/step - loss: 7.7408e-04 - val_loss: 3.9367e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 41s 158ms/step - loss: 8.5482e-04 - val_loss: 2.1513e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 8.6528e-04 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0010 - val_loss: 1.6003e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.8324e-04 - val_loss: 1.1682e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 9.1762e-04 - val_loss: 3.5855e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.4655e-04 - val_loss: 1.3020e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.6491e-04 - val_loss: 1.6935e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.8486e-04 - val_loss: 1.1150e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.9303e-04 - val_loss: 2.2267e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 7.4987e-04 - val_loss: 1.3203e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 8.2930e-04 - val_loss: 1.4380e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 7.1702e-04 - val_loss: 3.2616e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 8.0600e-04 - val_loss: 1.1536e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 7.4053e-04 - val_loss: 3.3103e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 7.1299e-04 - val_loss: 1.6349e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 6.4320e-04 - val_loss: 1.1172e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 6.7614e-04 - val_loss: 1.7434e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.0734e-04 - val_loss: 5.1361e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.2246e-04 - val_loss: 2.2130e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 7.6065e-04 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 8.2649e-04 - val_loss: 3.0274e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 6.5450e-04 - val_loss: 1.4524e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.7472e-04 - val_loss: 1.2239e-04\n",
      "8/8 [==============================] - 4s 67ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.922054015168726\n",
      "Training model with epochs=50, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 60s 158ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 37s 140ms/step - loss: 0.0037 - val_loss: 7.6950e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 0.0028 - val_loss: 3.2961e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 0.0022 - val_loss: 4.5515e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0014 - val_loss: 2.6364e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 40s 151ms/step - loss: 0.0014 - val_loss: 2.3526e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 0.0011 - val_loss: 1.6143e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 9.0884e-04 - val_loss: 1.5190e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 8.3854e-04 - val_loss: 2.0374e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.9808e-04 - val_loss: 5.6022e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 8.9282e-04 - val_loss: 1.3063e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 9.3972e-04 - val_loss: 4.3848e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 8.6827e-04 - val_loss: 1.1451e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 7.5779e-04 - val_loss: 4.1851e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 9.8824e-04 - val_loss: 1.7043e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 0.0011 - val_loss: 1.2906e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 0.0010 - val_loss: 1.0720e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 7.9705e-04 - val_loss: 2.4099e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 7.4133e-04 - val_loss: 4.2881e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 9.2901e-04 - val_loss: 1.1156e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 8.2761e-04 - val_loss: 5.2766e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.2813e-04 - val_loss: 1.0950e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 7.7586e-04 - val_loss: 1.3564e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.4263e-04 - val_loss: 1.1515e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.1492e-04 - val_loss: 2.2634e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 7.0955e-04 - val_loss: 2.5702e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 9.6558e-04 - val_loss: 1.2145e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 37s 143ms/step - loss: 7.2791e-04 - val_loss: 1.3047e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 7.4303e-04 - val_loss: 1.1132e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 7.9722e-04 - val_loss: 1.5623e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 7.1628e-04 - val_loss: 8.2793e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.0612e-04 - val_loss: 3.4353e-04\n",
      "8/8 [==============================] - 7s 95ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 42.36064631238659\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 63s 150ms/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 34s 129ms/step - loss: 0.0026 - val_loss: 4.8400e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 0.0022 - val_loss: 5.2371e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 0.0016 - val_loss: 6.4495e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 0.0013 - val_loss: 4.6128e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 0.0011 - val_loss: 1.5839e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 35s 135ms/step - loss: 0.0011 - val_loss: 2.6185e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 9.4901e-04 - val_loss: 1.3522e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 9.9976e-04 - val_loss: 8.4185e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 8.2583e-04 - val_loss: 1.1738e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 8.0368e-04 - val_loss: 1.2643e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 34s 127ms/step - loss: 7.0528e-04 - val_loss: 4.2541e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 7.6174e-04 - val_loss: 1.2642e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 9.9351e-04 - val_loss: 1.5522e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 8.0749e-04 - val_loss: 1.1462e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 7.7485e-04 - val_loss: 1.6726e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.6365e-04 - val_loss: 1.5949e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 35s 135ms/step - loss: 7.5256e-04 - val_loss: 5.6884e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 7.8786e-04 - val_loss: 2.6723e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 8.4604e-04 - val_loss: 1.0500e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.9509e-04 - val_loss: 1.8328e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 8.0425e-04 - val_loss: 1.1660e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 6.7761e-04 - val_loss: 1.2536e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 7.9396e-04 - val_loss: 2.8185e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 6.7786e-04 - val_loss: 1.1547e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 6.3105e-04 - val_loss: 1.5594e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.9326e-04 - val_loss: 1.6393e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 5.9613e-04 - val_loss: 1.0929e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 7.0509e-04 - val_loss: 1.4060e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 36s 137ms/step - loss: 6.4884e-04 - val_loss: 1.8942e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 7.1344e-04 - val_loss: 3.2021e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 6.8169e-04 - val_loss: 1.4486e-04\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 7.5582e-04 - val_loss: 1.7958e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 34s 130ms/step - loss: 7.5199e-04 - val_loss: 1.1168e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 35s 132ms/step - loss: 7.4527e-04 - val_loss: 4.1002e-04\n",
      "7/7 [==============================] - 8s 74ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.41727548299754\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 102s 213ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 45s 172ms/step - loss: 0.0043 - val_loss: 7.2527e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 40s 154ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 0.0020 - val_loss: 2.8720e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 41s 158ms/step - loss: 0.0020 - val_loss: 2.6715e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 0.0016 - val_loss: 2.5081e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 0.0014 - val_loss: 2.4325e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 0.0010 - val_loss: 2.0174e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 9.4243e-04 - val_loss: 1.5939e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 7.9373e-04 - val_loss: 6.4761e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 0.0010 - val_loss: 1.3371e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 9.6371e-04 - val_loss: 1.3029e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 9.2806e-04 - val_loss: 3.8367e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 9.1592e-04 - val_loss: 1.1733e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0011 - val_loss: 2.8169e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 8.3331e-04 - val_loss: 1.4127e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 49s 188ms/step - loss: 7.6977e-04 - val_loss: 1.1699e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 9.0141e-04 - val_loss: 6.9559e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 7.4053e-04 - val_loss: 1.0151e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.8918e-04 - val_loss: 1.3902e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 9.1443e-04 - val_loss: 2.3065e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 7.9244e-04 - val_loss: 1.0803e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 51s 194ms/step - loss: 7.2722e-04 - val_loss: 4.5232e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 57s 215ms/step - loss: 8.3667e-04 - val_loss: 9.0439e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 7.3636e-04 - val_loss: 1.2542e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 7.7177e-04 - val_loss: 9.3106e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 7.3219e-04 - val_loss: 3.0770e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 6.6607e-04 - val_loss: 2.6140e-04\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 7.6266e-04 - val_loss: 1.6167e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 7.0900e-04 - val_loss: 1.6332e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 7.5647e-04 - val_loss: 1.0801e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 50s 189ms/step - loss: 6.4009e-04 - val_loss: 9.8872e-05\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 7.0412e-04 - val_loss: 1.0158e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 7.1645e-04 - val_loss: 2.5486e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 46s 176ms/step - loss: 6.7302e-04 - val_loss: 1.2560e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 6.3443e-04 - val_loss: 1.5968e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 8.5222e-04 - val_loss: 1.1744e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 6.6132e-04 - val_loss: 1.3142e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.2708e-04 - val_loss: 9.8559e-05\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 5.9483e-04 - val_loss: 1.2843e-04\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 7.1223e-04 - val_loss: 1.4066e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 7.4351e-04 - val_loss: 1.1085e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 51s 195ms/step - loss: 6.5848e-04 - val_loss: 1.2026e-04\n",
      "Epoch 44/50\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.6047e-04 - val_loss: 1.1183e-04\n",
      "Epoch 45/50\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 7.2475e-04 - val_loss: 1.8980e-04\n",
      "Epoch 46/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 6.6332e-04 - val_loss: 1.1678e-04\n",
      "Epoch 47/50\n",
      "263/263 [==============================] - 43s 164ms/step - loss: 6.2389e-04 - val_loss: 1.7694e-04\n",
      "Epoch 48/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 5.8207e-04 - val_loss: 2.4591e-04\n",
      "Epoch 49/50\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 6.6447e-04 - val_loss: 2.3509e-04\n",
      "Epoch 50/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 7.4950e-04 - val_loss: 3.7449e-04\n",
      "7/7 [==============================] - 6s 72ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 89.57664520503046\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - 67s 184ms/step - loss: 0.0053 - val_loss: 3.2920e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 41s 155ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 0.0015 - val_loss: 6.7739e-04\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 47s 179ms/step - loss: 0.0012 - val_loss: 1.9168e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 0.0010 - val_loss: 3.3466e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 43s 161ms/step - loss: 0.0012 - val_loss: 1.6662e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 7.4762e-04 - val_loss: 1.0690e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 41s 158ms/step - loss: 9.1548e-04 - val_loss: 4.8572e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 9.0714e-04 - val_loss: 3.2406e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 8.0789e-04 - val_loss: 4.4418e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 40s 150ms/step - loss: 8.1341e-04 - val_loss: 1.1920e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 42s 159ms/step - loss: 9.4769e-04 - val_loss: 1.6487e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 41s 158ms/step - loss: 8.3652e-04 - val_loss: 9.9295e-05\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 6.5237e-04 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 45s 173ms/step - loss: 8.6913e-04 - val_loss: 3.4646e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 7.3897e-04 - val_loss: 1.0124e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 50s 188ms/step - loss: 9.0460e-04 - val_loss: 1.0027e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 45s 173ms/step - loss: 7.0651e-04 - val_loss: 1.1442e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 7.6297e-04 - val_loss: 1.6813e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 7.1933e-04 - val_loss: 1.3021e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 7.0454e-04 - val_loss: 1.5138e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 7.5137e-04 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 8.7864e-04 - val_loss: 1.2088e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 6.4998e-04 - val_loss: 2.9881e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 6.6115e-04 - val_loss: 1.9517e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 51s 195ms/step - loss: 6.9166e-04 - val_loss: 4.8254e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 6.7142e-04 - val_loss: 1.1388e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 6.3768e-04 - val_loss: 1.1066e-04\n",
      "7/7 [==============================] - 6s 127ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.189416870304264\n",
      "Training model with epochs=50, batch_size=4, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/50\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.0096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 92s 229ms/step - loss: 0.0096 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.0040 - val_loss: 4.4124e-04\n",
      "Epoch 3/50\n",
      "263/263 [==============================] - 71s 270ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.0019 - val_loss: 2.3254e-04\n",
      "Epoch 5/50\n",
      "263/263 [==============================] - 72s 272ms/step - loss: 0.0015 - val_loss: 2.4543e-04\n",
      "Epoch 6/50\n",
      "263/263 [==============================] - 76s 289ms/step - loss: 0.0012 - val_loss: 2.2495e-04\n",
      "Epoch 7/50\n",
      "263/263 [==============================] - 71s 269ms/step - loss: 0.0010 - val_loss: 2.6511e-04\n",
      "Epoch 8/50\n",
      "263/263 [==============================] - 71s 271ms/step - loss: 0.0011 - val_loss: 1.4644e-04\n",
      "Epoch 9/50\n",
      "263/263 [==============================] - 57s 215ms/step - loss: 9.0293e-04 - val_loss: 1.2040e-04\n",
      "Epoch 10/50\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 9.5224e-04 - val_loss: 1.5762e-04\n",
      "Epoch 11/50\n",
      "263/263 [==============================] - 63s 241ms/step - loss: 8.9924e-04 - val_loss: 3.6786e-04\n",
      "Epoch 12/50\n",
      "263/263 [==============================] - 60s 227ms/step - loss: 8.8124e-04 - val_loss: 5.1417e-04\n",
      "Epoch 13/50\n",
      "263/263 [==============================] - 61s 232ms/step - loss: 9.9948e-04 - val_loss: 1.5486e-04\n",
      "Epoch 14/50\n",
      "263/263 [==============================] - 63s 239ms/step - loss: 8.9099e-04 - val_loss: 3.4718e-04\n",
      "Epoch 15/50\n",
      "263/263 [==============================] - 61s 231ms/step - loss: 8.1766e-04 - val_loss: 1.0024e-04\n",
      "Epoch 16/50\n",
      "263/263 [==============================] - 58s 221ms/step - loss: 9.6812e-04 - val_loss: 1.8014e-04\n",
      "Epoch 17/50\n",
      "263/263 [==============================] - 62s 235ms/step - loss: 6.7086e-04 - val_loss: 1.6709e-04\n",
      "Epoch 18/50\n",
      "263/263 [==============================] - 59s 226ms/step - loss: 9.8138e-04 - val_loss: 1.2890e-04\n",
      "Epoch 19/50\n",
      "263/263 [==============================] - 59s 226ms/step - loss: 7.3333e-04 - val_loss: 2.2505e-04\n",
      "Epoch 20/50\n",
      "263/263 [==============================] - 44s 167ms/step - loss: 8.2911e-04 - val_loss: 1.2762e-04\n",
      "Epoch 21/50\n",
      "263/263 [==============================] - 62s 236ms/step - loss: 7.1821e-04 - val_loss: 1.2704e-04\n",
      "Epoch 22/50\n",
      "263/263 [==============================] - 59s 226ms/step - loss: 8.2348e-04 - val_loss: 1.9870e-04\n",
      "Epoch 23/50\n",
      "263/263 [==============================] - 50s 188ms/step - loss: 9.1607e-04 - val_loss: 1.0597e-04\n",
      "Epoch 24/50\n",
      "263/263 [==============================] - 54s 204ms/step - loss: 7.8108e-04 - val_loss: 2.3913e-04\n",
      "Epoch 25/50\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 7.1367e-04 - val_loss: 1.1564e-04\n",
      "Epoch 26/50\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 7.3135e-04 - val_loss: 1.0751e-04\n",
      "Epoch 27/50\n",
      "263/263 [==============================] - 55s 209ms/step - loss: 6.8194e-04 - val_loss: 1.1238e-04\n",
      "Epoch 28/50\n",
      "263/263 [==============================] - 54s 207ms/step - loss: 6.9754e-04 - val_loss: 9.6908e-05\n",
      "Epoch 29/50\n",
      "263/263 [==============================] - 56s 212ms/step - loss: 7.8553e-04 - val_loss: 3.7417e-04\n",
      "Epoch 30/50\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 7.1663e-04 - val_loss: 1.4262e-04\n",
      "Epoch 31/50\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 6.7884e-04 - val_loss: 1.5513e-04\n",
      "Epoch 32/50\n",
      "263/263 [==============================] - 54s 206ms/step - loss: 7.3719e-04 - val_loss: 9.8065e-05\n",
      "Epoch 33/50\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 8.5311e-04 - val_loss: 8.1162e-04\n",
      "Epoch 34/50\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 6.8803e-04 - val_loss: 1.5530e-04\n",
      "Epoch 35/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.4915e-04 - val_loss: 1.0702e-04\n",
      "Epoch 36/50\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 7.4115e-04 - val_loss: 2.4996e-04\n",
      "Epoch 37/50\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 7.2916e-04 - val_loss: 3.4989e-04\n",
      "Epoch 38/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 6.2283e-04 - val_loss: 1.0929e-04\n",
      "Epoch 39/50\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 8.1785e-04 - val_loss: 1.3035e-04\n",
      "Epoch 40/50\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 6.6629e-04 - val_loss: 9.8032e-05\n",
      "Epoch 41/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.7092e-04 - val_loss: 1.0370e-04\n",
      "Epoch 42/50\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 7.1318e-04 - val_loss: 1.5337e-04\n",
      "Epoch 43/50\n",
      "263/263 [==============================] - 44s 165ms/step - loss: 8.4327e-04 - val_loss: 1.0072e-04\n",
      "7/7 [==============================] - 5s 103ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.92782993688304\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 22s 62ms/step - loss: 0.0089 - val_loss: 4.9143e-04\n",
      "Epoch 2/50\n",
      "  1/132 [..............................] - ETA: 4s - loss: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 5s 38ms/step - loss: 0.0032 - val_loss: 7.4584e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 0.0030 - val_loss: 5.8214e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 0.0019 - val_loss: 4.9494e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0015 - val_loss: 2.1476e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0016 - val_loss: 1.9715e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 0.0013 - val_loss: 3.5420e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 0.0013 - val_loss: 1.7062e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 0.0011 - val_loss: 2.1815e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 9.2612e-04 - val_loss: 2.9561e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 8.3955e-04 - val_loss: 1.4555e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.6664e-04 - val_loss: 3.4329e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 7.3134e-04 - val_loss: 4.0338e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 7.1739e-04 - val_loss: 1.4952e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 6.5208e-04 - val_loss: 1.4518e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 6.7444e-04 - val_loss: 1.1832e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 7.6636e-04 - val_loss: 1.6773e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 7.3365e-04 - val_loss: 2.8412e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 7.6131e-04 - val_loss: 4.9152e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 7.1003e-04 - val_loss: 1.1440e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 6.5401e-04 - val_loss: 1.8135e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 7.2440e-04 - val_loss: 4.7139e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.6663e-04 - val_loss: 1.0500e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 6.8848e-04 - val_loss: 1.6966e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 6.9596e-04 - val_loss: 2.8514e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 6.9928e-04 - val_loss: 1.0063e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 6.8048e-04 - val_loss: 1.9169e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.7270e-04 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 6.4546e-04 - val_loss: 1.1509e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.5544e-04 - val_loss: 1.8433e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 6.4430e-04 - val_loss: 1.4165e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 7.8697e-04 - val_loss: 9.2296e-05\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 7.8099e-04 - val_loss: 1.0027e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 5.6885e-04 - val_loss: 1.5469e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 6.2667e-04 - val_loss: 1.0957e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 5.8170e-04 - val_loss: 1.6437e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 5.6543e-04 - val_loss: 2.6805e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 6.3898e-04 - val_loss: 3.6300e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 6.9062e-04 - val_loss: 1.8069e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2011e-04 - val_loss: 1.0447e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 5.6847e-04 - val_loss: 9.2363e-05\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.0437e-04 - val_loss: 2.9549e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 6.6785e-04 - val_loss: 3.9498e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.0777e-04 - val_loss: 1.2567e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.9034e-04 - val_loss: 1.1281e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.9260e-04 - val_loss: 9.7377e-05\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 6.6155e-04 - val_loss: 1.0168e-04\n",
      "9/9 [==============================] - 5s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.46898365092455\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 46s 84ms/step - loss: 0.0091 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "  1/132 [..............................] - ETA: 6s - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 6s 48ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 0.0032 - val_loss: 5.4542e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 6s 45ms/step - loss: 0.0028 - val_loss: 8.0059e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 0.0020 - val_loss: 3.0985e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 0.0018 - val_loss: 7.3791e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0015 - val_loss: 4.8583e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0015 - val_loss: 1.9673e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 0.0015 - val_loss: 1.9458e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 7s 57ms/step - loss: 0.0010 - val_loss: 3.1569e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0010 - val_loss: 4.5380e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0013 - val_loss: 5.7486e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 8.5619e-04 - val_loss: 1.4265e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 8.3222e-04 - val_loss: 1.2834e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 8s 59ms/step - loss: 7.9257e-04 - val_loss: 3.7144e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 8.0780e-04 - val_loss: 1.2257e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 8.6308e-04 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 8.1064e-04 - val_loss: 1.4128e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 7.2430e-04 - val_loss: 2.2534e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.1674e-04 - val_loss: 4.1556e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 9.1878e-04 - val_loss: 1.4263e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.0015e-04 - val_loss: 5.7295e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 8.0803e-04 - val_loss: 1.3698e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 7.3776e-04 - val_loss: 1.2411e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.9413e-04 - val_loss: 5.1626e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 6.6575e-04 - val_loss: 1.6087e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 6.3058e-04 - val_loss: 1.0797e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 7.8607e-04 - val_loss: 1.8311e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 7.8443e-04 - val_loss: 1.2654e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 6.1879e-04 - val_loss: 2.3102e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 7.3148e-04 - val_loss: 9.8694e-05\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 6.7592e-04 - val_loss: 7.7506e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 7.7545e-04 - val_loss: 7.8821e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.6008e-04 - val_loss: 1.9762e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.0860e-04 - val_loss: 1.1917e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 6.5544e-04 - val_loss: 2.5223e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.6080e-04 - val_loss: 9.0657e-05\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.3122e-04 - val_loss: 1.7304e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 7.4827e-04 - val_loss: 9.6337e-05\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.5725e-04 - val_loss: 2.3457e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.9141e-04 - val_loss: 9.4678e-05\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 6.0816e-04 - val_loss: 9.2256e-05\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 7.7110e-04 - val_loss: 9.2380e-05\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.7716e-04 - val_loss: 9.5762e-05\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 6.5505e-04 - val_loss: 4.1097e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.4923e-04 - val_loss: 8.8732e-05\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 5.7769e-04 - val_loss: 9.7112e-05\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.1419e-04 - val_loss: 1.3144e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 6.9535e-04 - val_loss: 8.6483e-05\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 8.1172e-04 - val_loss: 5.6787e-04\n",
      "9/9 [==============================] - 10s 35ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 90.68968577808018\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 58s 150ms/step - loss: 0.0085 - val_loss: 6.1194e-04\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 0.0030 - val_loss: 3.9240e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.0022 - val_loss: 7.5733e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.0018 - val_loss: 6.3818e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.0021 - val_loss: 7.9843e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.0010 - val_loss: 2.0167e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0011 - val_loss: 1.4653e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 9.4794e-04 - val_loss: 1.9170e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 9.0682e-04 - val_loss: 1.1581e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 9.7480e-04 - val_loss: 2.8551e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 7.0158e-04 - val_loss: 1.0896e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 7.8521e-04 - val_loss: 2.0448e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 7.5548e-04 - val_loss: 1.6096e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 8.8246e-04 - val_loss: 1.3560e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 7.8152e-04 - val_loss: 1.3493e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 9.3824e-04 - val_loss: 1.1264e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.5057e-04 - val_loss: 1.2729e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 6.6657e-04 - val_loss: 3.1232e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 7.1837e-04 - val_loss: 2.3815e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.7491e-04 - val_loss: 1.4861e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 7.6305e-04 - val_loss: 6.9110e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.9086e-04 - val_loss: 2.8942e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.5217e-04 - val_loss: 9.2399e-05\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.9611e-04 - val_loss: 9.6383e-05\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 7.1741e-04 - val_loss: 1.2069e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 6.8855e-04 - val_loss: 1.8928e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.9883e-04 - val_loss: 2.4160e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.9479e-04 - val_loss: 1.2689e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.0826e-04 - val_loss: 8.8724e-05\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.5610e-04 - val_loss: 2.0794e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 7.7101e-04 - val_loss: 1.2256e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 7.5902e-04 - val_loss: 3.9140e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 7.6956e-04 - val_loss: 8.8403e-05\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 6.3335e-04 - val_loss: 9.4241e-05\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.7191e-04 - val_loss: 1.7695e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 6.9640e-04 - val_loss: 1.7846e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.9272e-04 - val_loss: 1.1962e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.7596e-04 - val_loss: 1.4143e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 6.7830e-04 - val_loss: 1.3323e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 6.1526e-04 - val_loss: 8.7211e-05\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 5.8354e-04 - val_loss: 9.8796e-05\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.3196e-04 - val_loss: 1.2949e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 6.5647e-04 - val_loss: 3.8177e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 5.7251e-04 - val_loss: 8.8568e-05\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 5.9027e-04 - val_loss: 8.4976e-05\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 6.4787e-04 - val_loss: 1.0451e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.2624e-04 - val_loss: 9.3700e-05\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 6.5508e-04 - val_loss: 1.1202e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 6.3069e-04 - val_loss: 9.5221e-05\n",
      "9/9 [==============================] - 3s 40ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.58013672902477\n",
      "Training model with epochs=50, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 66s 168ms/step - loss: 0.0108 - val_loss: 9.7165e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 13s 98ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 0.0031 - val_loss: 6.2788e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0028 - val_loss: 3.4528e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 0.0015 - val_loss: 1.9779e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 12s 95ms/step - loss: 0.0011 - val_loss: 1.9942e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 0.0011 - val_loss: 4.0231e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 0.0011 - val_loss: 1.5099e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 9.6356e-04 - val_loss: 2.2039e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 0.0010 - val_loss: 1.1655e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 7.1437e-04 - val_loss: 1.7159e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 8.4380e-04 - val_loss: 1.3068e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 8.4511e-04 - val_loss: 2.0183e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 8.7265e-04 - val_loss: 1.7546e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.7898e-04 - val_loss: 5.0999e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 8.1988e-04 - val_loss: 1.0059e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 0.0011 - val_loss: 1.0727e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 8.5187e-04 - val_loss: 1.4195e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 6.3962e-04 - val_loss: 1.4149e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 6.2401e-04 - val_loss: 1.6061e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 6.6273e-04 - val_loss: 1.2571e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 6.3798e-04 - val_loss: 9.9043e-05\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 6.8891e-04 - val_loss: 1.9178e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 5.9166e-04 - val_loss: 9.3627e-05\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 7.4168e-04 - val_loss: 2.2759e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 6.8522e-04 - val_loss: 1.0533e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.5336e-04 - val_loss: 2.6995e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 0.0012 - val_loss: 9.1023e-05\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.5298e-04 - val_loss: 1.5632e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 7.0671e-04 - val_loss: 8.6769e-05\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.4587e-04 - val_loss: 1.8178e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 7.2223e-04 - val_loss: 1.6646e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 6.6263e-04 - val_loss: 3.0067e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 6.1138e-04 - val_loss: 2.0852e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 6.5722e-04 - val_loss: 9.0775e-05\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 6.0392e-04 - val_loss: 8.7075e-05\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.7460e-04 - val_loss: 9.1051e-05\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 6.2807e-04 - val_loss: 1.1624e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 8.1395e-04 - val_loss: 1.5436e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 7.0945e-04 - val_loss: 1.5133e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 12s 95ms/step - loss: 7.9317e-04 - val_loss: 2.8449e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 6.7157e-04 - val_loss: 4.3679e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 14s 102ms/step - loss: 6.2031e-04 - val_loss: 1.1073e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 5.9063e-04 - val_loss: 1.7763e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 6.2845e-04 - val_loss: 1.0225e-04\n",
      "9/9 [==============================] - 8s 53ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.05279609388185\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 56s 162ms/step - loss: 0.0072 - val_loss: 4.1960e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0031 - val_loss: 6.0213e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0031 - val_loss: 3.7451e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0017 - val_loss: 5.2644e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 0.0014 - val_loss: 7.8573e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0013 - val_loss: 2.1506e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 0.0012 - val_loss: 2.9492e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 9.1961e-04 - val_loss: 8.1572e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 0.0011 - val_loss: 1.7344e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 7.7102e-04 - val_loss: 4.3121e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 17s 126ms/step - loss: 8.3739e-04 - val_loss: 1.4630e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 7.4290e-04 - val_loss: 4.2246e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.7278e-04 - val_loss: 1.5153e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 6.4401e-04 - val_loss: 1.3678e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.5080e-04 - val_loss: 1.2763e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 7.3255e-04 - val_loss: 2.3260e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.6117e-04 - val_loss: 1.2146e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 7.1738e-04 - val_loss: 2.2127e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 7.8421e-04 - val_loss: 2.7805e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.1292e-04 - val_loss: 1.2031e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 6.3131e-04 - val_loss: 4.0378e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.5261e-04 - val_loss: 1.3740e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.2011e-04 - val_loss: 2.0716e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.3730e-04 - val_loss: 7.8551e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 7.5928e-04 - val_loss: 2.0883e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 7.5275e-04 - val_loss: 3.3307e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 5.8780e-04 - val_loss: 1.5436e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.8662e-04 - val_loss: 2.2378e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.7290e-04 - val_loss: 1.9130e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.5280e-04 - val_loss: 1.4405e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.8470e-04 - val_loss: 1.1140e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 7.4936e-04 - val_loss: 2.3589e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 7.9173e-04 - val_loss: 1.6013e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.8754e-04 - val_loss: 1.2009e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 5.9623e-04 - val_loss: 1.1370e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.1463e-04 - val_loss: 5.6734e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.6493e-04 - val_loss: 3.3306e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.3829e-04 - val_loss: 1.1926e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.0308e-04 - val_loss: 2.5147e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 7.1428e-04 - val_loss: 1.8148e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 13s 95ms/step - loss: 5.6289e-04 - val_loss: 1.2738e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 6.7490e-04 - val_loss: 3.5936e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.8360e-04 - val_loss: 1.1385e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 6.2032e-04 - val_loss: 1.0726e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 5.9594e-04 - val_loss: 1.2826e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.9659e-04 - val_loss: 2.3745e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 5.9362e-04 - val_loss: 2.4758e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.9433e-04 - val_loss: 2.1026e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 5.6983e-04 - val_loss: 1.2069e-04\n",
      "8/8 [==============================] - 5s 48ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 45.579428860432095\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 67s 242ms/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 21s 159ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 0.0033 - val_loss: 7.3479e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 0.0023 - val_loss: 6.4640e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 0.0021 - val_loss: 3.7506e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 17s 126ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 16s 125ms/step - loss: 0.0015 - val_loss: 3.2136e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 17s 127ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 0.0014 - val_loss: 5.7921e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 0.0013 - val_loss: 2.3657e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 16s 125ms/step - loss: 0.0010 - val_loss: 5.2801e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 17s 127ms/step - loss: 0.0015 - val_loss: 2.1401e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 0.0011 - val_loss: 2.3529e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 8.2006e-04 - val_loss: 2.8377e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 7.8908e-04 - val_loss: 1.6342e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 7.8656e-04 - val_loss: 1.5223e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 7.6455e-04 - val_loss: 2.3442e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 7.7502e-04 - val_loss: 6.6325e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 8.7462e-04 - val_loss: 1.4031e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 8.5139e-04 - val_loss: 2.6188e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 7.1312e-04 - val_loss: 2.4708e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 7.4030e-04 - val_loss: 1.3631e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 8.3968e-04 - val_loss: 1.8243e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 17s 126ms/step - loss: 6.8731e-04 - val_loss: 1.4528e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 7.2709e-04 - val_loss: 1.4899e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 7.5246e-04 - val_loss: 4.1474e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 9.4369e-04 - val_loss: 4.2479e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 8.5631e-04 - val_loss: 1.2801e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 6.3866e-04 - val_loss: 3.4182e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 6.3734e-04 - val_loss: 6.6672e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.3807e-04 - val_loss: 1.4131e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.3835e-04 - val_loss: 1.9458e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 8.3110e-04 - val_loss: 1.3863e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 6.4636e-04 - val_loss: 1.2801e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.3136e-04 - val_loss: 1.4485e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 7.1371e-04 - val_loss: 1.5289e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 7.2655e-04 - val_loss: 7.1118e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.6529e-04 - val_loss: 1.1124e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.5933e-04 - val_loss: 1.4695e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 6.2301e-04 - val_loss: 1.3042e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 17s 133ms/step - loss: 8.4029e-04 - val_loss: 2.5152e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 6.3988e-04 - val_loss: 1.2040e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 6.1092e-04 - val_loss: 1.0858e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 7.0741e-04 - val_loss: 1.7284e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.9183e-04 - val_loss: 5.3930e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.8350e-04 - val_loss: 1.1697e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.1430e-04 - val_loss: 1.4552e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.1775e-04 - val_loss: 1.4208e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.2628e-04 - val_loss: 1.9671e-04\n",
      "8/8 [==============================] - 6s 61ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 63.630720383265526\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 43s 185ms/step - loss: 0.0110 - val_loss: 4.6105e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0038 - val_loss: 8.8465e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 0.0027 - val_loss: 7.9666e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 0.0025 - val_loss: 3.4227e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 0.0016 - val_loss: 3.6058e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 0.0014 - val_loss: 7.5959e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0016 - val_loss: 3.5285e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 0.0014 - val_loss: 5.5541e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 0.0012 - val_loss: 2.5596e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 0.0011 - val_loss: 3.3263e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 9.3833e-04 - val_loss: 2.4240e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 8.5575e-04 - val_loss: 1.5362e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.2585e-04 - val_loss: 1.3912e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 7.9817e-04 - val_loss: 1.3696e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.6031e-04 - val_loss: 7.5883e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 6.8047e-04 - val_loss: 1.3444e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 22s 164ms/step - loss: 7.1452e-04 - val_loss: 5.0228e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 6.4902e-04 - val_loss: 1.4090e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 7.7265e-04 - val_loss: 3.2042e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 9.5110e-04 - val_loss: 2.4930e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 7.0789e-04 - val_loss: 3.4149e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 24s 181ms/step - loss: 8.0284e-04 - val_loss: 2.1935e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 8.2123e-04 - val_loss: 2.0260e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 25s 186ms/step - loss: 6.6389e-04 - val_loss: 2.0035e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 7.6363e-04 - val_loss: 2.3822e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 7.4424e-04 - val_loss: 2.0688e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 23s 178ms/step - loss: 6.6700e-04 - val_loss: 1.2397e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 6.6536e-04 - val_loss: 1.8212e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 8.2492e-04 - val_loss: 1.2664e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 24s 184ms/step - loss: 7.1403e-04 - val_loss: 2.3555e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 5.7393e-04 - val_loss: 1.1863e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 7.1629e-04 - val_loss: 1.5091e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 22s 164ms/step - loss: 7.3659e-04 - val_loss: 3.5521e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 7.4081e-04 - val_loss: 4.9776e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.8082e-04 - val_loss: 1.6652e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.4037e-04 - val_loss: 1.1269e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 6.6949e-04 - val_loss: 1.1267e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.8157e-04 - val_loss: 6.8883e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.9248e-04 - val_loss: 2.3247e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.9227e-04 - val_loss: 3.8115e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 7.1293e-04 - val_loss: 1.9920e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 7.1375e-04 - val_loss: 1.5557e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.5932e-04 - val_loss: 1.4749e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 5.9348e-04 - val_loss: 1.1723e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 5.7754e-04 - val_loss: 1.0985e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 5.9015e-04 - val_loss: 1.5207e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 5.6597e-04 - val_loss: 1.2796e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 7.3715e-04 - val_loss: 1.3526e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.2532e-04 - val_loss: 2.2248e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.0911e-04 - val_loss: 2.4088e-04\n",
      "8/8 [==============================] - 4s 70ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 70.5843426202368\n",
      "Training model with epochs=50, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 47s 190ms/step - loss: 0.0145 - val_loss: 7.0932e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 0.0037 - val_loss: 4.4958e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 0.0017 - val_loss: 5.7498e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 0.0014 - val_loss: 2.7695e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 0.0016 - val_loss: 3.8352e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 0.0014 - val_loss: 3.1440e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 0.0012 - val_loss: 2.4471e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 9.7030e-04 - val_loss: 3.3183e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 9.2927e-04 - val_loss: 2.0103e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.4547e-04 - val_loss: 2.5142e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 7.5385e-04 - val_loss: 1.6813e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 8.4192e-04 - val_loss: 3.2807e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 8.5483e-04 - val_loss: 1.7735e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 0.0011 - val_loss: 8.5329e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 19s 148ms/step - loss: 8.7172e-04 - val_loss: 4.6804e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 7.3611e-04 - val_loss: 3.9937e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 8.6528e-04 - val_loss: 2.0050e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 8.6051e-04 - val_loss: 1.3062e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 6.8261e-04 - val_loss: 2.2933e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 7.8471e-04 - val_loss: 4.5099e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.4646e-04 - val_loss: 2.2886e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 6.0697e-04 - val_loss: 1.2831e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 6.8446e-04 - val_loss: 1.2011e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.5006e-04 - val_loss: 1.4255e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 6.9509e-04 - val_loss: 2.0077e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 6.8068e-04 - val_loss: 2.6469e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.4205e-04 - val_loss: 1.2849e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 7.3187e-04 - val_loss: 1.3412e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 7.3372e-04 - val_loss: 1.7036e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.3014e-04 - val_loss: 2.4230e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.4636e-04 - val_loss: 1.4509e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.8131e-04 - val_loss: 2.1848e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 19s 148ms/step - loss: 8.1425e-04 - val_loss: 1.2217e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 8.6537e-04 - val_loss: 1.0594e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.7274e-04 - val_loss: 1.1439e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 5.5575e-04 - val_loss: 2.3487e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 17s 128ms/step - loss: 7.0029e-04 - val_loss: 1.1854e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.2951e-04 - val_loss: 1.2124e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 16s 125ms/step - loss: 7.2877e-04 - val_loss: 1.7409e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.6667e-04 - val_loss: 2.4446e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.2481e-04 - val_loss: 2.8911e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.4371e-04 - val_loss: 1.2811e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.5361e-04 - val_loss: 3.2844e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 7.2586e-04 - val_loss: 4.8640e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 7.3356e-04 - val_loss: 1.0714e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 5.5974e-04 - val_loss: 1.3528e-04\n",
      "8/8 [==============================] - 5s 81ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 50.33769931967402\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 41s 145ms/step - loss: 0.0091 - val_loss: 4.0806e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0035 - val_loss: 4.8233e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0025 - val_loss: 7.5667e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0023 - val_loss: 3.9401e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0016 - val_loss: 3.7434e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0013 - val_loss: 4.4689e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0013 - val_loss: 2.2743e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 0.0013 - val_loss: 9.2172e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.0014 - val_loss: 3.6874e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 9.6188e-04 - val_loss: 2.0219e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 9.9188e-04 - val_loss: 1.9834e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 9.0603e-04 - val_loss: 1.6862e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 9.0983e-04 - val_loss: 3.9367e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 8.9324e-04 - val_loss: 1.6098e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 7.0154e-04 - val_loss: 4.1759e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 6.9691e-04 - val_loss: 3.9811e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 17s 132ms/step - loss: 8.3494e-04 - val_loss: 1.2154e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 7.8015e-04 - val_loss: 1.3866e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 6.9176e-04 - val_loss: 2.6417e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 16s 125ms/step - loss: 7.4914e-04 - val_loss: 3.0137e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.4939e-04 - val_loss: 1.5589e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 8.1270e-04 - val_loss: 1.1253e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 8.1627e-04 - val_loss: 1.9850e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.8753e-04 - val_loss: 1.2059e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.1907e-04 - val_loss: 1.4839e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 7.1957e-04 - val_loss: 1.3672e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.3062e-04 - val_loss: 1.4103e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.3878e-04 - val_loss: 1.5488e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.2047e-04 - val_loss: 7.5771e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.1316e-04 - val_loss: 1.2583e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.2576e-04 - val_loss: 1.9760e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0561e-04 - val_loss: 1.3180e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.4407e-04 - val_loss: 1.7437e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.7059e-04 - val_loss: 1.1136e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.6755e-04 - val_loss: 3.5083e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.6154e-04 - val_loss: 1.0612e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.1375e-04 - val_loss: 6.3085e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 6.5736e-04 - val_loss: 1.3264e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.2895e-04 - val_loss: 2.9645e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.1028e-04 - val_loss: 2.0735e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.6364e-04 - val_loss: 1.4440e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.1230e-04 - val_loss: 6.5593e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.6649e-04 - val_loss: 2.3738e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.3672e-04 - val_loss: 1.0449e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 6.0175e-04 - val_loss: 1.1627e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.4576e-04 - val_loss: 1.2537e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.3551e-04 - val_loss: 1.6156e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.3519e-04 - val_loss: 2.0071e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 7.3481e-04 - val_loss: 1.3827e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.4673e-04 - val_loss: 1.0698e-04\n",
      "7/7 [==============================] - 4s 55ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.64454728631389\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 47s 196ms/step - loss: 0.0119 - val_loss: 9.9355e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 21s 162ms/step - loss: 0.0042 - val_loss: 6.4714e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 0.0031 - val_loss: 3.7198e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 0.0021 - val_loss: 5.7916e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 0.0019 - val_loss: 8.2926e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 0.0019 - val_loss: 3.5552e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 0.0019 - val_loss: 4.0238e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0015 - val_loss: 8.2703e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 17s 131ms/step - loss: 0.0015 - val_loss: 5.3863e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0013 - val_loss: 2.3688e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 0.0013 - val_loss: 1.9598e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 9.9177e-04 - val_loss: 1.8850e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 8.4412e-04 - val_loss: 1.6641e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 0.0010 - val_loss: 2.9014e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 0.0010 - val_loss: 3.6896e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 8.5456e-04 - val_loss: 1.8198e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.0363e-04 - val_loss: 4.2577e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 8.4414e-04 - val_loss: 1.6201e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 8.5073e-04 - val_loss: 1.4988e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 6.9608e-04 - val_loss: 3.7128e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 6.8593e-04 - val_loss: 1.3231e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 7.2972e-04 - val_loss: 1.7740e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 6.5877e-04 - val_loss: 1.3619e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.8731e-04 - val_loss: 6.5027e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 9.8030e-04 - val_loss: 1.2275e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 8.5550e-04 - val_loss: 1.5343e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.3925e-04 - val_loss: 3.3151e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 8.8184e-04 - val_loss: 1.1891e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 7.8681e-04 - val_loss: 3.6532e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.0498e-04 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 7.5550e-04 - val_loss: 1.1626e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.6294e-04 - val_loss: 1.2239e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 7.0576e-04 - val_loss: 2.3795e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.5629e-04 - val_loss: 3.7043e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.6444e-04 - val_loss: 1.3877e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 6.3233e-04 - val_loss: 1.3973e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 6.1809e-04 - val_loss: 1.2561e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 6.2771e-04 - val_loss: 1.1539e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 6.4172e-04 - val_loss: 2.5768e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.7567e-04 - val_loss: 4.4586e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 6.9501e-04 - val_loss: 3.0865e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.2888e-04 - val_loss: 1.2497e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.4387e-04 - val_loss: 1.0573e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.3173e-04 - val_loss: 9.8405e-05\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.1155e-04 - val_loss: 3.6975e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.3556e-04 - val_loss: 1.2041e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.0801e-04 - val_loss: 1.1487e-04\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 7.2027e-04 - val_loss: 1.1095e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 7.6431e-04 - val_loss: 2.7125e-04\n",
      "7/7 [==============================] - 4s 67ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 80.20947177632961\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 35s 160ms/step - loss: 0.0063 - val_loss: 3.4811e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 18s 135ms/step - loss: 0.0023 - val_loss: 5.7571e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0020 - val_loss: 2.6580e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 0.0020 - val_loss: 5.1252e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0015 - val_loss: 2.7434e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 9.5916e-04 - val_loss: 1.6204e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 8.1676e-04 - val_loss: 3.7150e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 9.2172e-04 - val_loss: 1.9199e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 9.1934e-04 - val_loss: 1.2318e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 8.5124e-04 - val_loss: 6.2343e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 8.1084e-04 - val_loss: 2.1677e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.1943e-04 - val_loss: 5.2500e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.7053e-04 - val_loss: 1.3508e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.1555e-04 - val_loss: 1.2571e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.0042e-04 - val_loss: 1.1696e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 6.9103e-04 - val_loss: 1.1576e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.9413e-04 - val_loss: 1.0438e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.0198e-04 - val_loss: 1.4780e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.5898e-04 - val_loss: 3.2970e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 8.6115e-04 - val_loss: 1.0488e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 6.5224e-04 - val_loss: 1.3046e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 7.5477e-04 - val_loss: 1.9872e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 7.0136e-04 - val_loss: 2.3559e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 6.9245e-04 - val_loss: 1.2523e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.3666e-04 - val_loss: 5.0110e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 8.0858e-04 - val_loss: 5.0055e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.5454e-04 - val_loss: 1.6843e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 7.1128e-04 - val_loss: 2.0539e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 6.2881e-04 - val_loss: 8.1920e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 0.0010 - val_loss: 1.4535e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.9370e-04 - val_loss: 3.1017e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 6.5698e-04 - val_loss: 2.1930e-04\n",
      "7/7 [==============================] - 4s 91ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.42932310246256\n",
      "Training model with epochs=50, batch_size=8, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 52s 234ms/step - loss: 0.0106 - val_loss: 0.0019\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 26s 197ms/step - loss: 0.0042 - val_loss: 3.9769e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 0.0032 - val_loss: 3.8289e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 0.0026 - val_loss: 4.2360e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 26s 193ms/step - loss: 0.0019 - val_loss: 3.0788e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 0.0015 - val_loss: 4.4902e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 0.0019 - val_loss: 4.8718e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 0.0014 - val_loss: 2.0950e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 0.0010 - val_loss: 4.1685e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 27s 205ms/step - loss: 0.0010 - val_loss: 1.7104e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 26s 193ms/step - loss: 0.0012 - val_loss: 1.5445e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 26s 193ms/step - loss: 9.4540e-04 - val_loss: 1.4577e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 9.0866e-04 - val_loss: 4.7031e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 8.7080e-04 - val_loss: 2.0390e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.7975e-04 - val_loss: 1.7713e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.6364e-04 - val_loss: 4.8447e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 8.5808e-04 - val_loss: 5.8733e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 8.2278e-04 - val_loss: 2.7876e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.5537e-04 - val_loss: 3.6672e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.5925e-04 - val_loss: 1.5952e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 22s 163ms/step - loss: 6.8737e-04 - val_loss: 1.1448e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.8772e-04 - val_loss: 1.0328e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 7.7886e-04 - val_loss: 6.5788e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 25s 187ms/step - loss: 8.1600e-04 - val_loss: 3.0558e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.5497e-04 - val_loss: 1.0869e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 6.0539e-04 - val_loss: 1.4006e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 7.1683e-04 - val_loss: 1.8846e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.9314e-04 - val_loss: 4.7428e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 6.7499e-04 - val_loss: 1.7233e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.9117e-04 - val_loss: 9.9515e-05\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 7.8272e-04 - val_loss: 1.1536e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 7.3137e-04 - val_loss: 1.2119e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.5899e-04 - val_loss: 1.0584e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 8.6638e-04 - val_loss: 4.1602e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 25s 191ms/step - loss: 7.2007e-04 - val_loss: 9.9496e-05\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 7.0702e-04 - val_loss: 1.0389e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 6.9364e-04 - val_loss: 1.3088e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 6.2815e-04 - val_loss: 1.2777e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 7.4615e-04 - val_loss: 1.0035e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 8.6434e-04 - val_loss: 1.0296e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 25s 191ms/step - loss: 5.8492e-04 - val_loss: 1.3270e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 25s 190ms/step - loss: 7.3206e-04 - val_loss: 3.4177e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 6.8336e-04 - val_loss: 3.4201e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 6.3509e-04 - val_loss: 2.2521e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 6.9618e-04 - val_loss: 1.4176e-04\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 5.7199e-04 - val_loss: 2.0711e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 6.5608e-04 - val_loss: 2.6525e-04\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 6.7355e-04 - val_loss: 9.9649e-05\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.4238e-04 - val_loss: 1.5152e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 6.0324e-04 - val_loss: 1.3340e-04\n",
      "7/7 [==============================] - 6s 109ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.96913620605502\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 30s 40ms/step - loss: 0.0088 - val_loss: 3.8797e-04\n",
      "Epoch 2/100\n",
      "  3/263 [..............................] - ETA: 8s - loss: 0.0050    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 9s 35ms/step - loss: 0.0031 - val_loss: 6.5698e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0025 - val_loss: 2.3156e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 9s 35ms/step - loss: 0.0016 - val_loss: 2.5165e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0015 - val_loss: 1.8622e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0012 - val_loss: 2.2564e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0010 - val_loss: 1.6222e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.0012 - val_loss: 1.3065e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.9996e-04 - val_loss: 2.5816e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.8928e-04 - val_loss: 1.0709e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.6973e-04 - val_loss: 6.5010e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.3206e-04 - val_loss: 6.2913e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 8.9124e-04 - val_loss: 2.1309e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.9318e-04 - val_loss: 1.0042e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.7970e-04 - val_loss: 5.8166e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 8.7378e-04 - val_loss: 5.2439e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 7.7826e-04 - val_loss: 1.0736e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.4157e-04 - val_loss: 1.9119e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.6316e-04 - val_loss: 1.2477e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.1810e-04 - val_loss: 1.4006e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 6.9551e-04 - val_loss: 1.7459e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.1458e-04 - val_loss: 2.4799e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.5769e-04 - val_loss: 4.2692e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 9s 36ms/step - loss: 7.3355e-04 - val_loss: 4.7666e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.4542e-04 - val_loss: 1.0041e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.0769e-04 - val_loss: 1.8088e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.5073e-04 - val_loss: 8.9530e-05\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 7.1191e-04 - val_loss: 9.7778e-05\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 5.9268e-04 - val_loss: 1.5735e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 7.7321e-04 - val_loss: 5.7398e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 6.5423e-04 - val_loss: 1.0818e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 7.1074e-04 - val_loss: 4.9130e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 7.1703e-04 - val_loss: 4.4575e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.5641e-04 - val_loss: 9.0071e-05\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.0677e-04 - val_loss: 1.5422e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.0662e-04 - val_loss: 1.3594e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.7151e-04 - val_loss: 1.4027e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.3563e-04 - val_loss: 8.5769e-05\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 6.3166e-04 - val_loss: 2.5451e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 6.9315e-04 - val_loss: 9.3648e-05\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.4176e-04 - val_loss: 1.3881e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.4782e-04 - val_loss: 1.4339e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.1508e-04 - val_loss: 8.8059e-05\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.1729e-04 - val_loss: 8.4996e-05\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.2091e-04 - val_loss: 2.5551e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 7.1687e-04 - val_loss: 9.8489e-05\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 6.0268e-04 - val_loss: 1.1963e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 14s 52ms/step - loss: 6.0242e-04 - val_loss: 1.8551e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.4510e-04 - val_loss: 1.1453e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 6.2440e-04 - val_loss: 9.6595e-05\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.3437e-04 - val_loss: 8.7793e-05\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 6.5405e-04 - val_loss: 9.8682e-05\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 6.5872e-04 - val_loss: 1.0240e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 5.7299e-04 - val_loss: 1.0100e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 5.8342e-04 - val_loss: 1.2894e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 6.4704e-04 - val_loss: 1.2260e-04\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 6.2601e-04 - val_loss: 4.6249e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 9s 36ms/step - loss: 6.5548e-04 - val_loss: 9.0414e-05\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 6.2760e-04 - val_loss: 8.5828e-05\n",
      "9/9 [==============================] - 3s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.72000917897652\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 32s 62ms/step - loss: 0.0107 - val_loss: 0.0017\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0040 - val_loss: 5.3409e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0024 - val_loss: 8.9104e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0017 - val_loss: 3.9547e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0012 - val_loss: 2.9570e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0010 - val_loss: 2.4556e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0013 - val_loss: 6.5265e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 9.8035e-04 - val_loss: 6.9128e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 8.3900e-04 - val_loss: 1.2284e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.8713e-04 - val_loss: 4.7950e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.4246e-04 - val_loss: 1.4842e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.4066e-04 - val_loss: 1.0724e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 8.8902e-04 - val_loss: 1.6606e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0011 - val_loss: 2.8808e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.8724e-04 - val_loss: 5.2563e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 8.7466e-04 - val_loss: 1.4151e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.0789e-04 - val_loss: 2.2026e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.3545e-04 - val_loss: 3.3298e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.3454e-04 - val_loss: 3.9916e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.6768e-04 - val_loss: 9.4240e-05\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.2704e-04 - val_loss: 2.4954e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.6442e-04 - val_loss: 1.5612e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.8515e-04 - val_loss: 1.8438e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 8.6281e-04 - val_loss: 2.1407e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 7.4845e-04 - val_loss: 1.6972e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4332e-04 - val_loss: 1.6389e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.8885e-04 - val_loss: 1.4401e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.2373e-04 - val_loss: 1.4010e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.6607e-04 - val_loss: 1.0825e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 0.0011 - val_loss: 1.3438e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.2200e-04 - val_loss: 1.2745e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.5485e-04 - val_loss: 1.9637e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.6131e-04 - val_loss: 1.5668e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.5589e-04 - val_loss: 9.2661e-05\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.7836e-04 - val_loss: 1.0790e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 6.7554e-04 - val_loss: 1.0341e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 6.9657e-04 - val_loss: 3.4541e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 7.1069e-04 - val_loss: 1.5595e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.4375e-04 - val_loss: 1.4952e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.8950e-04 - val_loss: 1.3431e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.5346e-04 - val_loss: 1.4585e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 7.3543e-04 - val_loss: 9.0606e-05\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.0959e-04 - val_loss: 1.2754e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.0366e-04 - val_loss: 1.6821e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 6.0410e-04 - val_loss: 1.0060e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4636e-04 - val_loss: 9.7843e-05\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.8285e-04 - val_loss: 2.5964e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.0411e-04 - val_loss: 8.8992e-05\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.9457e-04 - val_loss: 1.2724e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.7720e-04 - val_loss: 9.3319e-05\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4607e-04 - val_loss: 8.9098e-05\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.0997e-04 - val_loss: 1.1372e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.4065e-04 - val_loss: 1.4047e-04\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.4204e-04 - val_loss: 8.5626e-05\n",
      "Epoch 57/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.3465e-04 - val_loss: 1.1071e-04\n",
      "Epoch 58/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.5519e-04 - val_loss: 2.3706e-04\n",
      "Epoch 59/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.8925e-04 - val_loss: 3.4790e-04\n",
      "Epoch 60/100\n",
      "263/263 [==============================] - 12s 48ms/step - loss: 5.9656e-04 - val_loss: 1.3244e-04\n",
      "Epoch 61/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 7.5498e-04 - val_loss: 1.1923e-04\n",
      "Epoch 62/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.7610e-04 - val_loss: 9.9646e-05\n",
      "Epoch 63/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.5718e-04 - val_loss: 1.1723e-04\n",
      "Epoch 64/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.9286e-04 - val_loss: 8.8119e-05\n",
      "Epoch 65/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.1816e-04 - val_loss: 9.8080e-05\n",
      "Epoch 66/100\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 6.0687e-04 - val_loss: 1.1434e-04\n",
      "Epoch 67/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.7285e-04 - val_loss: 1.7490e-04\n",
      "Epoch 68/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.6113e-04 - val_loss: 1.2486e-04\n",
      "Epoch 69/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.7859e-04 - val_loss: 9.9568e-05\n",
      "Epoch 70/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 5.9973e-04 - val_loss: 9.7154e-05\n",
      "Epoch 71/100\n",
      "263/263 [==============================] - 13s 48ms/step - loss: 6.1318e-04 - val_loss: 9.9179e-05\n",
      "9/9 [==============================] - 4s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.44097840808724\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 28s 57ms/step - loss: 0.0059 - val_loss: 3.4314e-04\n",
      "Epoch 2/100\n",
      "  1/263 [..............................] - ETA: 11s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 12s 46ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.0017 - val_loss: 2.0021e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.0014 - val_loss: 1.3896e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.0011 - val_loss: 1.2363e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.0010 - val_loss: 2.0733e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 9.7874e-04 - val_loss: 3.1417e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 8.2236e-04 - val_loss: 1.1166e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 9.4514e-04 - val_loss: 2.5686e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 9.5530e-04 - val_loss: 1.0185e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.3237e-04 - val_loss: 9.5653e-05\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 0.0010 - val_loss: 1.1270e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.9163e-04 - val_loss: 2.8752e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.3728e-04 - val_loss: 1.1445e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.6055e-04 - val_loss: 1.1972e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.6421e-04 - val_loss: 3.9762e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.6532e-04 - val_loss: 9.3927e-05\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.8537e-04 - val_loss: 9.2909e-05\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.5067e-04 - val_loss: 9.5017e-05\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 8.9928e-04 - val_loss: 1.9833e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.5684e-04 - val_loss: 9.1998e-05\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.1859e-04 - val_loss: 3.1011e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.2146e-04 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.2869e-04 - val_loss: 1.8502e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.6852e-04 - val_loss: 2.2321e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 7.4643e-04 - val_loss: 1.9643e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.5879e-04 - val_loss: 9.2412e-05\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.5672e-04 - val_loss: 1.3325e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.4851e-04 - val_loss: 7.3746e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.6163e-04 - val_loss: 1.0095e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.9155e-04 - val_loss: 2.4396e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.7361e-04 - val_loss: 9.1334e-05\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.2118e-04 - val_loss: 8.6981e-05\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.7248e-04 - val_loss: 1.3723e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.3983e-04 - val_loss: 1.4067e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 6.8632e-04 - val_loss: 8.8238e-05\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.3267e-04 - val_loss: 8.7347e-05\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.7331e-04 - val_loss: 8.7559e-05\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.2217e-04 - val_loss: 1.5929e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 5.9647e-04 - val_loss: 1.1911e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.2591e-04 - val_loss: 8.4944e-05\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.7918e-04 - val_loss: 2.0709e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 5.9712e-04 - val_loss: 8.8572e-05\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.1350e-04 - val_loss: 1.2533e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.3962e-04 - val_loss: 1.2042e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.4304e-04 - val_loss: 1.8194e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.0611e-04 - val_loss: 1.0181e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.3290e-04 - val_loss: 9.8195e-05\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 5.9783e-04 - val_loss: 1.7018e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.9773e-04 - val_loss: 1.2857e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.3496e-04 - val_loss: 3.6168e-04\n",
      "Epoch 52/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 7.0670e-04 - val_loss: 8.5367e-05\n",
      "Epoch 53/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.3908e-04 - val_loss: 2.5998e-04\n",
      "Epoch 54/100\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 6.1183e-04 - val_loss: 1.3379e-04\n",
      "Epoch 55/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 7.2146e-04 - val_loss: 9.0292e-05\n",
      "Epoch 56/100\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 6.2734e-04 - val_loss: 8.5588e-05\n",
      "9/9 [==============================] - 3s 30ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.51334731758593\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 37s 74ms/step - loss: 0.0084 - val_loss: 9.9176e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 16s 59ms/step - loss: 0.0037 - val_loss: 2.9811e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 16s 59ms/step - loss: 0.0023 - val_loss: 2.1043e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 0.0021 - val_loss: 4.8264e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.0012 - val_loss: 3.4106e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 0.0012 - val_loss: 8.1712e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 0.0010 - val_loss: 1.5449e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 16s 59ms/step - loss: 8.3213e-04 - val_loss: 1.5325e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 8.9887e-04 - val_loss: 1.4430e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 8.2281e-04 - val_loss: 1.4154e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 8.7254e-04 - val_loss: 2.3966e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 9.2741e-04 - val_loss: 3.6179e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 9.5854e-04 - val_loss: 2.7996e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 8.2175e-04 - val_loss: 1.3497e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 9.0483e-04 - val_loss: 1.3967e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 17s 65ms/step - loss: 8.1634e-04 - val_loss: 1.0428e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.2854e-04 - val_loss: 1.8348e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 8.2478e-04 - val_loss: 9.7919e-05\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 8.6810e-04 - val_loss: 1.3414e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.9310e-04 - val_loss: 4.7077e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 6.7748e-04 - val_loss: 1.1534e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.8016e-04 - val_loss: 9.0586e-05\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.8638e-04 - val_loss: 1.0373e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.9466e-04 - val_loss: 1.0991e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.1888e-04 - val_loss: 9.5089e-05\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 0.0010 - val_loss: 5.5616e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 8.5861e-04 - val_loss: 4.1349e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.3733e-04 - val_loss: 1.5223e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 8.4323e-04 - val_loss: 9.4359e-05\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 16s 59ms/step - loss: 6.6191e-04 - val_loss: 1.0419e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.8125e-04 - val_loss: 1.7974e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.3743e-04 - val_loss: 9.1291e-05\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 15s 59ms/step - loss: 6.9998e-04 - val_loss: 2.1667e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 6.6665e-04 - val_loss: 1.3569e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.4916e-04 - val_loss: 4.9264e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 16s 59ms/step - loss: 6.7913e-04 - val_loss: 1.0256e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 15s 58ms/step - loss: 7.0560e-04 - val_loss: 2.4080e-04\n",
      "9/9 [==============================] - 4s 34ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 48.22224832285934\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 37s 90ms/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 21s 80ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 0.0028 - val_loss: 6.0967e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.0016 - val_loss: 5.4648e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 0.0015 - val_loss: 2.2732e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.0011 - val_loss: 4.4621e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 9.0867e-04 - val_loss: 1.7844e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 8.8157e-04 - val_loss: 1.5020e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 8.3474e-04 - val_loss: 3.8204e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.5055e-04 - val_loss: 3.0945e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.2023e-04 - val_loss: 1.7965e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.0010 - val_loss: 1.5537e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.6064e-04 - val_loss: 2.2947e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.9833e-04 - val_loss: 2.6443e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 8.3447e-04 - val_loss: 5.5742e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 9.7373e-04 - val_loss: 7.2651e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.9695e-04 - val_loss: 3.9189e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.2112e-04 - val_loss: 1.1361e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 8.0654e-04 - val_loss: 1.4718e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 7.6896e-04 - val_loss: 1.6865e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.2102e-04 - val_loss: 1.3859e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.2092e-04 - val_loss: 3.5654e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 6.9673e-04 - val_loss: 1.5667e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 5.8557e-04 - val_loss: 3.0053e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 7.9844e-04 - val_loss: 1.1079e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.5792e-04 - val_loss: 1.1666e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.3850e-04 - val_loss: 1.2311e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 6.1561e-04 - val_loss: 4.6362e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.6046e-04 - val_loss: 1.9909e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 7.5598e-04 - val_loss: 1.1790e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 6.8991e-04 - val_loss: 2.8651e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.1745e-04 - val_loss: 1.9294e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 8.0039e-04 - val_loss: 4.2074e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.4052e-04 - val_loss: 1.9575e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 6.6959e-04 - val_loss: 1.3513e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.9036e-04 - val_loss: 2.8861e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.0839e-04 - val_loss: 1.2403e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 6.8609e-04 - val_loss: 2.2873e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 7.0239e-04 - val_loss: 1.3509e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 5.8442e-04 - val_loss: 1.1897e-04\n",
      "8/8 [==============================] - 4s 41ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 41.842530369843004\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 60s 135ms/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 30s 112ms/step - loss: 0.0050 - val_loss: 7.3559e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0024 - val_loss: 6.7843e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0019 - val_loss: 7.0640e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 0.0024 - val_loss: 3.2496e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 0.0014 - val_loss: 5.7577e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 9.2114e-04 - val_loss: 2.6933e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 9.5714e-04 - val_loss: 4.4768e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 0.0012 - val_loss: 8.8839e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 9.3302e-04 - val_loss: 5.6026e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 9.9244e-04 - val_loss: 1.5444e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 7.8325e-04 - val_loss: 3.6170e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 30s 112ms/step - loss: 8.1613e-04 - val_loss: 1.5010e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 8.7337e-04 - val_loss: 6.1151e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 9.6911e-04 - val_loss: 4.8112e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 28s 106ms/step - loss: 7.0660e-04 - val_loss: 7.4874e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 8.8788e-04 - val_loss: 1.1729e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 7.6243e-04 - val_loss: 1.8260e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.4661e-04 - val_loss: 1.2104e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 8.1480e-04 - val_loss: 1.4373e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 8.0214e-04 - val_loss: 3.5344e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 8.0136e-04 - val_loss: 1.1312e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 7.2445e-04 - val_loss: 3.1885e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.2325e-04 - val_loss: 1.6563e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.5681e-04 - val_loss: 4.6733e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 8.0473e-04 - val_loss: 1.0603e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.3714e-04 - val_loss: 1.2074e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.1138e-04 - val_loss: 2.2777e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.5103e-04 - val_loss: 1.9245e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.5656e-04 - val_loss: 6.0682e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 7.1788e-04 - val_loss: 1.1238e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.9437e-04 - val_loss: 4.6002e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.9721e-04 - val_loss: 2.3157e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.6565e-04 - val_loss: 1.2374e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 7.0988e-04 - val_loss: 1.9583e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 8.4233e-04 - val_loss: 1.4563e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 6.9004e-04 - val_loss: 1.9205e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 29s 112ms/step - loss: 6.4248e-04 - val_loss: 2.1407e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.2451e-04 - val_loss: 1.1746e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.7092e-04 - val_loss: 1.1880e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 7.5921e-04 - val_loss: 1.1958e-04\n",
      "8/8 [==============================] - 5s 52ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.363938738643185\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 48s 123ms/step - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 31s 117ms/step - loss: 0.0029 - val_loss: 4.2869e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 0.0016 - val_loss: 3.3346e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 0.0015 - val_loss: 7.4619e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 0.0011 - val_loss: 1.8358e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 29s 108ms/step - loss: 0.0010 - val_loss: 1.4419e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 0.0011 - val_loss: 1.7774e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 8.5203e-04 - val_loss: 1.2547e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 0.0010 - val_loss: 1.5078e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 9.6312e-04 - val_loss: 2.9197e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 6.8328e-04 - val_loss: 4.6580e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 7.7129e-04 - val_loss: 2.9061e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 9.1835e-04 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 7.8466e-04 - val_loss: 1.5976e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 7.7523e-04 - val_loss: 2.0751e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 29s 110ms/step - loss: 9.3187e-04 - val_loss: 4.9762e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 7.1398e-04 - val_loss: 1.4284e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 29s 111ms/step - loss: 6.9551e-04 - val_loss: 3.1522e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 30s 113ms/step - loss: 7.9124e-04 - val_loss: 1.0758e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 6.6371e-04 - val_loss: 5.3404e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 7.4620e-04 - val_loss: 1.1817e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 28s 108ms/step - loss: 7.1782e-04 - val_loss: 1.1040e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 8.1866e-04 - val_loss: 1.1810e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 28s 107ms/step - loss: 8.1851e-04 - val_loss: 3.0966e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 6.4034e-04 - val_loss: 2.2798e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 6.9749e-04 - val_loss: 1.2145e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 7.4610e-04 - val_loss: 2.7337e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 8.2759e-04 - val_loss: 1.2316e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 25s 94ms/step - loss: 6.3310e-04 - val_loss: 3.8710e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.3215e-04 - val_loss: 1.5004e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.8953e-04 - val_loss: 1.0721e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.8203e-04 - val_loss: 1.2782e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 27s 101ms/step - loss: 6.2690e-04 - val_loss: 1.3257e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.7151e-04 - val_loss: 6.0375e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 7.5194e-04 - val_loss: 1.9186e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.4237e-04 - val_loss: 2.7677e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.6881e-04 - val_loss: 1.4618e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 7.6339e-04 - val_loss: 1.8330e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.7685e-04 - val_loss: 1.3527e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.0005e-04 - val_loss: 4.5731e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.4254e-04 - val_loss: 1.4605e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.4607e-04 - val_loss: 2.1191e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 25s 97ms/step - loss: 6.9201e-04 - val_loss: 2.2714e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.2167e-04 - val_loss: 1.1794e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 6.4588e-04 - val_loss: 1.2838e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 26s 97ms/step - loss: 6.1340e-04 - val_loss: 1.2223e-04\n",
      "8/8 [==============================] - 3s 61ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.50087487804098\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 53s 139ms/step - loss: 0.0109 - val_loss: 5.9618e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 33s 126ms/step - loss: 0.0048 - val_loss: 4.6554e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 0.0026 - val_loss: 5.5606e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0018 - val_loss: 7.9569e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0018 - val_loss: 5.6410e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 0.0014 - val_loss: 1.9643e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0016 - val_loss: 3.0716e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0011 - val_loss: 4.8615e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.3118e-04 - val_loss: 2.5058e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.5631e-04 - val_loss: 1.5922e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 0.0012 - val_loss: 1.4596e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 9.0602e-04 - val_loss: 1.3733e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.1232e-04 - val_loss: 1.8892e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.0104e-04 - val_loss: 1.6942e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.6271e-04 - val_loss: 1.6071e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.9645e-04 - val_loss: 5.8675e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 8.6694e-04 - val_loss: 1.4705e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 9.2015e-04 - val_loss: 1.1288e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 0.0010 - val_loss: 1.1618e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 7.3722e-04 - val_loss: 2.2825e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.4319e-04 - val_loss: 1.1237e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.5861e-04 - val_loss: 5.5808e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 6.1786e-04 - val_loss: 1.7709e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 7.8029e-04 - val_loss: 3.4380e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.2324e-04 - val_loss: 1.8275e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 7.6598e-04 - val_loss: 1.1274e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.3442e-04 - val_loss: 1.1587e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.7698e-04 - val_loss: 3.0685e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 8.2457e-04 - val_loss: 7.3389e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.7068e-04 - val_loss: 1.0942e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 8.5377e-04 - val_loss: 3.1462e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.7694e-04 - val_loss: 3.4714e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 6.1780e-04 - val_loss: 1.7563e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 7.2159e-04 - val_loss: 1.1077e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 8.1516e-04 - val_loss: 2.5670e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 7.8452e-04 - val_loss: 1.1065e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 33s 124ms/step - loss: 6.7447e-04 - val_loss: 1.3165e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.7539e-04 - val_loss: 1.2673e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 30s 114ms/step - loss: 8.3730e-04 - val_loss: 1.2732e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 30s 115ms/step - loss: 7.2314e-04 - val_loss: 1.1890e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 6.4295e-04 - val_loss: 1.4037e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.8096e-04 - val_loss: 1.5669e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 7.3255e-04 - val_loss: 2.9752e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 6.9075e-04 - val_loss: 1.4692e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 5.6216e-04 - val_loss: 1.3767e-04\n",
      "8/8 [==============================] - 5s 76ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.54977028356625\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 43s 116ms/step - loss: 0.0078 - val_loss: 3.9804e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 27s 105ms/step - loss: 0.0026 - val_loss: 3.3508e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0023 - val_loss: 5.1899e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0017 - val_loss: 8.8368e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0013 - val_loss: 2.4236e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0011 - val_loss: 5.9670e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 0.0010 - val_loss: 1.6864e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.0010 - val_loss: 4.2660e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 9.2431e-04 - val_loss: 1.7344e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 9.2329e-04 - val_loss: 4.9754e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 8.8536e-04 - val_loss: 1.2334e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.9888e-04 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.9201e-04 - val_loss: 2.5178e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.8619e-04 - val_loss: 1.4556e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.7217e-04 - val_loss: 2.2187e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.9644e-04 - val_loss: 8.4257e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 9.0310e-04 - val_loss: 1.8005e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 8.3067e-04 - val_loss: 9.8900e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.7489e-04 - val_loss: 1.3942e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 8.2549e-04 - val_loss: 1.1233e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.6886e-04 - val_loss: 1.3248e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.8484e-04 - val_loss: 1.2204e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.4664e-04 - val_loss: 1.0617e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 7.1124e-04 - val_loss: 1.1812e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 27s 105ms/step - loss: 7.2282e-04 - val_loss: 1.4500e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 7.6168e-04 - val_loss: 9.3082e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.9187e-04 - val_loss: 7.0746e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.9632e-04 - val_loss: 1.0332e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.8704e-04 - val_loss: 1.6087e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 28s 105ms/step - loss: 6.9753e-04 - val_loss: 1.2121e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.5262e-04 - val_loss: 1.7476e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.7132e-04 - val_loss: 1.9977e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.4111e-04 - val_loss: 1.1510e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 7.0674e-04 - val_loss: 1.2824e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 27s 105ms/step - loss: 7.4189e-04 - val_loss: 1.0670e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.9598e-04 - val_loss: 3.8232e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.5455e-04 - val_loss: 2.3604e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.3464e-04 - val_loss: 1.1538e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 7.4366e-04 - val_loss: 1.9790e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 6.5225e-04 - val_loss: 5.9483e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.9460e-04 - val_loss: 1.7846e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.3930e-04 - val_loss: 1.6922e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 27s 104ms/step - loss: 6.4408e-04 - val_loss: 1.4238e-04\n",
      "7/7 [==============================] - 3s 53ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 49.42263573652664\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 57s 153ms/step - loss: 0.0086 - val_loss: 5.5795e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 38s 144ms/step - loss: 0.0036 - val_loss: 3.9996e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0027 - val_loss: 4.0683e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 0.0023 - val_loss: 2.6983e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0017 - val_loss: 3.4384e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0013 - val_loss: 3.6276e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0011 - val_loss: 3.1465e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0011 - val_loss: 3.3953e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 9.8499e-04 - val_loss: 2.3849e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.5119e-04 - val_loss: 5.8290e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 9.2237e-04 - val_loss: 2.2794e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.1391e-04 - val_loss: 1.1657e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.6906e-04 - val_loss: 1.2554e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 0.0011 - val_loss: 2.5586e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.9438e-04 - val_loss: 1.5425e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.5742e-04 - val_loss: 2.0913e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.3668e-04 - val_loss: 1.9348e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 9.5833e-04 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.3276e-04 - val_loss: 4.7542e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 8.3535e-04 - val_loss: 3.3392e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 9.1489e-04 - val_loss: 1.0974e-04\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.0953e-04 - val_loss: 1.3628e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 6.7342e-04 - val_loss: 1.0487e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.4173e-04 - val_loss: 9.9971e-05\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 0.0011 - val_loss: 1.4080e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.4767e-04 - val_loss: 4.0213e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.7230e-04 - val_loss: 2.1281e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.1936e-04 - val_loss: 1.1174e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.1568e-04 - val_loss: 1.6506e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 7.2282e-04 - val_loss: 1.0258e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 6.2076e-04 - val_loss: 1.9875e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 37s 139ms/step - loss: 7.6823e-04 - val_loss: 1.7417e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 36s 138ms/step - loss: 7.3828e-04 - val_loss: 1.1697e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 6.7105e-04 - val_loss: 9.9051e-05\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 36s 139ms/step - loss: 7.7416e-04 - val_loss: 1.1986e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 34s 127ms/step - loss: 6.9555e-04 - val_loss: 1.7404e-04\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 6.8039e-04 - val_loss: 3.2774e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.7669e-04 - val_loss: 2.2883e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 39s 149ms/step - loss: 6.2627e-04 - val_loss: 1.0539e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 40s 150ms/step - loss: 7.3874e-04 - val_loss: 1.6890e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 6.2896e-04 - val_loss: 1.0223e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 40s 151ms/step - loss: 6.9620e-04 - val_loss: 6.0045e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 7.3207e-04 - val_loss: 1.3221e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 5.9646e-04 - val_loss: 3.3226e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 6.5926e-04 - val_loss: 1.0286e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 6.6769e-04 - val_loss: 2.9480e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 40s 151ms/step - loss: 7.0772e-04 - val_loss: 3.3293e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 39s 150ms/step - loss: 6.4037e-04 - val_loss: 1.1380e-04\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 40s 151ms/step - loss: 6.6177e-04 - val_loss: 1.9017e-04\n",
      "7/7 [==============================] - 5s 68ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.55542719675214\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - 63s 176ms/step - loss: 0.0071 - val_loss: 3.4177e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0024 - val_loss: 4.3496e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 0.0016 - val_loss: 2.9064e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 0.0012 - val_loss: 3.3562e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 0.0011 - val_loss: 1.5259e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 0.0010 - val_loss: 1.3970e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 9.3365e-04 - val_loss: 1.8797e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 0.0014 - val_loss: 1.2068e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.4767e-04 - val_loss: 1.6690e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 7.8627e-04 - val_loss: 2.5635e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.2534e-04 - val_loss: 1.2913e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 8.2636e-04 - val_loss: 1.9603e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 7.2928e-04 - val_loss: 1.6510e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 7.8125e-04 - val_loss: 1.3661e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 6.9489e-04 - val_loss: 1.5083e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 8.1868e-04 - val_loss: 3.0232e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 7.5922e-04 - val_loss: 9.8066e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.8184e-04 - val_loss: 1.4566e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.2221e-04 - val_loss: 3.2158e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 8.6930e-04 - val_loss: 0.0010\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.2697e-04 - val_loss: 3.9757e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 29s 109ms/step - loss: 7.7699e-04 - val_loss: 1.0091e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 6.9589e-04 - val_loss: 1.1390e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.5784e-04 - val_loss: 1.6239e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.5514e-04 - val_loss: 1.5220e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.7175e-04 - val_loss: 1.1284e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 8.0934e-04 - val_loss: 1.3256e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.0335e-04 - val_loss: 3.8541e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.8884e-04 - val_loss: 9.7983e-05\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 7.1769e-04 - val_loss: 1.3302e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 7.0133e-04 - val_loss: 1.2973e-04\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.3491e-04 - val_loss: 4.9477e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 7.2829e-04 - val_loss: 1.2319e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.6114e-04 - val_loss: 1.1366e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.9316e-04 - val_loss: 9.6077e-05\n",
      "Epoch 37/100\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 7.0422e-04 - val_loss: 1.4880e-04\n",
      "Epoch 38/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.9406e-04 - val_loss: 6.2195e-04\n",
      "Epoch 39/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.9036e-04 - val_loss: 1.8119e-04\n",
      "Epoch 40/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.2192e-04 - val_loss: 1.5396e-04\n",
      "Epoch 41/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 6.2011e-04 - val_loss: 1.1488e-04\n",
      "Epoch 42/100\n",
      "263/263 [==============================] - 37s 142ms/step - loss: 6.6202e-04 - val_loss: 2.0263e-04\n",
      "Epoch 43/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 6.5360e-04 - val_loss: 1.7099e-04\n",
      "Epoch 44/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 6.1811e-04 - val_loss: 1.0180e-04\n",
      "Epoch 45/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 5.8462e-04 - val_loss: 1.3666e-04\n",
      "Epoch 46/100\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 6.7032e-04 - val_loss: 2.3555e-04\n",
      "Epoch 47/100\n",
      "263/263 [==============================] - 38s 143ms/step - loss: 7.4282e-04 - val_loss: 1.6212e-04\n",
      "Epoch 48/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.6437e-04 - val_loss: 9.6136e-05\n",
      "Epoch 49/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 7.3906e-04 - val_loss: 1.7497e-04\n",
      "Epoch 50/100\n",
      "263/263 [==============================] - 39s 148ms/step - loss: 6.9278e-04 - val_loss: 1.0548e-04\n",
      "Epoch 51/100\n",
      "263/263 [==============================] - 38s 144ms/step - loss: 6.3771e-04 - val_loss: 2.2679e-04\n",
      "7/7 [==============================] - 4s 93ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 42.89021057975056\n",
      "Training model with epochs=100, batch_size=4, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.0070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 72s 197ms/step - loss: 0.0070 - val_loss: 4.9678e-04\n",
      "Epoch 2/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 0.0032 - val_loss: 3.6003e-04\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 0.0024 - val_loss: 4.4353e-04\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 0.0018 - val_loss: 5.8172e-04\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 0.0014 - val_loss: 1.7472e-04\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 0.0012 - val_loss: 1.3235e-04\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 9.7149e-04 - val_loss: 3.6187e-04\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 9.1008e-04 - val_loss: 1.4756e-04\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 0.0010 - val_loss: 3.2017e-04\n",
      "Epoch 10/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.6349e-04 - val_loss: 1.6504e-04\n",
      "Epoch 11/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.3758e-04 - val_loss: 1.1634e-04\n",
      "Epoch 12/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 8.4382e-04 - val_loss: 1.1830e-04\n",
      "Epoch 13/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 8.3384e-04 - val_loss: 1.1673e-04\n",
      "Epoch 14/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 9.6838e-04 - val_loss: 1.1659e-04\n",
      "Epoch 15/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 8.0079e-04 - val_loss: 1.8396e-04\n",
      "Epoch 16/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 9.9341e-04 - val_loss: 1.1913e-04\n",
      "Epoch 17/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 8.4216e-04 - val_loss: 1.0826e-04\n",
      "Epoch 18/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.9602e-04 - val_loss: 2.0963e-04\n",
      "Epoch 19/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 9.8062e-04 - val_loss: 6.9245e-04\n",
      "Epoch 20/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 7.7909e-04 - val_loss: 5.5438e-04\n",
      "Epoch 21/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 7.7824e-04 - val_loss: 9.9790e-05\n",
      "Epoch 22/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 9.8831e-04 - val_loss: 1.1476e-04\n",
      "Epoch 23/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 7.2219e-04 - val_loss: 1.2564e-04\n",
      "Epoch 24/100\n",
      "263/263 [==============================] - 48s 183ms/step - loss: 9.1877e-04 - val_loss: 1.7006e-04\n",
      "Epoch 25/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.1722e-04 - val_loss: 8.0606e-04\n",
      "Epoch 26/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.1221e-04 - val_loss: 1.3773e-04\n",
      "Epoch 27/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.8074e-04 - val_loss: 1.0019e-04\n",
      "Epoch 28/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 7.3312e-04 - val_loss: 3.6334e-04\n",
      "Epoch 29/100\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 8.3381e-04 - val_loss: 1.3495e-04\n",
      "Epoch 30/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 7.7682e-04 - val_loss: 1.7057e-04\n",
      "Epoch 31/100\n",
      "263/263 [==============================] - 50s 190ms/step - loss: 8.2938e-04 - val_loss: 1.0169e-04\n",
      "Epoch 32/100\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 6.7382e-04 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 8.4480e-04 - val_loss: 1.8184e-04\n",
      "Epoch 34/100\n",
      "263/263 [==============================] - 49s 184ms/step - loss: 6.6962e-04 - val_loss: 1.1184e-04\n",
      "Epoch 35/100\n",
      "263/263 [==============================] - 49s 186ms/step - loss: 8.4224e-04 - val_loss: 1.2747e-04\n",
      "Epoch 36/100\n",
      "263/263 [==============================] - 49s 187ms/step - loss: 7.1534e-04 - val_loss: 1.3623e-04\n",
      "7/7 [==============================] - 5s 112ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 48.43075830712718\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 25s 70ms/step - loss: 0.0103 - val_loss: 4.3466e-04\n",
      "Epoch 2/100\n",
      "  2/132 [..............................] - ETA: 7s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0038 - val_loss: 3.5514e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0021 - val_loss: 2.9596e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0014 - val_loss: 2.8196e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0013 - val_loss: 1.9432e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0011 - val_loss: 2.0744e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 0.0010 - val_loss: 1.9146e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 0.0010 - val_loss: 1.5564e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 8.5509e-04 - val_loss: 2.0496e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 0.0010 - val_loss: 2.2941e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 8.5550e-04 - val_loss: 1.3946e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 5s 42ms/step - loss: 8.1193e-04 - val_loss: 2.6408e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 7.4336e-04 - val_loss: 1.7894e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.7636e-04 - val_loss: 3.1770e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 9.1672e-04 - val_loss: 1.2497e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.3418e-04 - val_loss: 2.0234e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.8635e-04 - val_loss: 1.2569e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.5988e-04 - val_loss: 5.6263e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 7.8467e-04 - val_loss: 1.0585e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 7.0120e-04 - val_loss: 7.8285e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 8.6220e-04 - val_loss: 1.7576e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4183e-04 - val_loss: 1.0308e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 6.8755e-04 - val_loss: 3.2298e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.1125e-04 - val_loss: 1.3458e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.0721e-04 - val_loss: 1.0247e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.5032e-04 - val_loss: 9.8637e-05\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 8.2959e-04 - val_loss: 7.4866e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 8.9313e-04 - val_loss: 9.9782e-05\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.7327e-04 - val_loss: 2.7962e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.5067e-04 - val_loss: 1.0612e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4900e-04 - val_loss: 1.5627e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 6.3125e-04 - val_loss: 9.4645e-05\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.1976e-04 - val_loss: 4.6768e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.3730e-04 - val_loss: 1.8280e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4371e-04 - val_loss: 1.5335e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4850e-04 - val_loss: 2.6742e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4353e-04 - val_loss: 1.1766e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 6.6237e-04 - val_loss: 1.5653e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 7.1466e-04 - val_loss: 2.6744e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 6.6792e-04 - val_loss: 1.1298e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.3757e-04 - val_loss: 1.5961e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.4851e-04 - val_loss: 3.0650e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 6.3116e-04 - val_loss: 1.0533e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 5s 41ms/step - loss: 6.1371e-04 - val_loss: 1.6346e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 5.9386e-04 - val_loss: 2.8981e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 5.4031e-04 - val_loss: 1.4844e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 6.0966e-04 - val_loss: 9.5152e-05\n",
      "9/9 [==============================] - 2s 17ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 44.39591812961605\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 26s 83ms/step - loss: 0.0113 - val_loss: 6.2753e-04\n",
      "Epoch 2/100\n",
      "  1/132 [..............................] - ETA: 6s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0043 - val_loss: 4.4265e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0032 - val_loss: 4.2043e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0031 - val_loss: 3.4770e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0028 - val_loss: 2.8946e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0016 - val_loss: 8.6677e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0015 - val_loss: 6.4464e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0016 - val_loss: 2.2888e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0012 - val_loss: 3.9573e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0010 - val_loss: 2.9805e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0010 - val_loss: 3.7842e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 9.6133e-04 - val_loss: 1.4944e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0011 - val_loss: 1.4959e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 9.2420e-04 - val_loss: 1.4092e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.4834e-04 - val_loss: 1.9712e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.6576e-04 - val_loss: 1.4761e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.2957e-04 - val_loss: 1.6377e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.2961e-04 - val_loss: 1.6571e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.1268e-04 - val_loss: 3.1532e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.6757e-04 - val_loss: 1.9857e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.4891e-04 - val_loss: 1.1563e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.2409e-04 - val_loss: 6.4494e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.8348e-04 - val_loss: 1.5058e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 7.8332e-04 - val_loss: 1.8333e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7666e-04 - val_loss: 1.1826e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.3198e-04 - val_loss: 3.0902e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.7230e-04 - val_loss: 5.5690e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.7149e-04 - val_loss: 1.1608e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.4122e-04 - val_loss: 1.1081e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.5666e-04 - val_loss: 1.5083e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.2042e-04 - val_loss: 1.1172e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2856e-04 - val_loss: 2.4474e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.0677e-04 - val_loss: 1.8573e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7238e-04 - val_loss: 1.3035e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.0798e-04 - val_loss: 1.6998e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.7341e-04 - val_loss: 9.5303e-05\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.6624e-04 - val_loss: 1.4946e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2257e-04 - val_loss: 2.6042e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.4335e-04 - val_loss: 1.1681e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7574e-04 - val_loss: 1.1095e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.8068e-04 - val_loss: 2.0140e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7226e-04 - val_loss: 1.2888e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.0564e-04 - val_loss: 2.5011e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.1260e-04 - val_loss: 1.3978e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.3098e-04 - val_loss: 2.2392e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.4077e-04 - val_loss: 2.7395e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2445e-04 - val_loss: 1.0290e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 9.4231e-04 - val_loss: 1.5176e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.3147e-04 - val_loss: 9.6683e-05\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.4260e-04 - val_loss: 9.6566e-05\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.1089e-04 - val_loss: 9.7198e-05\n",
      "9/9 [==============================] - 4s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.66343528559608\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 24s 75ms/step - loss: 0.0098 - val_loss: 4.0164e-04\n",
      "Epoch 2/100\n",
      "  1/132 [..............................] - ETA: 6s - loss: 0.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0025 - val_loss: 6.2299e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0023 - val_loss: 5.7404e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0016 - val_loss: 3.9231e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0016 - val_loss: 3.0315e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0013 - val_loss: 2.2715e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0012 - val_loss: 1.8980e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 0.0013 - val_loss: 2.5679e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.9588e-04 - val_loss: 1.3482e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 8.6625e-04 - val_loss: 2.4773e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.8396e-04 - val_loss: 1.2071e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.3813e-04 - val_loss: 1.2273e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.2468e-04 - val_loss: 7.7734e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.5668e-04 - val_loss: 2.2938e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.5716e-04 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.8142e-04 - val_loss: 5.3467e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 9.0811e-04 - val_loss: 9.8018e-05\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7890e-04 - val_loss: 4.2613e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.8497e-04 - val_loss: 1.2330e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 6.7428e-04 - val_loss: 3.1019e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 7.8799e-04 - val_loss: 1.2089e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 6.8087e-04 - val_loss: 9.9096e-05\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 6s 42ms/step - loss: 7.3877e-04 - val_loss: 1.1220e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 6.7210e-04 - val_loss: 1.2065e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 6s 43ms/step - loss: 7.6812e-04 - val_loss: 9.5091e-05\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 6.3628e-04 - val_loss: 1.2844e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 6s 47ms/step - loss: 6.0448e-04 - val_loss: 1.4815e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 6s 46ms/step - loss: 7.3169e-04 - val_loss: 2.1232e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 6.2732e-04 - val_loss: 2.7049e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.7336e-04 - val_loss: 2.8456e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.2781e-04 - val_loss: 4.1308e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 8.0128e-04 - val_loss: 1.1432e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.1685e-04 - val_loss: 2.2794e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 8.0222e-04 - val_loss: 9.4760e-05\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.8085e-04 - val_loss: 1.0196e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.3527e-04 - val_loss: 8.9316e-05\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.1010e-04 - val_loss: 1.1523e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.8841e-04 - val_loss: 1.0116e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 7.7285e-04 - val_loss: 5.2909e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.9385e-04 - val_loss: 9.5252e-05\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.5293e-04 - val_loss: 1.1925e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 7.4825e-04 - val_loss: 9.7948e-05\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2699e-04 - val_loss: 3.7016e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.6951e-04 - val_loss: 8.9094e-05\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.1893e-04 - val_loss: 1.4384e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.2270e-04 - val_loss: 8.5654e-05\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.7616e-04 - val_loss: 1.5528e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.0864e-04 - val_loss: 8.4877e-05\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.3432e-04 - val_loss: 1.1235e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.8907e-04 - val_loss: 1.2943e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.4125e-04 - val_loss: 9.2032e-05\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 7s 49ms/step - loss: 6.5747e-04 - val_loss: 1.0902e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.0692e-04 - val_loss: 8.9732e-05\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.5877e-04 - val_loss: 2.4754e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.4688e-04 - val_loss: 8.9419e-05\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.1835e-04 - val_loss: 9.4472e-05\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.3512e-04 - val_loss: 9.3017e-05\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.2395e-04 - val_loss: 5.7424e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 6.5245e-04 - val_loss: 1.9663e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 5.6092e-04 - val_loss: 1.0372e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 5.9428e-04 - val_loss: 9.3501e-05\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 6.0683e-04 - val_loss: 9.8697e-05\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 6.1232e-04 - val_loss: 1.6473e-04\n",
      "9/9 [==============================] - 4s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.18884430681221\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 31s 96ms/step - loss: 0.0114 - val_loss: 5.3087e-04\n",
      "Epoch 2/100\n",
      "  1/132 [..............................] - ETA: 7s - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 10s 78ms/step - loss: 0.0046 - val_loss: 4.1616e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 0.0038 - val_loss: 6.1155e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 0.0021 - val_loss: 3.7288e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0021 - val_loss: 3.7806e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 0.0018 - val_loss: 2.2755e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 0.0011 - val_loss: 1.6283e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 9.4832e-04 - val_loss: 3.4077e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0012 - val_loss: 4.4507e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 8.7172e-04 - val_loss: 1.4846e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 9.4543e-04 - val_loss: 1.3729e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.6549e-04 - val_loss: 1.8254e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.2992e-04 - val_loss: 1.4391e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 9.0719e-04 - val_loss: 2.0485e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 8.2627e-04 - val_loss: 1.4064e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 9s 65ms/step - loss: 7.3750e-04 - val_loss: 2.0222e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 8.3832e-04 - val_loss: 3.1396e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 6.5536e-04 - val_loss: 1.1743e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.4026e-04 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 0.0010 - val_loss: 2.2709e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 8.7943e-04 - val_loss: 1.0186e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 8.8463e-04 - val_loss: 1.4065e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 7.0132e-04 - val_loss: 9.2189e-05\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 6.2231e-04 - val_loss: 1.4492e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.6611e-04 - val_loss: 1.7579e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 7.0917e-04 - val_loss: 1.0964e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 8s 64ms/step - loss: 7.2819e-04 - val_loss: 9.4651e-05\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 9s 64ms/step - loss: 6.6547e-04 - val_loss: 1.6088e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 9s 64ms/step - loss: 6.9513e-04 - val_loss: 1.4608e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 8s 63ms/step - loss: 8.1623e-04 - val_loss: 1.0139e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 9s 67ms/step - loss: 7.1156e-04 - val_loss: 8.8061e-05\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 6.0311e-04 - val_loss: 1.0742e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 7.0787e-04 - val_loss: 1.2490e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 6.7899e-04 - val_loss: 2.6765e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 8s 62ms/step - loss: 5.8689e-04 - val_loss: 1.0702e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 8s 61ms/step - loss: 6.2038e-04 - val_loss: 1.3188e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.9655e-04 - val_loss: 1.0935e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 6.0817e-04 - val_loss: 9.2171e-05\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.7429e-04 - val_loss: 1.7202e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 8.2028e-04 - val_loss: 9.9706e-05\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 5.8903e-04 - val_loss: 9.0724e-05\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 7.4163e-04 - val_loss: 8.5424e-05\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.7150e-04 - val_loss: 1.8795e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 9s 69ms/step - loss: 6.0572e-04 - val_loss: 1.1405e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.3112e-04 - val_loss: 1.0010e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 7.5165e-04 - val_loss: 1.2921e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 8.0502e-04 - val_loss: 4.0682e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 7.0013e-04 - val_loss: 1.5922e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 6.5558e-04 - val_loss: 1.2665e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 10s 72ms/step - loss: 6.7561e-04 - val_loss: 9.6953e-05\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.7004e-04 - val_loss: 1.2523e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.4975e-04 - val_loss: 8.6373e-05\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 5.8657e-04 - val_loss: 8.8685e-05\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.7630e-04 - val_loss: 8.9293e-05\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 6.0798e-04 - val_loss: 8.6811e-05\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 9s 70ms/step - loss: 6.7939e-04 - val_loss: 2.6747e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 5.7677e-04 - val_loss: 1.7004e-04\n",
      "9/9 [==============================] - 6s 39ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.336231340258315\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 35s 123ms/step - loss: 0.0077 - val_loss: 0.0012\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 12s 89ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0027 - val_loss: 4.4161e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 0.0019 - val_loss: 5.3974e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 0.0014 - val_loss: 5.6725e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0013 - val_loss: 2.7251e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0013 - val_loss: 2.3099e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0012 - val_loss: 4.5176e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.0012 - val_loss: 2.4264e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 9.1895e-04 - val_loss: 2.6520e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 8.2026e-04 - val_loss: 1.7995e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 8.9877e-04 - val_loss: 1.4332e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.6742e-04 - val_loss: 2.3619e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 8.7973e-04 - val_loss: 2.5028e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.6336e-04 - val_loss: 2.1750e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.2175e-04 - val_loss: 1.2843e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.3381e-04 - val_loss: 1.9252e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 7.5580e-04 - val_loss: 1.7062e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 7.5665e-04 - val_loss: 2.2416e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.7455e-04 - val_loss: 2.1412e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.3059e-04 - val_loss: 1.2604e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.4285e-04 - val_loss: 1.5284e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.4485e-04 - val_loss: 1.2823e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 7.9236e-04 - val_loss: 1.3210e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.5062e-04 - val_loss: 1.8503e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.5073e-04 - val_loss: 1.8420e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.7943e-04 - val_loss: 1.7816e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 6.6476e-04 - val_loss: 4.4323e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 8.9743e-04 - val_loss: 1.9955e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.6133e-04 - val_loss: 6.9879e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 6.5827e-04 - val_loss: 6.9597e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 6.1750e-04 - val_loss: 3.3845e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 9s 72ms/step - loss: 6.2850e-04 - val_loss: 1.2191e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 6.8435e-04 - val_loss: 6.9492e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.9579e-04 - val_loss: 2.2397e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.5558e-04 - val_loss: 1.4117e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 7.4399e-04 - val_loss: 3.6899e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 7.2605e-04 - val_loss: 1.3343e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 6.1464e-04 - val_loss: 1.9019e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.1904e-04 - val_loss: 1.1112e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.6211e-04 - val_loss: 1.4860e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.3454e-04 - val_loss: 1.3514e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 6.1812e-04 - val_loss: 1.3745e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.9216e-04 - val_loss: 1.3424e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 6.6705e-04 - val_loss: 1.5103e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.3749e-04 - val_loss: 9.4398e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.3321e-04 - val_loss: 1.8162e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 5.8127e-04 - val_loss: 1.0856e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.9421e-04 - val_loss: 3.4240e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 6.1191e-04 - val_loss: 1.2916e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.9444e-04 - val_loss: 1.3855e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 6.5728e-04 - val_loss: 2.1890e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 6.2460e-04 - val_loss: 1.4776e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 5.8791e-04 - val_loss: 1.1334e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.7849e-04 - val_loss: 1.0998e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 5.6889e-04 - val_loss: 1.4249e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 5.7704e-04 - val_loss: 2.1051e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 5.7757e-04 - val_loss: 1.2042e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 7.1196e-04 - val_loss: 1.3786e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 6.0650e-04 - val_loss: 5.8177e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 8.5487e-04 - val_loss: 1.0928e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 5.6633e-04 - val_loss: 1.3414e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 6.9492e-04 - val_loss: 3.2172e-04\n",
      "8/8 [==============================] - 4s 40ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 41.52144267662495\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 54s 156ms/step - loss: 0.0104 - val_loss: 0.0013\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0036 - val_loss: 5.1488e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0025 - val_loss: 3.9999e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 0.0019 - val_loss: 4.6860e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.0015 - val_loss: 3.6430e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 0.0014 - val_loss: 5.8527e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 14s 104ms/step - loss: 0.0013 - val_loss: 9.0304e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 0.0020 - val_loss: 7.5299e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 0.0010 - val_loss: 4.4098e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 9.5677e-04 - val_loss: 2.5225e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.4303e-04 - val_loss: 6.9693e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 8.8098e-04 - val_loss: 1.7735e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 8.0670e-04 - val_loss: 4.5785e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.6405e-04 - val_loss: 3.8047e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 9.3155e-04 - val_loss: 1.5213e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 8.9214e-04 - val_loss: 1.7541e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 7.8590e-04 - val_loss: 1.7935e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.3989e-04 - val_loss: 5.8906e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 8.1100e-04 - val_loss: 1.3156e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.5024e-04 - val_loss: 1.8337e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 7.0087e-04 - val_loss: 5.5147e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 8.7980e-04 - val_loss: 1.5978e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.8921e-04 - val_loss: 1.9450e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 9.1220e-04 - val_loss: 6.7608e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.5506e-04 - val_loss: 1.3208e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.3568e-04 - val_loss: 1.2157e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.9631e-04 - val_loss: 3.4664e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.1910e-04 - val_loss: 1.3672e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.6129e-04 - val_loss: 2.3304e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.7806e-04 - val_loss: 5.8466e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 8.8526e-04 - val_loss: 5.7248e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.5630e-04 - val_loss: 1.8202e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.5053e-04 - val_loss: 2.1620e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 14s 105ms/step - loss: 7.1707e-04 - val_loss: 1.2191e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.2593e-04 - val_loss: 3.3087e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.3504e-04 - val_loss: 2.9995e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 7.0124e-04 - val_loss: 1.3250e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.3820e-04 - val_loss: 1.1696e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 7.0738e-04 - val_loss: 1.9190e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.3408e-04 - val_loss: 1.3321e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.3549e-04 - val_loss: 1.2788e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.5720e-04 - val_loss: 1.5260e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.6620e-04 - val_loss: 1.1755e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.2371e-04 - val_loss: 2.2620e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.2981e-04 - val_loss: 1.3421e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.6419e-04 - val_loss: 1.9716e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.4865e-04 - val_loss: 2.8061e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.0489e-04 - val_loss: 1.0612e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.1231e-04 - val_loss: 2.1035e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.4578e-04 - val_loss: 1.0790e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.7927e-04 - val_loss: 1.9050e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.9581e-04 - val_loss: 2.5649e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.5321e-04 - val_loss: 1.9682e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.6577e-04 - val_loss: 1.1857e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.8860e-04 - val_loss: 1.1598e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.2230e-04 - val_loss: 2.0251e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.1484e-04 - val_loss: 3.7684e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 5.7986e-04 - val_loss: 1.5645e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 5.5214e-04 - val_loss: 1.8269e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.4982e-04 - val_loss: 1.3679e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 6.2613e-04 - val_loss: 1.8696e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 5.5682e-04 - val_loss: 1.5139e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.5350e-04 - val_loss: 3.4584e-04\n",
      "8/8 [==============================] - 4s 49ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 41.7271949821912\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 31s 134ms/step - loss: 0.0076 - val_loss: 4.9033e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 122ms/step - loss: 0.0033 - val_loss: 3.8975e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 0.0018 - val_loss: 4.7200e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 0.0021 - val_loss: 8.1840e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 0.0013 - val_loss: 9.0964e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.0013 - val_loss: 2.2807e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 0.0011 - val_loss: 2.1806e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 9.0126e-04 - val_loss: 1.6599e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.7502e-04 - val_loss: 2.2249e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 7.5159e-04 - val_loss: 1.5835e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 7.7122e-04 - val_loss: 1.2373e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 8.2999e-04 - val_loss: 1.2711e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 9.5292e-04 - val_loss: 2.1400e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.4206e-04 - val_loss: 1.3215e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.6280e-04 - val_loss: 2.1901e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 7.7045e-04 - val_loss: 1.2196e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 7.5272e-04 - val_loss: 1.1950e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.9993e-04 - val_loss: 2.8200e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 8.1188e-04 - val_loss: 2.0591e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 7.2902e-04 - val_loss: 1.3018e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 8.2536e-04 - val_loss: 2.0896e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.4347e-04 - val_loss: 1.7971e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 8.2430e-04 - val_loss: 2.5437e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 7.6124e-04 - val_loss: 1.4184e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 6.2172e-04 - val_loss: 2.7755e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.4980e-04 - val_loss: 2.0759e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.6741e-04 - val_loss: 1.2470e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.7299e-04 - val_loss: 1.0805e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 7.2268e-04 - val_loss: 4.2414e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.5512e-04 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 7.8377e-04 - val_loss: 1.4580e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.3522e-04 - val_loss: 1.6472e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 6.4682e-04 - val_loss: 3.1056e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 5.7438e-04 - val_loss: 1.1353e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.3036e-04 - val_loss: 1.7032e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.9345e-04 - val_loss: 1.1056e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.4626e-04 - val_loss: 1.1979e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.8495e-04 - val_loss: 1.0651e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.0401e-04 - val_loss: 1.2573e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 14s 107ms/step - loss: 7.7887e-04 - val_loss: 1.3442e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 7.0003e-04 - val_loss: 1.9560e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.8618e-04 - val_loss: 1.1454e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 6.1274e-04 - val_loss: 1.0778e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 6.7405e-04 - val_loss: 1.7663e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.0477e-04 - val_loss: 1.0769e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 6.4708e-04 - val_loss: 1.2303e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.0710e-04 - val_loss: 1.0881e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 7.6618e-04 - val_loss: 2.2410e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.5941e-04 - val_loss: 1.1726e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.3847e-04 - val_loss: 1.0836e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 14s 110ms/step - loss: 5.5806e-04 - val_loss: 1.1316e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 5.8133e-04 - val_loss: 1.0839e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 6.0378e-04 - val_loss: 3.2552e-04\n",
      "8/8 [==============================] - 4s 66ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 42.13402251501234\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 42s 175ms/step - loss: 0.0123 - val_loss: 0.0015\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0031 - val_loss: 6.9434e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 19s 148ms/step - loss: 0.0022 - val_loss: 3.8572e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0018 - val_loss: 3.2298e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 0.0017 - val_loss: 3.8462e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0014 - val_loss: 2.7536e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 0.0015 - val_loss: 7.0792e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 0.0011 - val_loss: 1.9282e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 8.8217e-04 - val_loss: 2.7748e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 0.0014 - val_loss: 1.6907e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 9.4635e-04 - val_loss: 1.5032e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 7.2053e-04 - val_loss: 1.3674e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 7.1069e-04 - val_loss: 1.3340e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 7.9954e-04 - val_loss: 1.3235e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 0.0012 - val_loss: 5.0923e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 7.5536e-04 - val_loss: 1.4858e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 8.7854e-04 - val_loss: 2.4167e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 9.6042e-04 - val_loss: 1.4405e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 8.2554e-04 - val_loss: 1.2306e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 7.2122e-04 - val_loss: 1.2607e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.6941e-04 - val_loss: 2.4022e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.9081e-04 - val_loss: 3.9335e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 7.4890e-04 - val_loss: 4.5336e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.0003e-04 - val_loss: 1.1634e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.3578e-04 - val_loss: 1.9409e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 8.0115e-04 - val_loss: 2.1467e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 6.1632e-04 - val_loss: 1.2532e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 7.3146e-04 - val_loss: 1.3573e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 8.4232e-04 - val_loss: 1.2076e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 7.7758e-04 - val_loss: 1.2164e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.7593e-04 - val_loss: 1.7584e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 7.1305e-04 - val_loss: 4.2092e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.5028e-04 - val_loss: 1.1411e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.5883e-04 - val_loss: 1.1641e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 7.5516e-04 - val_loss: 1.5221e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.4248e-04 - val_loss: 1.5973e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.1180e-04 - val_loss: 3.2297e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 5.9506e-04 - val_loss: 1.1846e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.2438e-04 - val_loss: 1.5000e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.7199e-04 - val_loss: 1.1485e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.9188e-04 - val_loss: 1.2877e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.2215e-04 - val_loss: 1.3006e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.5791e-04 - val_loss: 2.1592e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.8693e-04 - val_loss: 1.4710e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.0150e-04 - val_loss: 1.0644e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 8.3110e-04 - val_loss: 2.0686e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.4100e-04 - val_loss: 2.5034e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 7.2352e-04 - val_loss: 2.0178e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.1035e-04 - val_loss: 1.0846e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 7.6397e-04 - val_loss: 1.1481e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.3847e-04 - val_loss: 1.3390e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 19s 146ms/step - loss: 6.1548e-04 - val_loss: 2.4531e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.7236e-04 - val_loss: 1.5804e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 6.6091e-04 - val_loss: 1.9352e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 6.4471e-04 - val_loss: 1.5975e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 5.7317e-04 - val_loss: 1.2072e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.1205e-04 - val_loss: 3.2184e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 7.1882e-04 - val_loss: 3.2009e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 7.6586e-04 - val_loss: 1.4318e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 5.5898e-04 - val_loss: 1.5298e-04\n",
      "8/8 [==============================] - 6s 83ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 42.13246490579221\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=50, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 39s 149ms/step - loss: 0.0088 - val_loss: 5.4414e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 16s 119ms/step - loss: 0.0039 - val_loss: 6.7459e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.0029 - val_loss: 5.7842e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 0.0021 - val_loss: 3.9952e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0019 - val_loss: 5.4132e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.0014 - val_loss: 4.7134e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.0012 - val_loss: 2.6702e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 0.0010 - val_loss: 4.1064e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.0010 - val_loss: 4.0058e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 0.0011 - val_loss: 4.5554e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 9.0983e-04 - val_loss: 2.5603e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 9.1486e-04 - val_loss: 2.1323e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 9.0066e-04 - val_loss: 1.7640e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 8.6184e-04 - val_loss: 2.9449e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.4293e-04 - val_loss: 1.2896e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.5816e-04 - val_loss: 3.6017e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.5758e-04 - val_loss: 1.7022e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.1202e-04 - val_loss: 1.7647e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.4123e-04 - val_loss: 1.3634e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 9.0380e-04 - val_loss: 1.2761e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.1564e-04 - val_loss: 3.7999e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 8.4462e-04 - val_loss: 2.5324e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 16s 117ms/step - loss: 8.2333e-04 - val_loss: 6.4474e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.0281e-04 - val_loss: 1.1840e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.6108e-04 - val_loss: 4.9581e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.1171e-04 - val_loss: 1.5425e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0743e-04 - val_loss: 3.0292e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.6105e-04 - val_loss: 2.3305e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0617e-04 - val_loss: 2.9419e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.7883e-04 - val_loss: 1.2758e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.1719e-04 - val_loss: 1.1766e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.7709e-04 - val_loss: 3.0641e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.8232e-04 - val_loss: 1.1155e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 6.6830e-04 - val_loss: 2.8671e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 5.9676e-04 - val_loss: 7.7237e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.9133e-04 - val_loss: 1.3943e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.7814e-04 - val_loss: 3.9878e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.9263e-04 - val_loss: 5.0935e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.4643e-04 - val_loss: 1.2749e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 7.0129e-04 - val_loss: 3.7273e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 5.8134e-04 - val_loss: 1.2131e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 17s 127ms/step - loss: 7.3281e-04 - val_loss: 1.8191e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.1000e-04 - val_loss: 1.7338e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 6.2315e-04 - val_loss: 1.1696e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 6.7959e-04 - val_loss: 1.0198e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.8534e-04 - val_loss: 9.9258e-05\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.6402e-04 - val_loss: 1.6089e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.2347e-04 - val_loss: 1.7625e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.0615e-04 - val_loss: 1.5053e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.4050e-04 - val_loss: 2.8715e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 7.2199e-04 - val_loss: 3.1602e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.6838e-04 - val_loss: 1.5377e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.5546e-04 - val_loss: 4.1932e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.9224e-04 - val_loss: 2.1358e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.8110e-04 - val_loss: 1.9845e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 6.0262e-04 - val_loss: 1.0600e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.8240e-04 - val_loss: 2.0405e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.6989e-04 - val_loss: 9.9180e-05\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.8897e-04 - val_loss: 2.4682e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 6.9925e-04 - val_loss: 1.3269e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.4294e-04 - val_loss: 2.3015e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.4762e-04 - val_loss: 1.1509e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.5629e-04 - val_loss: 2.6105e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 6.6693e-04 - val_loss: 9.8542e-05\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.1298e-04 - val_loss: 2.4489e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.5934e-04 - val_loss: 1.0832e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.7018e-04 - val_loss: 9.8984e-05\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 5.6224e-04 - val_loss: 9.6826e-05\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.1238e-04 - val_loss: 9.8998e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 6.1921e-04 - val_loss: 1.4449e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.2762e-04 - val_loss: 1.3058e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.5123e-04 - val_loss: 1.0127e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.9029e-04 - val_loss: 9.6640e-05\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.4849e-04 - val_loss: 1.6677e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.7389e-04 - val_loss: 7.8657e-04\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 6.0265e-04 - val_loss: 2.2002e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 6.2317e-04 - val_loss: 9.7913e-05\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 5.7725e-04 - val_loss: 2.3168e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 6.2106e-04 - val_loss: 1.5736e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 6.2845e-04 - val_loss: 1.3985e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.5450e-04 - val_loss: 1.5704e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 5.7369e-04 - val_loss: 1.1886e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 6.4801e-04 - val_loss: 1.1412e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 7.2818e-04 - val_loss: 1.9458e-04\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 5.7327e-04 - val_loss: 1.1431e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 15s 118ms/step - loss: 5.6885e-04 - val_loss: 1.0916e-04\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 5.6006e-04 - val_loss: 1.6508e-04\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 5.6005e-04 - val_loss: 1.2973e-04\n",
      "7/7 [==============================] - 5s 60ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.544990784325755\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=50, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 55s 201ms/step - loss: 0.0112 - val_loss: 5.4934e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 21s 159ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 0.0037 - val_loss: 5.5296e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 0.0036 - val_loss: 3.6856e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 0.0021 - val_loss: 8.6205e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 0.0016 - val_loss: 9.0448e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 0.0016 - val_loss: 4.9206e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 21s 163ms/step - loss: 0.0013 - val_loss: 3.2827e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 0.0013 - val_loss: 2.2752e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 0.0011 - val_loss: 1.9585e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 8.3208e-04 - val_loss: 2.8977e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 19s 148ms/step - loss: 8.1870e-04 - val_loss: 3.0020e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 8.9351e-04 - val_loss: 3.0216e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 9.8305e-04 - val_loss: 2.7120e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 9.6733e-04 - val_loss: 3.0274e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 8.4846e-04 - val_loss: 8.0359e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 8.2756e-04 - val_loss: 1.6768e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 8.0263e-04 - val_loss: 1.7608e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 7.4976e-04 - val_loss: 1.2975e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 6.7328e-04 - val_loss: 1.5965e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 7.3543e-04 - val_loss: 8.2541e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 6.8431e-04 - val_loss: 3.5963e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 8.4768e-04 - val_loss: 2.3658e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 7.2882e-04 - val_loss: 1.1499e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 20s 148ms/step - loss: 6.9800e-04 - val_loss: 2.4163e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 6.7521e-04 - val_loss: 8.0070e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 19s 147ms/step - loss: 7.3611e-04 - val_loss: 1.4138e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.8822e-04 - val_loss: 1.3047e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 8.0367e-04 - val_loss: 0.0016\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 9.0993e-04 - val_loss: 1.2179e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.2466e-04 - val_loss: 2.8850e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.6353e-04 - val_loss: 1.0619e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.7853e-04 - val_loss: 1.5186e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 8.0224e-04 - val_loss: 1.0608e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.9729e-04 - val_loss: 1.7730e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.0514e-04 - val_loss: 1.1159e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 7.8381e-04 - val_loss: 3.7334e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 5.8362e-04 - val_loss: 1.1479e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.5522e-04 - val_loss: 1.1372e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 6.4415e-04 - val_loss: 1.0507e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 7.3014e-04 - val_loss: 2.1330e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.3895e-04 - val_loss: 2.4990e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 8.1078e-04 - val_loss: 2.1131e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.0669e-04 - val_loss: 9.8154e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 7.0567e-04 - val_loss: 1.1094e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.2250e-04 - val_loss: 6.6152e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 7.7734e-04 - val_loss: 1.0443e-04\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 5.9727e-04 - val_loss: 1.3504e-04\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 5.5700e-04 - val_loss: 1.0873e-04\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.6508e-04 - val_loss: 5.6065e-04\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 6.2610e-04 - val_loss: 1.2290e-04\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 19s 144ms/step - loss: 6.8865e-04 - val_loss: 1.0626e-04\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 5.6676e-04 - val_loss: 1.5615e-04\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.8368e-04 - val_loss: 2.3491e-04\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.0415e-04 - val_loss: 2.3331e-04\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.1205e-04 - val_loss: 1.5737e-04\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 5.8692e-04 - val_loss: 2.8003e-04\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 8.0999e-04 - val_loss: 1.0002e-04\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.9867e-04 - val_loss: 1.6233e-04\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 6.4383e-04 - val_loss: 4.0357e-04\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.7577e-04 - val_loss: 1.3594e-04\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.1114e-04 - val_loss: 1.1521e-04\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 5.9369e-04 - val_loss: 6.9780e-04\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 6.0732e-04 - val_loss: 1.1193e-04\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.4229e-04 - val_loss: 1.1170e-04\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.1554e-04 - val_loss: 1.6845e-04\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 5.4875e-04 - val_loss: 1.0499e-04\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.6770e-04 - val_loss: 2.3447e-04\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.9160e-04 - val_loss: 1.0726e-04\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 5.7530e-04 - val_loss: 1.1465e-04\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 5.8293e-04 - val_loss: 1.6030e-04\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.0596e-04 - val_loss: 5.0192e-04\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 5.9149e-04 - val_loss: 9.7468e-05\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.4148e-04 - val_loss: 1.0631e-04\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 6.0415e-04 - val_loss: 1.5272e-04\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.7485e-04 - val_loss: 2.5287e-04\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 5.9831e-04 - val_loss: 1.6921e-04\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.5986e-04 - val_loss: 1.7952e-04\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.8855e-04 - val_loss: 1.1688e-04\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 5.8544e-04 - val_loss: 1.7643e-04\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 6.8114e-04 - val_loss: 2.1630e-04\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 6.3830e-04 - val_loss: 1.0687e-04\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 6.1562e-04 - val_loss: 3.8658e-04\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 5.9954e-04 - val_loss: 1.2302e-04\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 19s 140ms/step - loss: 5.3422e-04 - val_loss: 1.0074e-04\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 5.9579e-04 - val_loss: 1.6967e-04\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.3317e-04 - val_loss: 1.5785e-04\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.7946e-04 - val_loss: 1.0677e-04\n",
      "7/7 [==============================] - 4s 63ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.330449753474234\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=100, layers=2\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 35s 163ms/step - loss: 0.0066 - val_loss: 0.0016\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0021 - val_loss: 3.5901e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 0.0021 - val_loss: 2.8763e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0012 - val_loss: 5.0749e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0012 - val_loss: 8.4294e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 0.0013 - val_loss: 2.2030e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 9.9682e-04 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 0.0012 - val_loss: 9.1773e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 8.2740e-04 - val_loss: 1.7557e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.4249e-04 - val_loss: 5.2421e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 8.0523e-04 - val_loss: 2.1181e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.9048e-04 - val_loss: 1.8343e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.9241e-04 - val_loss: 3.3041e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 7.4173e-04 - val_loss: 1.0698e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 6.3415e-04 - val_loss: 1.1391e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 7.8616e-04 - val_loss: 1.5331e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 6.6111e-04 - val_loss: 6.2819e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 7.8445e-04 - val_loss: 1.1203e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 7.9777e-04 - val_loss: 2.5808e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 8.1939e-04 - val_loss: 1.5094e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.3109e-04 - val_loss: 2.4601e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 5.8905e-04 - val_loss: 5.3157e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 7.5951e-04 - val_loss: 1.0799e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.5011e-04 - val_loss: 1.4234e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.2274e-04 - val_loss: 2.3879e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.7542e-04 - val_loss: 1.0988e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.4943e-04 - val_loss: 4.3603e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 7.6624e-04 - val_loss: 1.0222e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 6.7317e-04 - val_loss: 1.0174e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 7.1880e-04 - val_loss: 1.0142e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.2602e-04 - val_loss: 3.7352e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.2275e-04 - val_loss: 1.6737e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 5.9296e-04 - val_loss: 2.0016e-04\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.4688e-04 - val_loss: 1.4039e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 6.1611e-04 - val_loss: 1.7320e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 19s 141ms/step - loss: 6.6809e-04 - val_loss: 1.0656e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.4337e-04 - val_loss: 2.4409e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 5.9549e-04 - val_loss: 2.9280e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.0369e-04 - val_loss: 2.3862e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 7.0960e-04 - val_loss: 4.1645e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 18s 140ms/step - loss: 6.1909e-04 - val_loss: 1.7646e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 5.9179e-04 - val_loss: 1.1094e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 8.0327e-04 - val_loss: 2.7230e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 6.6614e-04 - val_loss: 2.1018e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 6.5612e-04 - val_loss: 1.1342e-04\n",
      "7/7 [==============================] - 3s 85ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.2970180452656\n",
      "Training model with epochs=100, batch_size=8, sequence_length=80, units=100, layers=3\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 45s 205ms/step - loss: 0.0110 - val_loss: 0.0014\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 25s 189ms/step - loss: 0.0037 - val_loss: 5.6350e-04\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 0.0028 - val_loss: 6.2226e-04\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 0.0022 - val_loss: 3.6313e-04\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 0.0019 - val_loss: 2.9163e-04\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 0.0016 - val_loss: 2.4196e-04\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 0.0017 - val_loss: 2.0268e-04\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 0.0013 - val_loss: 3.4084e-04\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 0.0010 - val_loss: 5.0379e-04\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 7.9387e-04 - val_loss: 1.6319e-04\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 8.5454e-04 - val_loss: 3.2504e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 0.0013 - val_loss: 4.9847e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 7.0611e-04 - val_loss: 6.8723e-04\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 20s 149ms/step - loss: 8.1729e-04 - val_loss: 4.5636e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 25s 187ms/step - loss: 9.0736e-04 - val_loss: 1.7216e-04\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 6.7558e-04 - val_loss: 1.5331e-04\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 9.8394e-04 - val_loss: 4.3638e-04\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 6.7092e-04 - val_loss: 6.4087e-04\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.4347e-04 - val_loss: 8.9946e-04\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 9.3960e-04 - val_loss: 2.3145e-04\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 26s 200ms/step - loss: 7.2283e-04 - val_loss: 1.1474e-04\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 7.7591e-04 - val_loss: 5.7278e-04\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.2300e-04 - val_loss: 1.4598e-04\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 27s 204ms/step - loss: 6.4161e-04 - val_loss: 2.2002e-04\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 27s 204ms/step - loss: 7.3660e-04 - val_loss: 2.7777e-04\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 26s 198ms/step - loss: 7.2066e-04 - val_loss: 2.4877e-04\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 6.6555e-04 - val_loss: 2.3353e-04\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 6.9620e-04 - val_loss: 1.5319e-04\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 8.4997e-04 - val_loss: 1.1929e-04\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 7.6223e-04 - val_loss: 3.8831e-04\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 8.5121e-04 - val_loss: 1.2956e-04\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 26s 198ms/step - loss: 7.2679e-04 - val_loss: 1.1016e-04\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 7.0457e-04 - val_loss: 1.7616e-04\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 26s 198ms/step - loss: 6.1380e-04 - val_loss: 9.8662e-05\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 6.9543e-04 - val_loss: 2.4059e-04\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 26s 198ms/step - loss: 6.8874e-04 - val_loss: 3.9065e-04\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 6.5471e-04 - val_loss: 1.4715e-04\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.6661e-04 - val_loss: 1.1500e-04\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 7.6464e-04 - val_loss: 1.3699e-04\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 26s 193ms/step - loss: 6.9991e-04 - val_loss: 1.4884e-04\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 7.6926e-04 - val_loss: 1.0946e-04\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 26s 199ms/step - loss: 5.7545e-04 - val_loss: 2.1930e-04\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 8.3883e-04 - val_loss: 1.7143e-04\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 26s 198ms/step - loss: 7.3572e-04 - val_loss: 1.0777e-04\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 6.3001e-04 - val_loss: 1.2726e-04\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 8.3569e-04 - val_loss: 3.4856e-04\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 26s 195ms/step - loss: 6.6623e-04 - val_loss: 1.0471e-04\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 5.9629e-04 - val_loss: 1.1383e-04\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 6.7469e-04 - val_loss: 1.2788e-04\n",
      "7/7 [==============================] - 6s 113ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 43.30469576190282\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c10902-6513-4100-b09b-cac85b463d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 127.08885006285385}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 45.149463312730155}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 43.78698928385512}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 46.17269548700949}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 44.61902077438216}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 42.83370651158674}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 43.922054015168726}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 42.36064631238659}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 43.41727548299754}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 89.57664520503046}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 43.189416870304264}\n",
      "{'epochs': 50, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 43.92782993688304}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 43.46898365092455}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 90.68968577808018}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 44.58013672902477}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 43.05279609388185}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 45.579428860432095}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 63.630720383265526}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 70.5843426202368}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 50.33769931967402}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 44.64454728631389}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 80.20947177632961}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 43.42932310246256}\n",
      "{'epochs': 50, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 43.96913620605502}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 43.72000917897652}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 44.44097840808724}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 43.51334731758593}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 48.22224832285934}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 41.842530369843004}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 43.363938738643185}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 43.50087487804098}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 44.54977028356625}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 49.42263573652664}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 43.55542719675214}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 42.89021057975056}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 48.43075830712718}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 44.39591812961605}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 43.66343528559608}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 43.18884430681221}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 43.336231340258315}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 41.52144267662495}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 41.7271949821912}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 42.13402251501234}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 42.13246490579221}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 2, 'rmse': 43.544990784325755}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 50, 'layers': 3, 'rmse': 43.330449753474234}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 2, 'rmse': 43.2970180452656}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 80, 'units': 100, 'layers': 3, 'rmse': 43.30469576190282}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875e4df-1a2f-4f01-9b3e-da7ebfdcca3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
