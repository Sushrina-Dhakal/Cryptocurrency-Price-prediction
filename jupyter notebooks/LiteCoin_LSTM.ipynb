{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1432acdd-fe41-49e2-9392-eb3564c999e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4451aadd-536e-4dd8-9120-305fdcab8a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9834614-0a3c-49b0-86a6-45fc273a7f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_rmse = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bc83a9-26f2-4b39-9b3f-8bb8e951a00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, start_date, end_date):\n",
    "    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0cad1d0-7b85-4498-8f35-add118bd1381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, sequence_length):\n",
    "    data = df.filter(['Close'])\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "    \n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45f36f8-aa6b-4af2-a7c1-6e3229153f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lstm_model(X_train, units=50, layers=2, activation='tanh', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(LSTM(units*2))\n",
    "    model.add(Dense(25, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510a363b-1bbf-4d89-b5e0-8ffc5efa7965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers):\n",
    "    \n",
    "    global final_rmse\n",
    "    \n",
    "    loss_history = keras.callbacks.History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'model_{epochs}_{batch_size}_{sequence_length}_{units}_{layers}.h5', monitor='val_loss', save_best_only=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping, model_checkpoint, loss_history])\n",
    "\n",
    "    lstm_loss_history = loss_history.history['loss']\n",
    "    \n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    print(f\"Root Mean Squared Error (Testing Dataset): {rmse}\")\n",
    "    \n",
    "    if rmse <= final_rmse:\n",
    "        final_rmse = rmse\n",
    "        joblib.dump(model, \"LTC_model_lstm.pkl\")\n",
    "        plt.plot(y_test, label='Actual')\n",
    "        plt.plot(lstm_predictions, label='Predicted')\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'Plot_actualvspredicted/LTC_actual_vs_predicted.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(loss_history.history['loss'], label='Training Loss')\n",
    "        plt.plot(loss_history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Epoch Loss Curve')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'loss_curve/LTC_loss_curve.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b0263b-6f23-4faa-a55b-effd03aff6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbol = 'LTC-USD'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2f3696-808a-4776-aed2-03b721ea96da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_range = [100]\n",
    "batch_sizes = [4,8]\n",
    "sequence_lengths = [25,60]\n",
    "units_range = [50, 100]\n",
    "layers_range = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee08104-0187-41c2-9c8c-b8976df87d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = download_data(symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199aede7-2e2d-463c-9ffb-08158fdf5682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea07d2d-9bf4-48fd-823e-56689cb1a583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=2\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "268/268 [==============================] - 17s 33ms/step - loss: 0.0076 - val_loss: 3.1342e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 7s - loss: 0.0039    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0026 - val_loss: 5.0144e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0017 - val_loss: 1.9104e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0014 - val_loss: 2.2305e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 0.0011 - val_loss: 1.4564e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0011 - val_loss: 7.4196e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0011 - val_loss: 1.9088e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 9.7079e-04 - val_loss: 1.2579e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0010 - val_loss: 1.6111e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 10s 35ms/step - loss: 9.0776e-04 - val_loss: 1.0566e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 9.7093e-04 - val_loss: 1.9110e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.9413e-04 - val_loss: 1.3996e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 8.4147e-04 - val_loss: 1.0071e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.8007e-04 - val_loss: 1.1927e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4447e-04 - val_loss: 1.0395e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.3343e-04 - val_loss: 1.0779e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.7881e-04 - val_loss: 7.5545e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.4479e-04 - val_loss: 2.0299e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.3932e-04 - val_loss: 1.2878e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.7471e-04 - val_loss: 7.3575e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 7.6967e-04 - val_loss: 1.4465e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.2607e-04 - val_loss: 1.3295e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 7.8364e-04 - val_loss: 8.5966e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 6.8221e-04 - val_loss: 8.1876e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.8490e-04 - val_loss: 9.0934e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 8.3006e-04 - val_loss: 1.6027e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 6.7380e-04 - val_loss: 1.4037e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.7637e-04 - val_loss: 8.2727e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 6.8206e-04 - val_loss: 2.8922e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.5965e-04 - val_loss: 2.0394e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 6.5386e-04 - val_loss: 1.0898e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.2612e-04 - val_loss: 9.4763e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 7.1463e-04 - val_loss: 1.4691e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.0925e-04 - val_loss: 7.8894e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 6.6196e-04 - val_loss: 2.4248e-04\n",
      "9/9 [==============================] - 3s 21ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.5649441456419657\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 27s 57ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 11s 41ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 0.0024 - val_loss: 2.2720e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0019 - val_loss: 2.1134e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0014 - val_loss: 1.8478e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0014 - val_loss: 1.6471e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0011 - val_loss: 6.3752e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.0011 - val_loss: 5.3976e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.5000e-04 - val_loss: 2.3830e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 0.0011 - val_loss: 1.4895e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 14s 53ms/step - loss: 8.6958e-04 - val_loss: 2.8194e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 14s 54ms/step - loss: 9.1435e-04 - val_loss: 1.4444e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 9.2346e-04 - val_loss: 5.1212e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 9.1108e-04 - val_loss: 1.1303e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 15s 56ms/step - loss: 8.8374e-04 - val_loss: 1.2266e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 43ms/step - loss: 8.0842e-04 - val_loss: 1.0525e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 9.0522e-04 - val_loss: 9.2738e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.6756e-04 - val_loss: 1.2485e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.0561e-04 - val_loss: 8.9925e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0010 - val_loss: 1.0365e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 8.4834e-04 - val_loss: 7.7901e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.9374e-04 - val_loss: 9.0608e-05\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.4970e-04 - val_loss: 7.7022e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.8510e-04 - val_loss: 1.4419e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.0938e-04 - val_loss: 1.1569e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.8421e-04 - val_loss: 1.3555e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.5219e-04 - val_loss: 3.7782e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.7024e-04 - val_loss: 1.0174e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.0656e-04 - val_loss: 1.2313e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4419e-04 - val_loss: 1.0328e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.7747e-04 - val_loss: 7.7188e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4187e-04 - val_loss: 2.0509e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.3677e-04 - val_loss: 7.8760e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.6348e-04 - val_loss: 1.3576e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.4868e-04 - val_loss: 1.1532e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.8652e-04 - val_loss: 4.6703e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.1574e-04 - val_loss: 3.6948e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.4740e-04 - val_loss: 9.0335e-05\n",
      "9/9 [==============================] - 3s 18ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.2605241961169904\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 17s 37ms/step - loss: 0.0045 - val_loss: 2.6681e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 8s - loss: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0017 - val_loss: 2.0078e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.0016 - val_loss: 2.0932e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 0.0013 - val_loss: 2.3272e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 0.0011 - val_loss: 1.3083e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 9.2697e-04 - val_loss: 3.8516e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 9.4695e-04 - val_loss: 1.3964e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 8.4808e-04 - val_loss: 6.2356e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 8.5451e-04 - val_loss: 1.7368e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0010 - val_loss: 1.0301e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.0610e-04 - val_loss: 1.2848e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.5375e-04 - val_loss: 7.6114e-05\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.5739e-04 - val_loss: 7.7565e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.0217e-04 - val_loss: 1.4690e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.8192e-04 - val_loss: 9.8174e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.8362e-04 - val_loss: 1.8357e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 8.9478e-04 - val_loss: 2.1970e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 8.4121e-04 - val_loss: 9.5568e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 6.7434e-04 - val_loss: 1.1010e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.8725e-04 - val_loss: 2.8024e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 8.1240e-04 - val_loss: 1.4952e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 7.9814e-04 - val_loss: 9.3235e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 7.2204e-04 - val_loss: 2.0765e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 7.6572e-04 - val_loss: 1.5244e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 9.1041e-04 - val_loss: 1.8296e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 6.8733e-04 - val_loss: 1.4566e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 7.8222e-04 - val_loss: 8.1033e-05\n",
      "9/9 [==============================] - 2s 22ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.745883073945297\n",
      "Training model with epochs=100, batch_size=4, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 23s 48ms/step - loss: 0.0077 - val_loss: 5.1864e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 11s - loss: 0.0144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 12s 45ms/step - loss: 0.0034 - val_loss: 2.1407e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0021 - val_loss: 2.5217e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0017 - val_loss: 1.4711e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0013 - val_loss: 4.6162e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0014 - val_loss: 1.2080e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.0013 - val_loss: 1.3952e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 6.4446e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.7817e-04 - val_loss: 9.0763e-05\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 9.8028e-04 - val_loss: 9.0635e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 9.3411e-04 - val_loss: 3.0033e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 15s 55ms/step - loss: 9.2495e-04 - val_loss: 1.3241e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 7.9874e-04 - val_loss: 1.5833e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 9.7289e-04 - val_loss: 1.5095e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.0236e-04 - val_loss: 1.8969e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 9.0788e-04 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 0.0012 - val_loss: 9.3771e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.5992e-04 - val_loss: 8.5249e-05\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 11s 39ms/step - loss: 7.7843e-04 - val_loss: 1.8303e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.2618e-04 - val_loss: 9.9070e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 12s 45ms/step - loss: 6.8898e-04 - val_loss: 1.4268e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 11s 42ms/step - loss: 8.3424e-04 - val_loss: 8.2974e-05\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.1977e-04 - val_loss: 1.5214e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.2800e-04 - val_loss: 0.0010\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 9.2118e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 8.2068e-04 - val_loss: 8.3835e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.2161e-04 - val_loss: 2.3219e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 8.7319e-04 - val_loss: 2.4763e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.8987e-04 - val_loss: 7.4090e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 11s 41ms/step - loss: 6.7717e-04 - val_loss: 8.1798e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 12s 43ms/step - loss: 8.4083e-04 - val_loss: 9.3691e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.7842e-04 - val_loss: 9.8625e-05\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.3783e-04 - val_loss: 1.2182e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.1822e-04 - val_loss: 2.1784e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.5863e-04 - val_loss: 8.7907e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 6.6084e-04 - val_loss: 1.0635e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 8.3799e-04 - val_loss: 1.0173e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 6.7760e-04 - val_loss: 1.0571e-04\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.2675e-04 - val_loss: 1.1802e-04\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.4089e-04 - val_loss: 3.9581e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.7188e-04 - val_loss: 2.9344e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 7.7093e-04 - val_loss: 1.6281e-04\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 7.7511e-04 - val_loss: 1.5808e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 7.1699e-04 - val_loss: 1.2649e-04\n",
      "9/9 [==============================] - 3s 31ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.1647649199138193\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 22s 56ms/step - loss: 0.0053 - val_loss: 7.4306e-04\n",
      "Epoch 2/100\n",
      "  3/268 [..............................] - ETA: 12s - loss: 0.0011    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 13s 50ms/step - loss: 0.0022 - val_loss: 2.0044e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0017 - val_loss: 2.6963e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 0.0015 - val_loss: 7.4333e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0014 - val_loss: 1.7016e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.0012 - val_loss: 2.0589e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 14s 50ms/step - loss: 9.1986e-04 - val_loss: 1.2017e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 9.5813e-04 - val_loss: 1.7835e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 9.7235e-04 - val_loss: 7.7788e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 8.9944e-04 - val_loss: 2.1729e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.7149e-04 - val_loss: 2.0881e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 8.1076e-04 - val_loss: 1.8798e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 9.3303e-04 - val_loss: 2.2060e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.6831e-04 - val_loss: 2.5237e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.7117e-04 - val_loss: 8.8787e-05\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.9464e-04 - val_loss: 1.6281e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.6827e-04 - val_loss: 4.0850e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.1478e-04 - val_loss: 3.3711e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 6.9866e-04 - val_loss: 2.0853e-04\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.1716e-04 - val_loss: 7.9057e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 8.1435e-04 - val_loss: 1.9987e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.1083e-04 - val_loss: 7.7749e-05\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.7340e-04 - val_loss: 2.1459e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.1852e-04 - val_loss: 1.4279e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.3580e-04 - val_loss: 8.9976e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.1298e-04 - val_loss: 9.1429e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.8431e-04 - val_loss: 9.5413e-05\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.9189e-04 - val_loss: 8.5825e-05\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 8.4029e-04 - val_loss: 2.1937e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.2313e-04 - val_loss: 3.0659e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 7.9547e-04 - val_loss: 1.1057e-04\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 7.2891e-04 - val_loss: 1.0437e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 7.2643e-04 - val_loss: 7.6422e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 14s 51ms/step - loss: 7.0191e-04 - val_loss: 3.8278e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 8.2476e-04 - val_loss: 8.1795e-05\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 6.8822e-04 - val_loss: 3.3985e-04\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.0986e-04 - val_loss: 2.4402e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.5024e-04 - val_loss: 8.6030e-05\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.7868e-04 - val_loss: 8.3418e-05\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 7.1557e-04 - val_loss: 9.3369e-05\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 13s 50ms/step - loss: 6.5441e-04 - val_loss: 1.3505e-04\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 13s 49ms/step - loss: 6.3904e-04 - val_loss: 8.5803e-05\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.4783e-04 - val_loss: 1.0425e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.5149e-04 - val_loss: 1.1737e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.9184e-04 - val_loss: 1.6660e-04\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.5101e-04 - val_loss: 1.0226e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.6377e-04 - val_loss: 4.2080e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 6.0719e-04 - val_loss: 9.6981e-05\n",
      "8/8 [==============================] - 2s 29ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.109352861503208\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 29s 72ms/step - loss: 0.0065 - val_loss: 2.8714e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 19s - loss: 0.0066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 16s 61ms/step - loss: 0.0032 - val_loss: 3.2949e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0025 - val_loss: 2.2089e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0017 - val_loss: 3.2882e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0016 - val_loss: 1.7883e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0012 - val_loss: 3.8419e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0011 - val_loss: 1.4788e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.0010 - val_loss: 1.6253e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.0013 - val_loss: 6.2458e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0010 - val_loss: 1.5284e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 8.1494e-04 - val_loss: 1.2472e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 8.0718e-04 - val_loss: 1.0757e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 8.2776e-04 - val_loss: 1.0585e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 8.4044e-04 - val_loss: 1.6456e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 8.3840e-04 - val_loss: 3.0080e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.0010 - val_loss: 1.0023e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0011 - val_loss: 1.2158e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.6492e-04 - val_loss: 1.0003e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 7.2722e-04 - val_loss: 9.6794e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 9.1004e-04 - val_loss: 1.3147e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 8.3268e-04 - val_loss: 1.6789e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 8.8973e-04 - val_loss: 3.5485e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 7.2656e-04 - val_loss: 2.2233e-04\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 8.0366e-04 - val_loss: 8.5898e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 6.8808e-04 - val_loss: 9.4239e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 7.4549e-04 - val_loss: 9.6314e-05\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 7.8236e-04 - val_loss: 4.1443e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.7273e-04 - val_loss: 1.0712e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 7.3071e-04 - val_loss: 9.8621e-05\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 6.3791e-04 - val_loss: 7.7413e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 8.3720e-04 - val_loss: 8.7442e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 7.0963e-04 - val_loss: 2.5863e-04\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 8.5052e-04 - val_loss: 9.4899e-05\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.2915e-04 - val_loss: 1.9794e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 7.6239e-04 - val_loss: 3.6407e-04\n",
      "Epoch 36/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 8.4143e-04 - val_loss: 9.2496e-05\n",
      "Epoch 37/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.0891e-04 - val_loss: 1.0133e-04\n",
      "Epoch 38/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 6.2935e-04 - val_loss: 7.4134e-05\n",
      "Epoch 39/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 7.1536e-04 - val_loss: 9.8681e-05\n",
      "Epoch 40/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 6.7402e-04 - val_loss: 2.6025e-04\n",
      "Epoch 41/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.6185e-04 - val_loss: 9.6051e-05\n",
      "Epoch 42/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 7.9498e-04 - val_loss: 8.5245e-05\n",
      "Epoch 43/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 6.7700e-04 - val_loss: 3.1581e-04\n",
      "Epoch 44/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 7.0000e-04 - val_loss: 1.1709e-04\n",
      "Epoch 45/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.8227e-04 - val_loss: 9.8185e-05\n",
      "Epoch 46/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 7.1745e-04 - val_loss: 1.0426e-04\n",
      "Epoch 47/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 6.7018e-04 - val_loss: 1.8484e-04\n",
      "Epoch 48/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 6.1962e-04 - val_loss: 8.3754e-05\n",
      "Epoch 49/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.1328e-04 - val_loss: 8.8552e-05\n",
      "Epoch 50/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.4562e-04 - val_loss: 1.3500e-04\n",
      "Epoch 51/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 8.2878e-04 - val_loss: 9.6188e-05\n",
      "Epoch 52/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.8323e-04 - val_loss: 8.5556e-05\n",
      "Epoch 53/100\n",
      "268/268 [==============================] - 16s 61ms/step - loss: 6.5420e-04 - val_loss: 8.7289e-05\n",
      "8/8 [==============================] - 3s 37ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.1380105579063278\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 25s 68ms/step - loss: 0.0051 - val_loss: 8.7328e-04\n",
      "Epoch 2/100\n",
      "  2/268 [..............................] - ETA: 15s - loss: 9.6734e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 16s 62ms/step - loss: 0.0019 - val_loss: 5.0704e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.0014 - val_loss: 2.1405e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.0013 - val_loss: 1.3936e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.0011 - val_loss: 1.5460e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 0.0011 - val_loss: 1.2338e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 9.3589e-04 - val_loss: 6.4808e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.3084e-04 - val_loss: 7.5173e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 19s 71ms/step - loss: 8.3990e-04 - val_loss: 2.2449e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 9.3902e-04 - val_loss: 9.4335e-05\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 8.9595e-04 - val_loss: 1.6586e-04\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 8.9940e-04 - val_loss: 1.5399e-04\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 8.4547e-04 - val_loss: 2.1114e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 9.5691e-04 - val_loss: 1.5737e-04\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 6.8477e-04 - val_loss: 1.2076e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 9.1498e-04 - val_loss: 1.2853e-04\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 9.3713e-04 - val_loss: 1.6185e-04\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 8.0516e-04 - val_loss: 2.9204e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.7840e-04 - val_loss: 8.2992e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 6.9138e-04 - val_loss: 7.4749e-05\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 8.8298e-04 - val_loss: 8.3153e-05\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 19s 69ms/step - loss: 7.7176e-04 - val_loss: 2.8578e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 7.0764e-04 - val_loss: 8.2222e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 19s 69ms/step - loss: 8.4719e-04 - val_loss: 9.6204e-05\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 19s 72ms/step - loss: 7.5330e-04 - val_loss: 8.6932e-05\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.4966e-04 - val_loss: 1.6172e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 7.1597e-04 - val_loss: 8.4783e-05\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.6053e-04 - val_loss: 1.1525e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 7.7598e-04 - val_loss: 2.2330e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 6.9841e-04 - val_loss: 7.8557e-05\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 19s 69ms/step - loss: 7.8510e-04 - val_loss: 9.4823e-05\n",
      "Epoch 32/100\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 6.9761e-04 - val_loss: 8.6252e-05\n",
      "Epoch 33/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 7.0706e-04 - val_loss: 4.5644e-04\n",
      "Epoch 34/100\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 6.6524e-04 - val_loss: 1.5162e-04\n",
      "Epoch 35/100\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 6.9573e-04 - val_loss: 1.7087e-04\n",
      "8/8 [==============================] - 2s 51ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.48492639562897\n",
      "Training model with epochs=100, batch_size=4, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "268/268 [==============================] - 35s 95ms/step - loss: 0.0076 - val_loss: 2.3185e-04\n",
      "Epoch 2/100\n",
      "  1/268 [..............................] - ETA: 26s - loss: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 23s 84ms/step - loss: 0.0029 - val_loss: 2.6718e-04\n",
      "Epoch 3/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 0.0023 - val_loss: 2.6019e-04\n",
      "Epoch 4/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.0014 - val_loss: 3.0140e-04\n",
      "Epoch 5/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0011 - val_loss: 2.4426e-04\n",
      "Epoch 6/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.0014 - val_loss: 4.6190e-04\n",
      "Epoch 7/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0012 - val_loss: 1.7967e-04\n",
      "Epoch 8/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 0.0012 - val_loss: 1.0093e-04\n",
      "Epoch 9/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 0.0010 - val_loss: 1.0841e-04\n",
      "Epoch 10/100\n",
      "268/268 [==============================] - 23s 84ms/step - loss: 8.5155e-04 - val_loss: 1.3101e-04\n",
      "Epoch 11/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 0.0011 - val_loss: 9.8631e-05\n",
      "Epoch 12/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 0.0013 - val_loss: 9.4301e-05\n",
      "Epoch 13/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 8.8210e-04 - val_loss: 1.8014e-04\n",
      "Epoch 14/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.7451e-04 - val_loss: 7.9077e-05\n",
      "Epoch 15/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.8921e-04 - val_loss: 2.9674e-04\n",
      "Epoch 16/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 8.1639e-04 - val_loss: 7.8907e-05\n",
      "Epoch 17/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 0.0010 - val_loss: 8.6821e-05\n",
      "Epoch 18/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 7.5703e-04 - val_loss: 2.3014e-04\n",
      "Epoch 19/100\n",
      "268/268 [==============================] - 23s 87ms/step - loss: 8.7446e-04 - val_loss: 8.6288e-05\n",
      "Epoch 20/100\n",
      "268/268 [==============================] - 21s 79ms/step - loss: 7.1222e-04 - val_loss: 1.1900e-04\n",
      "Epoch 21/100\n",
      "268/268 [==============================] - 24s 89ms/step - loss: 8.9595e-04 - val_loss: 1.7327e-04\n",
      "Epoch 22/100\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 6.5367e-04 - val_loss: 5.2067e-04\n",
      "Epoch 23/100\n",
      "268/268 [==============================] - 22s 83ms/step - loss: 8.8226e-04 - val_loss: 8.7138e-05\n",
      "Epoch 24/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 7.1521e-04 - val_loss: 1.2569e-04\n",
      "Epoch 25/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 7.7135e-04 - val_loss: 7.0581e-04\n",
      "Epoch 26/100\n",
      "268/268 [==============================] - 23s 86ms/step - loss: 8.3300e-04 - val_loss: 1.0281e-04\n",
      "Epoch 27/100\n",
      "268/268 [==============================] - 22s 82ms/step - loss: 7.4632e-04 - val_loss: 1.6516e-04\n",
      "Epoch 28/100\n",
      "268/268 [==============================] - 22s 84ms/step - loss: 8.3642e-04 - val_loss: 1.5638e-04\n",
      "Epoch 29/100\n",
      "268/268 [==============================] - 22s 81ms/step - loss: 7.8379e-04 - val_loss: 2.5679e-04\n",
      "Epoch 30/100\n",
      "268/268 [==============================] - 21s 77ms/step - loss: 8.1466e-04 - val_loss: 3.0665e-04\n",
      "Epoch 31/100\n",
      "268/268 [==============================] - 21s 78ms/step - loss: 7.1424e-04 - val_loss: 9.4564e-05\n",
      "8/8 [==============================] - 3s 58ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.82759218669183\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 13s 40ms/step - loss: 0.0079 - val_loss: 4.8694e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 3s - loss: 0.0026    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0032 - val_loss: 4.0407e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0021 - val_loss: 7.0212e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0014 - val_loss: 2.2632e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0014 - val_loss: 2.0767e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0013 - val_loss: 3.0377e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0014 - val_loss: 3.1895e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 0.0011 - val_loss: 1.3903e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 8.8222e-04 - val_loss: 1.5321e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 9.9285e-04 - val_loss: 7.1685e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.6860e-04 - val_loss: 1.2024e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 0.0010 - val_loss: 5.2659e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0010 - val_loss: 4.7292e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.4875e-04 - val_loss: 1.6705e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.6558e-04 - val_loss: 2.6050e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.2090e-04 - val_loss: 1.0854e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.7992e-04 - val_loss: 1.5895e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.8380e-04 - val_loss: 4.5735e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 7.8260e-04 - val_loss: 9.8425e-05\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.0734e-04 - val_loss: 1.6492e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 8.1617e-04 - val_loss: 1.2406e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4732e-04 - val_loss: 1.1669e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 9.1304e-04 - val_loss: 2.1114e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.1021e-04 - val_loss: 9.5204e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 8.3548e-04 - val_loss: 1.1954e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.7095e-04 - val_loss: 1.1172e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.5637e-04 - val_loss: 1.8556e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.7327e-04 - val_loss: 3.3557e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.4342e-04 - val_loss: 2.1254e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 8.1449e-04 - val_loss: 5.5163e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 7.7191e-04 - val_loss: 2.8806e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.7762e-04 - val_loss: 8.7920e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.5286e-04 - val_loss: 1.4097e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 7.0436e-04 - val_loss: 8.7760e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 6.2773e-04 - val_loss: 1.0824e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4640e-04 - val_loss: 8.4677e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.3682e-04 - val_loss: 9.2790e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 7.6023e-04 - val_loss: 2.3391e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 8.1474e-04 - val_loss: 9.6752e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 6.7877e-04 - val_loss: 9.2536e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.0884e-04 - val_loss: 8.9118e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.3869e-04 - val_loss: 9.0623e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.2662e-04 - val_loss: 4.3649e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.3126e-04 - val_loss: 1.4940e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.2750e-04 - val_loss: 7.9200e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.4007e-04 - val_loss: 8.2507e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.5893e-04 - val_loss: 1.8187e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.0333e-04 - val_loss: 1.8942e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 7.7542e-04 - val_loss: 2.1450e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.5196e-04 - val_loss: 1.7113e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 6.5204e-04 - val_loss: 5.2038e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 5.9029e-04 - val_loss: 2.8590e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 7.2234e-04 - val_loss: 8.2480e-05\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 6.7458e-04 - val_loss: 1.7649e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.9305e-04 - val_loss: 3.2587e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 5.9321e-04 - val_loss: 1.4624e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 6.8768e-04 - val_loss: 8.1954e-05\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 6.3107e-04 - val_loss: 4.2691e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 3s 26ms/step - loss: 5.8353e-04 - val_loss: 1.6631e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 5.7248e-04 - val_loss: 1.2738e-04\n",
      "9/9 [==============================] - 2s 14ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.737554062397694\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 17s 51ms/step - loss: 0.0082 - val_loss: 8.7678e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0051 - val_loss: 7.3439e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0034 - val_loss: 3.1944e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0023 - val_loss: 4.7844e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 0.0026 - val_loss: 3.9540e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0015 - val_loss: 4.9732e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0015 - val_loss: 2.6032e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 1.9571e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0014 - val_loss: 1.7495e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.9043e-04 - val_loss: 1.7691e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.7132e-04 - val_loss: 1.7471e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.1859e-04 - val_loss: 1.4170e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.6984e-04 - val_loss: 3.8345e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0010 - val_loss: 3.5024e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.8529e-04 - val_loss: 1.2428e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 0.0011 - val_loss: 8.4017e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 8.4439e-04 - val_loss: 2.3415e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 8.4039e-04 - val_loss: 2.4702e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 7.7162e-04 - val_loss: 1.2716e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.8634e-04 - val_loss: 1.1576e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.9399e-04 - val_loss: 2.7766e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.3418e-04 - val_loss: 3.3966e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 4s 34ms/step - loss: 6.9064e-04 - val_loss: 9.4607e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 7.0632e-04 - val_loss: 9.9492e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.2562e-04 - val_loss: 3.9328e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.8007e-04 - val_loss: 9.9375e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.1539e-04 - val_loss: 1.0273e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8963e-04 - val_loss: 9.2045e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.9513e-04 - val_loss: 1.6876e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.1892e-04 - val_loss: 9.8311e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.7247e-04 - val_loss: 9.0991e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.2416e-04 - val_loss: 8.3523e-05\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8850e-04 - val_loss: 8.7515e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6407e-04 - val_loss: 8.8011e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.7351e-04 - val_loss: 1.5569e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.5982e-04 - val_loss: 1.1252e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.9885e-04 - val_loss: 1.5838e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.9545e-04 - val_loss: 9.0398e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.9464e-04 - val_loss: 7.9465e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.9849e-04 - val_loss: 1.4328e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.8617e-04 - val_loss: 9.5194e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.5385e-04 - val_loss: 1.5036e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.5810e-04 - val_loss: 1.0636e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 6.5374e-04 - val_loss: 9.1760e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 5.9465e-04 - val_loss: 2.1566e-04\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.4745e-04 - val_loss: 2.2337e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 8.1658e-04 - val_loss: 1.6236e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.1893e-04 - val_loss: 9.0642e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.2691e-04 - val_loss: 8.4179e-05\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.0336e-04 - val_loss: 1.2863e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.9331e-04 - val_loss: 3.5274e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.4383e-04 - val_loss: 8.2699e-05\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.5621e-04 - val_loss: 1.0301e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 6.1662e-04 - val_loss: 9.8113e-05\n",
      "9/9 [==============================] - 2s 19ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.6932409765507384\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 14s 50ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0023 - val_loss: 2.4351e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0015 - val_loss: 2.6720e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 0.0011 - val_loss: 1.7004e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0012 - val_loss: 6.4399e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.6846e-04 - val_loss: 1.8090e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 9.4583e-04 - val_loss: 6.1664e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 9.5222e-04 - val_loss: 1.1453e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.8446e-04 - val_loss: 1.6839e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.2513e-04 - val_loss: 1.4650e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 7.6931e-04 - val_loss: 9.2693e-05\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 8.6839e-04 - val_loss: 8.0984e-05\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 9.4393e-04 - val_loss: 8.6459e-05\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.7204e-04 - val_loss: 3.5721e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 7.0250e-04 - val_loss: 8.8468e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.8718e-04 - val_loss: 9.2787e-05\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 4s 34ms/step - loss: 7.5325e-04 - val_loss: 3.5510e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.7585e-04 - val_loss: 8.9744e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 9.2488e-04 - val_loss: 1.4181e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 6.8409e-04 - val_loss: 1.2995e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 8.4447e-04 - val_loss: 1.8183e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 6.7820e-04 - val_loss: 1.0159e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 6.3298e-04 - val_loss: 1.0375e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.3394e-04 - val_loss: 1.1235e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 8.4230e-04 - val_loss: 5.1042e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.6855e-04 - val_loss: 1.8113e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 5s 34ms/step - loss: 7.3361e-04 - val_loss: 1.3486e-04\n",
      "9/9 [==============================] - 2s 23ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.129119905417614\n",
      "Training model with epochs=100, batch_size=8, sequence_length=25, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 18s 63ms/step - loss: 0.0088 - val_loss: 3.4206e-04\n",
      "Epoch 2/100\n",
      "  3/134 [..............................] - ETA: 5s - loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0035 - val_loss: 4.9316e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0021 - val_loss: 4.9961e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0015 - val_loss: 1.8913e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0013 - val_loss: 5.4405e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0011 - val_loss: 1.6759e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0012 - val_loss: 2.8727e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0015 - val_loss: 2.0059e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0011 - val_loss: 2.2187e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0010 - val_loss: 2.0724e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0011 - val_loss: 2.1236e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.8323e-04 - val_loss: 1.5721e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 8.4390e-04 - val_loss: 1.5954e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 9.6937e-04 - val_loss: 1.0699e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 6.9726e-04 - val_loss: 1.2111e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 9.3764e-04 - val_loss: 8.8038e-05\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 7.8664e-04 - val_loss: 1.1042e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 7.9419e-04 - val_loss: 1.9167e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 7.9879e-04 - val_loss: 9.0217e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 9.7949e-04 - val_loss: 1.4762e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.8176e-04 - val_loss: 9.2491e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 8.4633e-04 - val_loss: 1.2853e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 9.8118e-04 - val_loss: 2.0066e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 8.5519e-04 - val_loss: 1.5922e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.1503e-04 - val_loss: 1.2965e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 6.9597e-04 - val_loss: 1.8939e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 6.8042e-04 - val_loss: 1.0845e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 7.5133e-04 - val_loss: 1.3933e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 6.3061e-04 - val_loss: 1.1485e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 7.5896e-04 - val_loss: 1.3375e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 7.9848e-04 - val_loss: 1.0182e-04\n",
      "9/9 [==============================] - 3s 27ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.3577528819383935\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 16s 70ms/step - loss: 0.0069 - val_loss: 9.9273e-04\n",
      "Epoch 2/100\n",
      "  2/134 [..............................] - ETA: 7s - loss: 0.0037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0031 - val_loss: 2.9738e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0022 - val_loss: 6.9911e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0015 - val_loss: 2.2697e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0015 - val_loss: 1.7919e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0012 - val_loss: 1.9150e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0011 - val_loss: 1.5027e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0013 - val_loss: 9.6305e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0012 - val_loss: 7.2069e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0011 - val_loss: 1.5008e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.0354e-04 - val_loss: 1.4073e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.3893e-04 - val_loss: 1.1994e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 7.9840e-04 - val_loss: 1.7178e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 7.7149e-04 - val_loss: 3.9724e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 7.5489e-04 - val_loss: 5.0121e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 9.2242e-04 - val_loss: 1.8857e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 9.6656e-04 - val_loss: 2.4915e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 8.0812e-04 - val_loss: 2.1934e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 8.6565e-04 - val_loss: 1.2459e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.7771e-04 - val_loss: 1.9077e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 7.3116e-04 - val_loss: 4.5237e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.4228e-04 - val_loss: 9.4868e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 8.1221e-04 - val_loss: 3.5963e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 7.0153e-04 - val_loss: 8.9679e-05\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 7.7135e-04 - val_loss: 8.4177e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 6.4876e-04 - val_loss: 5.8704e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 8.9804e-04 - val_loss: 1.4420e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 8.2870e-04 - val_loss: 9.9929e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.5640e-04 - val_loss: 1.0543e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.3385e-04 - val_loss: 9.3550e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.7964e-04 - val_loss: 1.8994e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.3151e-04 - val_loss: 9.4124e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.3824e-04 - val_loss: 2.8512e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.6730e-04 - val_loss: 8.8379e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.9175e-04 - val_loss: 1.8531e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.8244e-04 - val_loss: 3.5044e-04\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.5317e-04 - val_loss: 9.5810e-05\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 6.8359e-04 - val_loss: 2.0556e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.8379e-04 - val_loss: 8.1618e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.0124e-04 - val_loss: 2.1572e-04\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.5960e-04 - val_loss: 1.4213e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 5.7236e-04 - val_loss: 7.4114e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.7097e-04 - val_loss: 1.0501e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.5403e-04 - val_loss: 7.4543e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 7.5413e-04 - val_loss: 7.9688e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 7.2587e-04 - val_loss: 8.7155e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 5.8449e-04 - val_loss: 8.1531e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.0553e-04 - val_loss: 2.2772e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 5.6910e-04 - val_loss: 4.2319e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.6128e-04 - val_loss: 8.1111e-05\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 5.8135e-04 - val_loss: 1.5262e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.5947e-04 - val_loss: 9.0238e-05\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 6.3605e-04 - val_loss: 8.6472e-05\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 5.5719e-04 - val_loss: 1.0694e-04\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.3500e-04 - val_loss: 8.7745e-05\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 6.0445e-04 - val_loss: 1.6856e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 6.5750e-04 - val_loss: 1.2913e-04\n",
      "8/8 [==============================] - 2s 31ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.1593916547040437\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=50, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 21s 87ms/step - loss: 0.0100 - val_loss: 3.4768e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 9s - loss: 9.5764e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0045 - val_loss: 3.2740e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0036 - val_loss: 2.8320e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0020 - val_loss: 5.1992e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0018 - val_loss: 3.1547e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0015 - val_loss: 3.4666e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 0.0017 - val_loss: 1.9466e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 0.0019 - val_loss: 4.2257e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 0.0013 - val_loss: 2.2537e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 0.0013 - val_loss: 2.2653e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0013 - val_loss: 1.5279e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 0.0010 - val_loss: 2.7010e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.9763e-04 - val_loss: 1.4303e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 9.6085e-04 - val_loss: 4.7052e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 9.6893e-04 - val_loss: 2.8817e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 8.4400e-04 - val_loss: 1.9281e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 9.6965e-04 - val_loss: 1.2878e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 8.2881e-04 - val_loss: 1.5702e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 8.9252e-04 - val_loss: 1.3787e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 8.9531e-04 - val_loss: 3.2487e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.1397e-04 - val_loss: 1.2794e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 8.0184e-04 - val_loss: 1.1485e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.9956e-04 - val_loss: 2.4925e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 12s 89ms/step - loss: 9.6447e-04 - val_loss: 2.4276e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 7.3508e-04 - val_loss: 9.4248e-05\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.4680e-04 - val_loss: 1.0186e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 8.1493e-04 - val_loss: 1.2761e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.3593e-04 - val_loss: 2.2507e-04\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 9.2759e-04 - val_loss: 3.0369e-04\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 7.9090e-04 - val_loss: 1.1109e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 7.9475e-04 - val_loss: 6.1734e-04\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 7.7661e-04 - val_loss: 1.0737e-04\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 12s 89ms/step - loss: 7.1335e-04 - val_loss: 2.2999e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.4997e-04 - val_loss: 1.3380e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 6.9385e-04 - val_loss: 1.9750e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 5.7896e-04 - val_loss: 9.4572e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.2997e-04 - val_loss: 2.6910e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 12s 90ms/step - loss: 6.7861e-04 - val_loss: 9.0587e-05\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 7.1339e-04 - val_loss: 1.0811e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 13s 97ms/step - loss: 6.9182e-04 - val_loss: 8.9005e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.1349e-04 - val_loss: 7.7731e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 12s 88ms/step - loss: 6.2792e-04 - val_loss: 8.3578e-05\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 12s 88ms/step - loss: 7.0553e-04 - val_loss: 1.5843e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 6.5517e-04 - val_loss: 8.8626e-05\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.9790e-04 - val_loss: 1.7817e-04\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 6.1830e-04 - val_loss: 7.5600e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.6023e-04 - val_loss: 8.4137e-05\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 6.0940e-04 - val_loss: 1.7842e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.5139e-04 - val_loss: 8.3804e-05\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 5.8637e-04 - val_loss: 1.4091e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 6.5624e-04 - val_loss: 1.4477e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.7939e-04 - val_loss: 1.3221e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 6.2009e-04 - val_loss: 1.4142e-04\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 6.8740e-04 - val_loss: 7.5834e-05\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.4831e-04 - val_loss: 2.2359e-04\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.3948e-04 - val_loss: 1.2638e-04\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.1800e-04 - val_loss: 1.1501e-04\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 6.7932e-04 - val_loss: 1.0749e-04\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.6872e-04 - val_loss: 1.2321e-04\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 7.0290e-04 - val_loss: 7.9930e-05\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 6.8961e-04 - val_loss: 7.4319e-05\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.9959e-04 - val_loss: 1.2423e-04\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 6.5388e-04 - val_loss: 8.5575e-05\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 5.6738e-04 - val_loss: 1.0641e-04\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 5.6691e-04 - val_loss: 9.0440e-05\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 5.7172e-04 - val_loss: 1.1047e-04\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.3110e-04 - val_loss: 8.2417e-05\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 6.1163e-04 - val_loss: 8.4298e-05\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.1818e-04 - val_loss: 9.9911e-05\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.5217e-04 - val_loss: 9.0748e-05\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.4644e-04 - val_loss: 1.0206e-04\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 9s 69ms/step - loss: 6.6727e-04 - val_loss: 2.2681e-04\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 9s 68ms/step - loss: 6.2599e-04 - val_loss: 8.0359e-05\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.7998e-04 - val_loss: 1.2436e-04\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 9s 70ms/step - loss: 6.4028e-04 - val_loss: 1.5013e-04\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.2923e-04 - val_loss: 9.8854e-05\n",
      "8/8 [==============================] - 3s 38ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 3.757245870111482\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=2\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 20s 95ms/step - loss: 0.0057 - val_loss: 2.8160e-04\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 11s - loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 10s 74ms/step - loss: 0.0028 - val_loss: 6.5386e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0022 - val_loss: 3.8434e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 0.0015 - val_loss: 4.3145e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 0.0013 - val_loss: 1.5511e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.0011 - val_loss: 1.6765e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 0.0014 - val_loss: 1.4991e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 9.6314e-04 - val_loss: 4.1498e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 9.5469e-04 - val_loss: 5.2168e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 8.6715e-04 - val_loss: 1.2088e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.2073e-04 - val_loss: 1.1515e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.4419e-04 - val_loss: 1.0498e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.4882e-04 - val_loss: 1.8274e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.1657e-04 - val_loss: 1.2330e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.7775e-04 - val_loss: 1.4430e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 7.5163e-04 - val_loss: 2.6412e-04\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.8616e-04 - val_loss: 1.9315e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 8.0252e-04 - val_loss: 6.3978e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.2583e-04 - val_loss: 1.0119e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.6899e-04 - val_loss: 9.3651e-05\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 9.0803e-04 - val_loss: 3.1861e-04\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.4861e-04 - val_loss: 8.8380e-05\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.3423e-04 - val_loss: 8.6183e-05\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.3155e-04 - val_loss: 1.9061e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.3311e-04 - val_loss: 6.9942e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 7.2267e-04 - val_loss: 1.7509e-04\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.9458e-04 - val_loss: 1.2218e-04\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.0378e-04 - val_loss: 9.5753e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 10s 78ms/step - loss: 6.9203e-04 - val_loss: 8.0747e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 7.2984e-04 - val_loss: 1.1508e-04\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 8.0591e-04 - val_loss: 9.0794e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 11s 81ms/step - loss: 7.9210e-04 - val_loss: 0.0016\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 7.9651e-04 - val_loss: 1.3544e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.5922e-04 - val_loss: 9.4482e-05\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 7.6052e-04 - val_loss: 1.0244e-04\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 7.0112e-04 - val_loss: 7.6577e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 7.2436e-04 - val_loss: 1.6793e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 11s 79ms/step - loss: 7.2617e-04 - val_loss: 7.4373e-05\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.2476e-04 - val_loss: 9.5334e-05\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 11s 80ms/step - loss: 7.3350e-04 - val_loss: 7.7602e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 7.6250e-04 - val_loss: 2.4250e-04\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 6.6382e-04 - val_loss: 2.9314e-04\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 7.5336e-04 - val_loss: 1.8109e-04\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 6.5051e-04 - val_loss: 1.0212e-04\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.2773e-04 - val_loss: 8.7557e-05\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 10s 75ms/step - loss: 6.2203e-04 - val_loss: 8.3747e-05\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 6.2827e-04 - val_loss: 1.5211e-04\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 5.7537e-04 - val_loss: 1.3223e-04\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 10s 71ms/step - loss: 6.4674e-04 - val_loss: 1.5547e-04\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 10s 72ms/step - loss: 7.6756e-04 - val_loss: 1.5859e-04\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 10s 73ms/step - loss: 6.7163e-04 - val_loss: 1.0148e-04\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 6.6650e-04 - val_loss: 2.0865e-04\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 10s 74ms/step - loss: 6.5883e-04 - val_loss: 1.0890e-04\n",
      "8/8 [==============================] - 4s 59ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.8443500452851613\n",
      "Training model with epochs=100, batch_size=8, sequence_length=60, units=100, layers=3\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 26s 119ms/step - loss: 0.0094 - val_loss: 7.2313e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreenav Dhakal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 20s 147ms/step - loss: 0.0036 - val_loss: 4.1255e-04\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 20s 149ms/step - loss: 0.0024 - val_loss: 2.4098e-04\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 18s 133ms/step - loss: 0.0019 - val_loss: 2.0622e-04\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 18s 131ms/step - loss: 0.0015 - val_loss: 7.4789e-04\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 17s 130ms/step - loss: 0.0016 - val_loss: 2.6935e-04\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 18s 136ms/step - loss: 0.0012 - val_loss: 2.8552e-04\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 13s 95ms/step - loss: 0.0017 - val_loss: 4.6870e-04\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 16s 123ms/step - loss: 0.0010 - val_loss: 1.3735e-04\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 18s 131ms/step - loss: 8.7163e-04 - val_loss: 1.5698e-04\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 8.4174e-04 - val_loss: 6.2065e-04\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 8.6603e-04 - val_loss: 1.0791e-04\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 9.3875e-04 - val_loss: 1.0223e-04\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.0082e-04 - val_loss: 2.0040e-04\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 8.4230e-04 - val_loss: 1.2126e-04\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 8.5936e-04 - val_loss: 9.3064e-05\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.7112e-04 - val_loss: 2.0398e-04\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 9.1633e-04 - val_loss: 7.7391e-04\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.9715e-04 - val_loss: 1.3232e-04\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 6.9452e-04 - val_loss: 1.0446e-04\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 8.4479e-04 - val_loss: 7.8353e-05\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.7155e-04 - val_loss: 1.1309e-04\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 7.8203e-04 - val_loss: 1.1604e-04\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 6.7835e-04 - val_loss: 1.5802e-04\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 6.7755e-04 - val_loss: 2.2490e-04\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 6.8225e-04 - val_loss: 7.5964e-05\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 13s 98ms/step - loss: 6.4999e-04 - val_loss: 7.4481e-05\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 6.6531e-04 - val_loss: 9.2522e-05\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 13s 93ms/step - loss: 0.0011 - val_loss: 8.9008e-05\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 7.1440e-04 - val_loss: 9.7315e-05\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 12s 93ms/step - loss: 6.0720e-04 - val_loss: 7.7682e-05\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.0387e-04 - val_loss: 9.1472e-05\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 7.9092e-04 - val_loss: 1.0312e-04\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 6.6427e-04 - val_loss: 1.0142e-04\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 6.6630e-04 - val_loss: 8.8074e-05\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 6.8279e-04 - val_loss: 9.0527e-05\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 12s 91ms/step - loss: 6.7796e-04 - val_loss: 2.6803e-04\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 7.7026e-04 - val_loss: 3.0875e-04\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 6.7570e-04 - val_loss: 2.6196e-04\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 12s 92ms/step - loss: 6.8335e-04 - val_loss: 9.2938e-05\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 13s 95ms/step - loss: 7.3388e-04 - val_loss: 8.1836e-05\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 13s 94ms/step - loss: 6.4336e-04 - val_loss: 1.5309e-04\n",
      "8/8 [==============================] - 3s 62ms/step\n",
      "Root Mean Squared Error (Testing Dataset): 2.926678873637558\n"
     ]
    }
   ],
   "source": [
    "for epochs in epochs_range:\n",
    "    for batch_size in batch_sizes:\n",
    "        for sequence_length in sequence_lengths:\n",
    "            for units in units_range:\n",
    "                for layers in layers_range:\n",
    "                    print(f\"Training model with epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}, units={units}, layers={layers}\")\n",
    "                    X_train, X_test, y_train, y_test, scaler = prepare_data(df, sequence_length)\n",
    "                    model = build_lstm_model(X_train, units=units, layers=layers)\n",
    "                    model, rmse = train_model_and_evaluate_model(model, X_train, y_train, X_test, y_test, scaler, epochs, batch_size, sequence_length, units, layers)\n",
    "                    results.append({'epochs': epochs, 'batch_size': batch_size, 'sequence_length': sequence_length, 'units': units, 'layers': layers, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "514eee58-98c2-42e4-a48e-670d4c1f7c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 3.5649441456419657}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 3.2605241961169904}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 2.745883073945297}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 3.1647649199138193}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 3.109352861503208}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 3.1380105579063278}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 3.48492639562897}\n",
      "{'epochs': 100, 'batch_size': 4, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 2.82759218669183}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 2, 'rmse': 2.737554062397694}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 50, 'layers': 3, 'rmse': 2.6932409765507384}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 2, 'rmse': 3.129119905417614}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 25, 'units': 100, 'layers': 3, 'rmse': 3.3577528819383935}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 2, 'rmse': 3.1593916547040437}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 50, 'layers': 3, 'rmse': 3.757245870111482}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 2, 'rmse': 2.8443500452851613}\n",
      "{'epochs': 100, 'batch_size': 8, 'sequence_length': 60, 'units': 100, 'layers': 3, 'rmse': 2.926678873637558}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e5524-ad13-414f-b6a0-431904176668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
